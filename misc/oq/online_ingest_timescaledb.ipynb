{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e5ad9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics as stats\n",
    "import multiprocessing\n",
    "import time \n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "start_program = time.time()\n",
    "from multiprocessing import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from threading import Thread\n",
    "import time\n",
    "import subprocess \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2cda1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[] for i in range(5)]\n",
    "\n",
    "n_it = 100\n",
    "\n",
    "\n",
    "n_st = number_stations = 10\n",
    "n_s = number_sensors = 100\n",
    "\n",
    "def_st = 1\n",
    "def_s = 3\n",
    "def_r = 'day'\n",
    "\n",
    "\n",
    "set_date = [random.random() for i in range(500)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4c5bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def str_time_prop(start, end, time_format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formatted in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.mktime(time.strptime(start, time_format))\n",
    "    etime = time.mktime(time.strptime(end, time_format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return time.strftime(time_format, time.localtime(ptime))\n",
    "\n",
    "\n",
    "\n",
    "def random_date(start, end, prop, dform = '%Y-%m-%dT%H:%M:%S'):\n",
    "    return str_time_prop(start, end, dform, prop)\n",
    "    \n",
    "    \n",
    "def to_pm(v):\n",
    "    return str(round(v[0][0],2)) + \"$\" + '\\\\' + \"pm$\" + str(round(v[1][0],2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a529f",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e955bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_q1 = \"\"\"select time, id_station, <sid> FROM <db> where id_station in <stid>\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "# t_q1 = \"\"\"select time, s<sid> FROM d1 where id_station='st<stid>'\n",
    "# AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "# AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "t_q2 = \"\"\"select time, id_station, <sid> FROM <db> where id_station in <stid>\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' and <sfilter>;\"\"\"\n",
    "\n",
    "t_q3 = \"\"\"SELECT id_station, <avg_s> FROM <db> \n",
    "WHERE time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' \n",
    "AND id_station in <stid>\n",
    "GROUP BY id_station;\"\"\"\n",
    "\n",
    "t_q4 = \"\"\"SELECT id_station, EXTRACT(YEAR FROM time) AS \"year\",\n",
    "date_trunc('month', time) AS \"month\", \n",
    "date_trunc('DAY', time) AS \"day\", \n",
    "date_trunc('HOUR', time) AS \"hour\", \n",
    "<avg_s>\n",
    "FROM <db> where  time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' \n",
    "AND id_station in <stid>\n",
    "GROUP BY id_station, \"year\", \"month\", \"day\", \"hour\";\"\"\"\n",
    "\n",
    "t_q5 = \"\"\"SELECT\n",
    "  time_bucket_gapfill('5 second', time) AS NEWTIME,\n",
    "  id_station,\n",
    "  <avg_s>,\n",
    "  <interpolate_avg>\n",
    "FROM <db>\n",
    "WHERE time < '<timestamp>' AND time > timestamp '<timestamp>' - interval '<nb> <rangesUnit>'\n",
    "AND id_station in <stid> \n",
    "GROUP BY NEWTIME, id_station\n",
    "ORDER BY NEWTIME;\"\"\" # interpolate(avg(s<sid>))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725e5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "\n",
    "class TimescaleDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, db, max_d, rangesUnit, n_it, start_date = \"2019-04-01T00:00:00\", stop_date = \"2019-04-30T00:00:00\", n_st = 1, n_s = 10):\n",
    "        \n",
    "        CONNECTION = \"postgres://postgres:postgres@diufrm118:5432/postgres\"\n",
    "        conn = psycopg2.connect(CONNECTION)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select time, s4 FROM d1 where id_station='st1' AND time > TIMESTAMP '2019-03-06T16:57:36' - INTERVAL '1' day AND time < TIMESTAMP '2019-03-06T16:57:36';\")\n",
    "        cursor.fetchall()\n",
    "#         cursor.execute(\"set jit = off;\")\n",
    "        results = [[],[]]\n",
    "        \n",
    "        duration = max_d\n",
    "        \n",
    "        \n",
    "        runtimes = []\n",
    "        full_time = time.time()\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(start_date, stop_date, set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "            \n",
    "            li = ['st' + str(z) for z in random.sample(range(number_stations), n_st)]\n",
    "            q = '(' + \"'\" + li[0] + \"'\"\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + \"'\" + j + \"'\"\n",
    "            q += \")\"\n",
    "            temp = temp.replace(\"<stid>\", q)\n",
    "            \n",
    "            # sensor\n",
    "            li = ['s' + str(z) for z in random.sample(range(number_sensors), n_s)]\n",
    "            q = li[0]\n",
    "            q_filter = \"(\" + li[0] + ' > 0.95'\n",
    "            q_interpolate_avg = 'interpolate(avg(' + li[0] + '))'\n",
    "            q_avg = 'avg(' + li[0] + ')'\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + j\n",
    "#                 q_filter += ' OR ' + j + ' > 0.95'\n",
    "                q_avg += ', ' + 'avg(' + j + ')'\n",
    "                q_interpolate_avg += ', interpolate(avg(' + j + '))'\n",
    "\n",
    "            temp = temp.replace(\"<db>\", db)\n",
    "            temp = temp.replace(\"<sid>\", q)\n",
    "            temp = temp.replace(\"<sfilter>\", q_filter + \")\")\n",
    "            temp = temp.replace(\"<interpolate_avg>\", q_interpolate_avg)\n",
    "            temp = temp.replace(\"<avg_s>\", q_avg)\n",
    "\n",
    "            start = time.time()\n",
    "#             print(temp)\n",
    "            cursor.execute(temp)\n",
    "            cursor.fetchall()\n",
    "            diff = (time.time()-start)*1000\n",
    "#             print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "            if time.time() - full_time > 20 and i > 5: \n",
    "                break                \n",
    "#         print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def insert_file(batch_size,rate, st):\n",
    "#         template_sql = \"INSERT INTO d1_wide_slow_ingest (time, id_station\"\n",
    "#         for i in range(100):\n",
    "#             template_sql += \", s\" + str(i)\n",
    "#         template_sql += \") VALUES ('%s', '%s',\"  + ','.join(100* [' %s']) + ');'\n",
    "\n",
    "        CONNECTION = \"postgres://postgres:postgres@diufrm118:5432/postgres\"\n",
    "        conn = psycopg2.connect(CONNECTION)\n",
    "        conn.autocommit = True\n",
    "        cur = conn.cursor()\n",
    "        file = '/home/abdel/venv2/bin/insertion-100/short_ts' + str(st) + '.csv'\n",
    "        f = open(file, \"r\")\n",
    "        f = f.read()\n",
    "        f = f.splitlines()[1:]\n",
    "        for i in range(len(f)):\n",
    "            f[i] = f[i].split(',')            \n",
    "            temp = \"'\" + f[i][0] + \"' , \" + \"'\" + f[i][1] + \"' \"\n",
    "            for e in f[i][2:]:\n",
    "                temp += \", \" + str(e)\n",
    "            f[i] = temp\n",
    "        queries = []\n",
    "        for i in range(0, len(f), rate):\n",
    "            q = \"INSERT INTO d1_ingest VALUES (\" +  f[i] + \")\"\n",
    "            for i in f[i+1:i+rate]:\n",
    "                q += \", (\" + i + \")\"\n",
    "            queries.append(q)\n",
    "        start = time.time()\n",
    "        a = 0\n",
    "        print('insertion st' + str(st) + ' started')\n",
    "        while not stop_insertion[st]: \n",
    "            starttime = time.time()\n",
    "            cur.execute(queries[a])\n",
    "            a += 1\n",
    "            diff = 1.0 - ((time.time() - starttime))\n",
    "            try: \n",
    "                time.sleep(diff)\n",
    "            except: \n",
    "                print(diff)\n",
    "        \n",
    "    @staticmethod\n",
    "    def insert_file_1station(batch_size,rate, st, f):\n",
    "#         template_sql = \"INSERT INTO d1_wide_slow_ingest (time, id_station\"\n",
    "#         for i in range(100):\n",
    "#             template_sql += \", s\" + str(i)\n",
    "#         template_sql += \") VALUES ('%s', '%s',\"  + ','.join(100* [' %s']) + ');'\n",
    "\n",
    "        CONNECTION = \"postgres://postgres:postgres@diufrm118:5432/postgres\"\n",
    "        conn = psycopg2.connect(CONNECTION)\n",
    "        conn.autocommit = True\n",
    "        cur = conn.cursor()\n",
    "#         file = '/home/abdel/venv2/bin/insertion-100/short_ts' + str(st) + '.csv'\n",
    "#         f = open(file, \"r\")\n",
    "#         f = f.read()\n",
    "#         f = f.splitlines()[1:]\n",
    "#         for i in range(len(f)):\n",
    "#             f[i] = f[i].split(',')            \n",
    "#             temp = \"'\" + f[i][0] + \"' , \" + \"'\" + f[i][1] + \"' \"\n",
    "#             for e in f[i][2:]:\n",
    "#                 temp += \", \" + str(e)\n",
    "#             f[i] = temp\n",
    "        queries = []\n",
    "        for i in range(0, len(f), rate):\n",
    "            q = \"INSERT INTO d1_ingest VALUES (\" +  f[i] + \")\"\n",
    "            for i in f[i+1:i+rate]:\n",
    "                q += \", (\" + i + \")\"\n",
    "            queries.append(q)\n",
    "        start = time.time()\n",
    "        a = 0\n",
    "        print('insertion st' + str(st) + ' started')\n",
    "        while not stop_insertion[st]: \n",
    "            starttime = time.time()\n",
    "            cur.execute(queries[a])\n",
    "            a += 1\n",
    "            diff = 1.0 - ((time.time() - starttime))\n",
    "            try: \n",
    "                time.sleep(diff)\n",
    "            except: \n",
    "                print(diff)\n",
    "        \n",
    "    @staticmethod\n",
    "    def run_all(start, stop, db):\n",
    "        results[0].append(to_pm(TimescaleDB.query(t_q1, db, 1, def_r, n_it, start, stop, n_st = def_st, n_s = def_s)))\n",
    "        results[1].append(to_pm(TimescaleDB.query(t_q2, db, 1, def_r, n_it, start, stop, n_st = def_st, n_s = def_s)))\n",
    "        results[2].append(to_pm(TimescaleDB.query(t_q3, db, 1, def_r, n_it, start, stop, n_st = def_st, n_s = def_s)))\n",
    "        results[3].append(to_pm(TimescaleDB.query(t_q4, db, 1, def_r, n_it, start, stop, n_st = def_st, n_s = def_s)))\n",
    "        results[4].append(to_pm(TimescaleDB.query(t_q5, db, 1, def_r, n_it, start, stop, n_st = def_st, n_s = def_s)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc83fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TimescaleDB.run_all(\"2019-04-01T00:00:00\", \"2019-04-30T00:00:00\", \"d1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdbffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_insertion = [False for i in range(1)]\n",
    "rate = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9f9458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [01:45<00:00, 10.57s/it]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for st in tqdm(range(10)): \n",
    "    file = '/home/abdel/venv2/bin/insertion-100/short_ts' + str(st) + '.csv'\n",
    "    f = open(file, \"r\")\n",
    "    f = f.read()\n",
    "    f = f.splitlines()[1:]\n",
    "    for i in range(len(f)):\n",
    "        f[i] = f[i].split(',')            \n",
    "        temp = \"'\" + f[i][0] + \"' , \" + \"'\" + f[i][1] + \"' \"\n",
    "        for e in f[i][2:]:\n",
    "            temp += \", \" + str(e)\n",
    "        f[i] = temp\n",
    "    data.append(f)\n",
    "data2 = []\n",
    "for i in range(len(data[0])):\n",
    "    for j in range(10):\n",
    "        data2.append(data[j][i])\n",
    "f = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "408341a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insertion st0 started\n",
      "-4.890644788742065\n",
      "-1.9235787391662598\n",
      "-1.3168938159942627\n",
      "-1.0350377559661865\n",
      "-1.1226608753204346\n",
      "-1.22843337059021\n",
      "-1.1538517475128174\n",
      "-1.4646246433258057\n",
      "-1.7012081146240234\n",
      "-1.9128189086914062\n",
      "-1.2089052200317383\n",
      "-1.6284751892089844\n",
      "-1.0528538227081299\n",
      "-1.056199550628662\n",
      "-1.516286849975586\n",
      "-1.8915154933929443\n",
      "-1.1276702880859375\n",
      "-2.1982507705688477\n",
      "-1.7213656902313232\n",
      "-1.0831890106201172\n",
      "-1.2381577491760254\n",
      "-1.4078443050384521\n",
      "-1.7998137474060059\n",
      "-1.4179494380950928\n",
      "-1.194673776626587\n",
      "-1.2500855922698975\n",
      "-1.71842622756958\n",
      "-1.3827025890350342\n",
      "-3.9723167419433594\n",
      "-1.487624168395996\n",
      "-1.073974847793579\n",
      "-1.2158141136169434\n",
      "-1.3494787216186523\n",
      "-1.450373888015747\n",
      "-1.3126046657562256\n",
      "-1.6241672039031982\n",
      "-1.0301215648651123\n",
      "-1.1290340423583984\n",
      "-2.8703176975250244\n",
      "-2.8866631984710693\n",
      "-1.391852855682373\n",
      "-1.9225883483886719\n",
      "-1.3511295318603516\n",
      "-1.263110876083374\n",
      "-1.2930753231048584\n",
      "-1.4740755558013916\n",
      "-1.3003170490264893\n",
      "-1.0826289653778076\n",
      "-1.1330795288085938\n",
      "-5.097606182098389\n",
      "-1.779118299484253\n",
      "-1.2146830558776855\n",
      "-1.4297642707824707\n",
      "-1.5518555641174316\n",
      "-1.2499876022338867\n",
      "-1.159364938735962\n",
      "-1.467371940612793\n",
      "-1.1938858032226562\n",
      "-1.3415648937225342\n",
      "-3.666762351989746\n",
      "-1.8031911849975586\n",
      "-1.3747014999389648\n",
      "-1.1381101608276367\n",
      "-1.4695403575897217\n",
      "-1.2044928073883057\n",
      "-1.5351059436798096\n",
      "-1.7054073810577393\n",
      "-1.347665548324585\n",
      "-1.4232559204101562\n",
      "-1.2116622924804688\n",
      "-4.135916471481323\n",
      "-1.6527256965637207\n",
      "-1.4223973751068115\n",
      "-1.3100764751434326\n",
      "-1.1012146472930908\n",
      "-1.3734853267669678\n",
      "-1.1301743984222412\n",
      "-1.55832839012146\n",
      "-1.3873913288116455\n",
      "-1.2877941131591797\n",
      "-3.3267805576324463\n",
      "-1.632150411605835\n",
      "-1.2610664367675781\n",
      "-1.2808423042297363\n",
      "-1.2729310989379883\n",
      "-1.3090195655822754\n",
      "-0.7701923847198486\n",
      "-0.07232236862182617\n",
      "-0.054527997970581055\n",
      "-0.013570547103881836\n",
      "-0.0051267147064208984\n",
      "-0.0037665367126464844\n",
      "-0.05619454383850098\n"
     ]
    }
   ],
   "source": [
    "n_threads = 1\n",
    "stop_insertion = [False for i in range(n_threads)]\n",
    "rate = 2000\n",
    "\n",
    "# 20K dp/s\n",
    "\n",
    "# Launch insertion\n",
    "for i in range(n_threads):  \n",
    "    t1 = Thread(target = TimescaleDB.insert_file_1station, args=(100_000, rate, i, f))\n",
    "#     t1 = Thread(target = ClickHouse.insert_by_point, args=(rate, i))\n",
    "    t1.setDaemon(True)\n",
    "    t1.start()\n",
    "\n",
    "# insert_new(200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_threads = 50\n",
    "stop_insertion = [False for i in range(n_threads)]\n",
    "rate = 200\n",
    "\n",
    "# 20K dp/s\n",
    "\n",
    "# Launch insertion\n",
    "for i in range(n_threads):  \n",
    "    t1 = Thread(target = TimescaleDB.insert_file, args=(100_000, rate, i))\n",
    "#     t1 = Thread(target = ClickHouse.insert_by_point, args=(rate, i))\n",
    "    t1.setDaemon(True)\n",
    "    t1.start()\n",
    "\n",
    "# insert_new(200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767f0ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.sleep(3 * 8640 // rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10791d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TimescaleDB.run_all(\"2019-04-01T00:00:00\", \"2019-04-30T00:00:00\", \"d1_ingest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecda0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TimescaleDB.run_all(\"2019-05-01T01:00:00\", \"2019-05-02T00:00:00\", \"d1_ingest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e20ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TimescaleDB.run_all(\"2019-04-29T01:00:00\", \"2019-05-02T00:00:00\", \"d1_ingest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd7751d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_insertion = [True for i in range(n_threads)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ceed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes = [[float(results[i][j].split('$')[0]) for j in range(len(results[i]))][:4] for i in range(5)]\n",
    "variance = [[float(results[i][j].split('$')[2]) for j in range(len(results[i]))][:4] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eea9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes = list(map(list, zip(*runtimes)))\n",
    "variance = list(map(list, zip(*variance)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253767d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X = np.arange(5)\n",
    "labels = ['query'+str(1+i) for i in range(5)]\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "for i in range(4):\n",
    "    ax.bar(X +0.15*i, runtimes[i], yerr = variance[i], width = 0.15)\n",
    "ax.legend(['offline', 'online old', 'online new', 'online mixed', ])\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.yaxis.grid(True)\n",
    "plt.title('ClickHouse offline vs. online, rate: '+ str(rate) + ' x ' + str(n_threads))\n",
    "plt.tight_layout()\n",
    "\n",
    "# ax.bar(X+0.25, data[1], color = 'g', width = 0.25)\n",
    "# ax.bar(X+0.5, data[2], color = 'r', width = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71dee257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "CONNECTION = \"postgres://postgres:postgres@diufrm118:5432/postgres\"\n",
    "conn = psycopg2.connect(CONNECTION)\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"drop table d1_ingest;\")\n",
    "cursor.execute(\"CREATE TABLE d1_ingest (time TIMESTAMP NOT NULL, id_station VARCHAR(4) NOT NULL, s0 DOUBLE PRECISION , s1 DOUBLE PRECISION , s2 DOUBLE PRECISION , s3 DOUBLE PRECISION , s4 DOUBLE PRECISION , s5 DOUBLE PRECISION , s6 DOUBLE PRECISION , s7 DOUBLE PRECISION , s8 DOUBLE PRECISION , s9 DOUBLE PRECISION , s10 DOUBLE PRECISION , s11 DOUBLE PRECISION , s12 DOUBLE PRECISION , s13 DOUBLE PRECISION , s14 DOUBLE PRECISION , s15 DOUBLE PRECISION , s16 DOUBLE PRECISION , s17 DOUBLE PRECISION , s18 DOUBLE PRECISION , s19 DOUBLE PRECISION , s20 DOUBLE PRECISION , s21 DOUBLE PRECISION , s22 DOUBLE PRECISION , s23 DOUBLE PRECISION , s24 DOUBLE PRECISION , s25 DOUBLE PRECISION , s26 DOUBLE PRECISION , s27 DOUBLE PRECISION , s28 DOUBLE PRECISION , s29 DOUBLE PRECISION , s30 DOUBLE PRECISION , s31 DOUBLE PRECISION , s32 DOUBLE PRECISION , s33 DOUBLE PRECISION , s34 DOUBLE PRECISION , s35 DOUBLE PRECISION , s36 DOUBLE PRECISION , s37 DOUBLE PRECISION , s38 DOUBLE PRECISION , s39 DOUBLE PRECISION , s40 DOUBLE PRECISION , s41 DOUBLE PRECISION , s42 DOUBLE PRECISION , s43 DOUBLE PRECISION , s44 DOUBLE PRECISION , s45 DOUBLE PRECISION , s46 DOUBLE PRECISION , s47 DOUBLE PRECISION , s48 DOUBLE PRECISION , s49 DOUBLE PRECISION , s50 DOUBLE PRECISION , s51 DOUBLE PRECISION , s52 DOUBLE PRECISION , s53 DOUBLE PRECISION , s54 DOUBLE PRECISION , s55 DOUBLE PRECISION , s56 DOUBLE PRECISION , s57 DOUBLE PRECISION , s58 DOUBLE PRECISION , s59 DOUBLE PRECISION , s60 DOUBLE PRECISION , s61 DOUBLE PRECISION , s62 DOUBLE PRECISION , s63 DOUBLE PRECISION , s64 DOUBLE PRECISION , s65 DOUBLE PRECISION , s66 DOUBLE PRECISION , s67 DOUBLE PRECISION , s68 DOUBLE PRECISION , s69 DOUBLE PRECISION , s70 DOUBLE PRECISION , s71 DOUBLE PRECISION , s72 DOUBLE PRECISION , s73 DOUBLE PRECISION , s74 DOUBLE PRECISION , s75 DOUBLE PRECISION , s76 DOUBLE PRECISION , s77 DOUBLE PRECISION , s78 DOUBLE PRECISION , s79 DOUBLE PRECISION , s80 DOUBLE PRECISION , s81 DOUBLE PRECISION , s82 DOUBLE PRECISION , s83 DOUBLE PRECISION , s84 DOUBLE PRECISION , s85 DOUBLE PRECISION , s86 DOUBLE PRECISION , s87 DOUBLE PRECISION , s88 DOUBLE PRECISION , s89 DOUBLE PRECISION , s90 DOUBLE PRECISION , s91 DOUBLE PRECISION , s92 DOUBLE PRECISION , s93 DOUBLE PRECISION , s94 DOUBLE PRECISION , s95 DOUBLE PRECISION , s96 DOUBLE PRECISION , s97 DOUBLE PRECISION , s98 DOUBLE PRECISION , s99 DOUBLE PRECISION );\")\n",
    "cursor.execute(\"SELECT create_hypertable('d1_ingest', 'time', chunk_time_interval=>'7 days'::INTERVAL);\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35eda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a564be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"ALTER TABLE d1_ingest SET (timescaledb.compress, timescaledb.compress_segmentby='id_station');\")\n",
    "cursor.execute(\"SELECT compress_chunk(i) FROM show_chunks('d1_ingest') i ORDER BY i DESC OFFSET 1;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50affeae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
