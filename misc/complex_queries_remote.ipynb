{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82170098",
   "metadata": {},
   "source": [
    "# Advanced Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841e5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics as stats\n",
    "start_program = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a19ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "    \n",
    "def str_time_prop(start, end, time_format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formatted in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.mktime(time.strptime(start, time_format))\n",
    "    etime = time.mktime(time.strptime(end, time_format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return time.strftime(time_format, time.localtime(ptime))\n",
    "\n",
    "\n",
    "def random_date(start, end, prop, dform = '%Y-%m-%dT%H:%M:%S'):\n",
    "    return str_time_prop(start, end, dform, prop)\n",
    "    \n",
    "def get_list(elm, n_elm, max_r = 10, prefix = '', suffix = '', apostrophe = True):\n",
    "    res = ''\n",
    "    elms = random.sample(range(max_r), n_elm)\n",
    "    for i in range(n_elm): \n",
    "        item = prefix + elm + str(elms[i]) +  suffix \n",
    "        if apostrophe: \n",
    "            item = \"'\" + item + \"'\"\n",
    "        res += item \n",
    "        if i < n_elm - 1: \n",
    "            res += \", \"\n",
    "    return res\n",
    "\n",
    "import math\n",
    "\n",
    "def percentile(data, perc: int):\n",
    "    size = len(data)\n",
    "    return sorted(data)[int(math.ceil((size * perc) / 100)) - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5709e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1, query2, query3, query4 , query5 = [{},{}],[{},{}],[{},{}],[{},{}],[{},{}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6e3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = {\n",
    "    1: 5,\n",
    "    2: 5,\n",
    "    3: 5,\n",
    "    4: 5,\n",
    "    5: 5\n",
    "}\n",
    "rangesUnit = {\n",
    "    1: \"minute\",\n",
    "    2: \"minute\",\n",
    "    3: \"minute\",\n",
    "    4: \"minute\",\n",
    "    5: \"minute\"\n",
    "}\n",
    "\n",
    "n_it = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e4dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "\n",
    "set_st = [str(random.randint(0,9)) for i in range(500)]\n",
    "set_s = [str(random.randint(0,99)) for i in range(500)]\n",
    "set_date = [random.random() for i in range(500)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96bd9e",
   "metadata": {},
   "source": [
    "# Druid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079cfce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple class\n",
    "# attribute\n",
    "d_q1 = \"\"\"WITH series AS (\n",
    "   SELECT __time, \"value\" FROM d1 WHERE id_station='st<stid>' AND s = 's<sid>'\n",
    "   AND __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "   and __time < TIMESTAMP '<timestamp>'\n",
    "),\n",
    "stats AS (\n",
    "   SELECT\n",
    "       avg(\"value\") as series_mean ,\n",
    "       stddev(\"value\") as series_stddev\n",
    "   FROM\n",
    "       series\n",
    ")\n",
    "SELECT\n",
    "   __time, \"value\",\n",
    "   (\"value\" - series_mean) / CASE WHEN series_stddev = 0 THEN 1 ELSE series_stddev END as zscore\n",
    "FROM\n",
    "   series,\n",
    "   stats\"\"\"\n",
    "\n",
    "\n",
    "d_q2 = \"\"\"\n",
    "WITH series AS (\n",
    "   SELECT  \"__time\", \"value\" FROM d1 WHERE id_station='st<stid>' AND s = 's<sid>' AND __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND __time < TIMESTAMP '<timestamp>'\n",
    "),\n",
    "bounds AS (\n",
    "   SELECT\n",
    "       avg(\"value\") - stddev(\"value\") AS lower_bound,\n",
    "       avg(\"value\") + stddev(\"value\") AS upper_bound\n",
    "   FROM\n",
    "       series\n",
    ")\n",
    "SELECT\n",
    "   \"__time\", \"value\",\n",
    "   \"value\" NOT BETWEEN lower_bound AND upper_bound AS is_anomaly\n",
    "FROM\n",
    "   series,\n",
    "   bounds\n",
    "\"\"\"\n",
    "\n",
    "# d_q3 = \"\"\"select id_station, AVG(\"value\") FROM d1 \n",
    "#     where __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \\\n",
    "#     and __time < TIMESTAMP '<timestamp>' and s = 's<sid>'\n",
    "#     GROUP BY id_station\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "d_q4 = \"\"\"\n",
    "WITH t1 AS (\n",
    "  SELECT \"__time\", \"value\" as s1 FROM d1 WHERE \"id_station\"='st<stid>' AND \"s\" = 's<sid1>'\n",
    "  AND \"__time\" > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit>\n",
    "  and \"__time\" < TIMESTAMP '<timestamp>'\n",
    "),\n",
    "t2 AS (\n",
    "  SELECT \"__time\", \"value\" as s2 FROM d1 WHERE \"id_station\"='st1' AND \"s\" = 's<sid2>'\n",
    "  AND \"__time\" > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit>\n",
    "  and \"__time\" < TIMESTAMP '<timestamp>'\n",
    ")\n",
    "SELECT ((SUM(s1 * s2) - (SUM(s1) * SUM(s2)) / COUNT(*))) /\n",
    "  (SQRT(SUM(s1 * s1) - (SUM(s1) * SUM (s1)) / COUNT(*)) * SQRT(SUM(s2 * s2) - (SUM(s2) * SUM(s2)) / COUNT(*) )) \n",
    "AS pearson_corr \n",
    "FROM\n",
    "  t1,\n",
    "  t2\n",
    "WHERE t1.\"__time\" = t2.\"__time\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "d_q5 = \"\"\"\n",
    "WITH t1 AS (\n",
    "  SELECT \"__time\", \"value\" as s1 FROM d1 WHERE \"id_station\"='st<stid>' AND \"s\" = 's<sid1>'\n",
    "  AND \"__time\" > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit>\n",
    "  and \"__time\" < TIMESTAMP '<timestamp>'\n",
    "),\n",
    "t2 AS (\n",
    "  SELECT \"__time\", \"value\" as s2 FROM d1 WHERE \"id_station\"='st<stid>' AND \"s\" = 's<sid2>'\n",
    "  AND \"__time\" > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit>\n",
    "  and \"__time\" < TIMESTAMP '<timestamp>'\n",
    ")\n",
    "select sum(power(s1-s2,2))\n",
    "FROM\n",
    "  t1,\n",
    "  t2\n",
    "WHERE t1.\"__time\" = t2.\"__time\"\n",
    "\"\"\"\n",
    "#druid = Druid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35811a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = PyDruid('http://diufrm118:8083', 'druid/v2/')\n",
    "\n",
    "# ts = query.timeseries(\n",
    "#     datasource='d1',\n",
    "#     granularity={\"type\": \"duration\", \"duration\": 5000},\n",
    "#     aggregations={\"value\": stringfirst(\"value\")},\n",
    "#     intervals='2019-03-01/pt1h',\n",
    "#     filter=Dimension('s') == 's4',\n",
    "#     context={\"skipEmptyBuckets\": \"false\"}   \n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# # print(ts)\n",
    "\n",
    "# query.export_pandas()\n",
    "\n",
    "# # query.execute(d_q5)\n",
    "# # print((time.time()-start)*1000)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fde452ab",
   "metadata": {},
   "source": [
    "random_date(\"2019-04-01 00:00:00\", \"2019-05-01 00:00:00\", random.random(), dform = '%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a85adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydruid.client import *\n",
    "from pylab import plt\n",
    "from pydruid.db import connect\n",
    "from pydruid.utils.aggregators import *\n",
    "from pydruid.utils.filters import *\n",
    "\n",
    "class Druid:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it):\n",
    "        conn = connect(host='diufrm102', port=8082, path='/druid/v2/sql/', scheme='http')\n",
    "        curs = conn.cursor()\n",
    "        curs.execute(\"select * FROM d1 where id_station in ('st5') and s='s14' and __time > TIMESTAMP '2019-03-04 00:00:00' - INTERVAL '1' DAY and __time < TIMESTAMP '2019-03-04 00:00:00' \")\n",
    "        curs.fetchall()\n",
    "        results = [[],[]]\n",
    "        for duration in tqdm(range(int(max_d/5), max_d + 1, int(max_d/5))):\n",
    "            runtimes = []\n",
    "            for i in range(n_it):\n",
    "                date = random_date(\"2019-04-01 00:00:00\", \"2019-05-01 00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%d %H:%M:%S')\n",
    "                temp = query.replace(\"<timestamp>\", date)\n",
    "                temp = temp.replace(\"<nb>\", str(duration))\n",
    "                temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<sid1>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<sid2>\", str(set_s[(duration*(i+1))%500]))\n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "                start = time.time()\n",
    "#                 print(temp)\n",
    "                curs.execute(temp)\n",
    "                curs.fetchall()\n",
    "#                 print(temp, curs.rowcount)\n",
    "                runtimes.append((time.time()-start)*1000)\n",
    "            #print(runtimes)\n",
    "            print(temp)\n",
    "            results[0].append(stats.mean(runtimes))\n",
    "            results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results[0],results[1]\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc7c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query1[0][\"druid\"],query1[1][\"druid\"] = Druid.query(d_q1, max_duration[1], rangesUnit[1], n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2[0][\"druid\"],query2[1][\"druid\"] = Druid.query(d_q2, max_duration[2], rangesUnit[2], n_it)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "463140b1",
   "metadata": {},
   "source": [
    "query3[0][\"druid\"],query3[1][\"druid\"] = Druid.query(d_q3, max_duration[3], rangesUnit[3], n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684d7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4[0][\"druid\"],query4[1][\"druid\"] = Druid.query(d_q4, max_duration[4], rangesUnit[4], n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5[0][\"druid\"],query5[1][\"druid\"] = Druid.query(d_q5, max_duration[5], rangesUnit[5], n_it)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8f640",
   "metadata": {},
   "source": [
    "# eXtremeDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec01cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple class\n",
    "# attribute\n",
    "e_q1 = \"\"\"\n",
    "select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, s<sid>@tt,(s<sid>@tt - (select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt,\n",
    "\tseq_avg(s<sid>@tt) \n",
    "\tfrom d1_v\n",
    "\twhere id_station='st<stid>'))/(select seq_dev(s<sid>) as series_stddev \n",
    "\tfrom d1_v where id_station='st<stid>') \n",
    "\tfrom d1_v where id_station='st<stid>';\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "e_q2 = \"\"\"\n",
    "select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, s<sid>@tt,s<sid>@tt < \n",
    "(select diff from (select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, \n",
    "\tseq_avg(s<sid>@tt)-seq_dev(s<sid>@tt) as diff\n",
    "\tfrom d1_v where id_station='st<stid>')) \n",
    "or s<sid>@tt > (select diff from (select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, \n",
    "\tseq_avg(s<sid>@tt)+seq_dev(s<sid>@tt) as diff\n",
    "\tfrom d1_v where id_station='st<stid>')) as is_anomaly  \n",
    "from d1_v \n",
    "where id_station='st<stid>';\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# e_q3 = \"\"\"\n",
    "# select id_station,seq_filter_pos(t > <timestamp>) as period,\n",
    "# seq_avg(s<sid>@period) as mean,seq_sum(s<sid>@period*60)/(60*61/2) as weighted_mean \n",
    "# from d1_v;\n",
    "# \"\"\"\n",
    "\n",
    "e_q3 = \"\"\"\n",
    "select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, seq_wavg(s<sid1>@tt,s<sid2>@tt) FROM d1_v WHERE id_station = 'st<stid>';\n",
    "\"\"\"\n",
    "\n",
    "e_q4 = \"\"\"\n",
    "select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, seq_corr(s<sid1>@tt,s<sid2>@tt) FROM d1_v WHERE id_station = 'st<stid>';\n",
    "\"\"\"\n",
    "\n",
    "e_q5 = \"\"\"\n",
    "select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, seq_sum(seq_pow(abs(s<sid1>@tt-s<sid2>@tt),2)) FROM d1_v WHERE id_station = 'st<stid>';\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d618428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80.41763305664062, 79.60247993469238, 78.77135276794434, 78.70340347290039, 78.70674133300781, 78.72343063354492, 78.69863510131836, 78.70984077453613, 78.67574691772461, 78.62997055053711]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import exdb \n",
    "import datetime\n",
    "exdb.init_runtime(debug = False, shm = False, disk = False, tmgr = 'mursiw', UsePerfmon = True)\n",
    "con = exdb.connect('diufrm118', 5001)\n",
    "curs = con.cursor()\n",
    "res = []\n",
    "for i in range(10):\n",
    "    start = time.time()\n",
    "    curs.execute(\"select seq_search(t,1555315999 - 12 * 86400,1555315999) as tt, !seq_filter_search(s87@tt > 0.95, tt) as fe, s87@fe FROM d1_v WHERE id_station = 'st4';\")\n",
    "    #curs.fetchall()\n",
    "    res.append((time.time()-start)*1000)\n",
    "con.close()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4e730f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXtremeDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it):\n",
    "        # map the inputs to the function blocks\n",
    "        import exdb \n",
    "        import datetime\n",
    "        exdb.init_runtime(debug = False, shm = False, disk = False, tmgr = 'mursiw')\n",
    "        con = exdb.connect('diufrm118', 5001)\n",
    "        curs = con.cursor()\n",
    "        curs.execute(\"SELECT s23 FROM d1_v where id_station = 'st3'\")\n",
    "        curs.fetchall()\n",
    "        results = [[],[]]\n",
    "        options = {\"day\" : 60 * 60* 24,\n",
    "                   \"week\" : 60 * 60* 24 * 7,\n",
    "                   \"minute\" : 60,\n",
    "                   \"hour\" : 60 * 60,\n",
    "                   \"second\" : 1,\n",
    "                   \"month\" : 60 * 60 * 24 * 30,\n",
    "                   \"year\" :  60 * 60 * 24 * 30 * 12\n",
    "        }\n",
    "        for duration in tqdm(range(int(max_d/5), max_d + 1, int(max_d/5))):\n",
    "            runtimes = []\n",
    "            for i in range(n_it):\n",
    "                date = random_date(\"2019-04-01 00:00:00\", \"2019-05-01 00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%d %H:%M:%S')\n",
    "                date = int(time.mktime(datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S').timetuple()))\n",
    "                temp = query.replace(\"<timestamp>\", str(date))\n",
    "                temp = temp.replace(\"<nb>\", str(duration))\n",
    "                temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<sid1>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<sid2>\", str(set_s[(duration*(i+1))%500]))\n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<rangesUnit>\", str(options[rangesUnit]))\n",
    "#                 print(temp)\n",
    "                start = time.time()\n",
    "                curs.execute(temp)\n",
    "                # print(curs.rowcount)\n",
    "                curs.fetchall()\n",
    "                diff = (time.time()-start)*1000\n",
    "                #print(temp, diff)\n",
    "                runtimes.append(diff)\n",
    "            print(runtimes)\n",
    "            #print(temp)\n",
    "            results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,95))\n",
    "            results[1].append(stats.stdev(runtimes))\n",
    "        con.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3ed19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query1[0][\"extreme\"],query1[1][\"extreme\"] = EXtremeDB.query(e_q1, max_duration[1], rangesUnit[1], n_it)\n",
    "query1[0][\"extreme\"],query1[1][\"extreme\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a7aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query2[0][\"extreme\"],query2[1][\"extreme\"] = EXtremeDB.query(e_q2, max_duration[2], rangesUnit[2], n_it)\n",
    "query2[0][\"extreme\"],query2[1][\"extreme\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3[0][\"extreme\"],query3[1][\"extreme\"] = EXtremeDB.query(e_q3, max_duration[3], rangesUnit[3], n_it)\n",
    "query3[0][\"extreme\"],query3[1][\"extreme\"]\n",
    "# https://www.mcobject.com/docs/extremedb.htm#Users_Guides/SQL/SQL_Language_Reference/Functions/Window_Functions.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de33fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4[0][\"extreme\"],query4[1][\"extreme\"] = EXtremeDB.query(e_q4, max_duration[4], rangesUnit[4], n_it)\n",
    "query4[0][\"extreme\"],query4[1][\"extreme\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5[0][\"extreme\"],query5[1][\"extreme\"] = EXtremeDB.query(e_q5, max_duration[5], rangesUnit[5], n_it)\n",
    "query5[0][\"extreme\"],query5[1][\"extreme\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ff373",
   "metadata": {},
   "source": [
    "# Influx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41bb33dc",
   "metadata": {},
   "source": [
    "i_q1 = \"\"\"select * FROM \"d1\".\"autogen\".\"sensor\" where \"id_station\" ='st<stid>' AND \"s\" ='s<sid>' AND time > '<timestamp>Z' - <nb><rangesUnit> AND  time < '<timestamp>Z'\"\"\"\n",
    "i_q2 = \"\"\"select * FROM \"d1\".\"autogen\".\"sensor\" where \"id_station\" ='st<stid>' AND \"s\" ='s<sid>' AND time > '<timestamp>Z' - <nb><rangesUnit> AND  time < '<timestamp>Z' and value > 0.95\"\"\"\n",
    "i_q3 = \"\"\"SELECT mean(value) FROM \"d1\".\"autogen\".\"sensor\" WHERE  \"s\" ='s<sid>' AND time > '<timestamp>Z' - <nb><rangesUnit> AND time < '<timestamp>Z' GROUP BY \"id_station\"  \"\"\"\n",
    "i_q4 = \"\"\"SELECT first(id_station), mean(value) FROM \"d1\".\"autogen\".\"sensor\" WHERE time > '<timestamp>Z' - <nb><rangesUnit> AND s='s<sid>' and time < '<timestamp>Z' GROUP BY id_station,time(1h)\"\"\"\n",
    "i_q5 = \"\"\"SELECT id_station, mean_value FROM (SELECT mean(value) as mean_value FROM \"d1\".\"autogen\".\"sensor\" WHERE time > '<timestamp>Z' - <nb><rangesUnit> AND time < '<timestamp>Z' AND s='s<sid>' GROUP BY id_station,time(5s) FILL(0)) GROUP BY id_station\"\"\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d35d5be6",
   "metadata": {},
   "source": [
    "import time\n",
    "from influxdb import InfluxDBClient\n",
    "\n",
    "class Influx:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it):\n",
    "        client = InfluxDBClient(host='diufrm118', port=8086, username='abdel')\n",
    "        results = [[],[]]\n",
    "        client.query(\"select * FROM \\\"d1\\\".\\\"autogen\\\".\\\"sensor\\\" where \\\"id_station\\\" ='st8' AND \\\"s\\\" ='s8' AND time > '2019-03-29T02:37:39Z' - 1d  AND  time < '2019-03-29T02:37:39Z'\")\n",
    "        for duration in tqdm(range(int(max_d/5), max_d + 1, int(max_d/5))):\n",
    "            runtimes = []\n",
    "            for i in range(10):\n",
    "                date = random_date(\"2019-04-01T00:00:00\", \"2019-05-01T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "                temp = query.replace(\"<timestamp>\", date)\n",
    "                temp = temp.replace(\"<nb>\", str(duration))\n",
    "                temp = temp.replace(\"<rangesUnit>\", str(rangesUnit[0]))\n",
    "                temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "                start = time.time()\n",
    "                client.query(temp)\n",
    "                runtimes.append((time.time()-start)*1000)\n",
    "            #print(runtimes)\n",
    "            results[0].append(stats.mean(runtimes))\n",
    "            results[1].append(percentile(runtimes,95))\n",
    "#             results[1].append(stats.stdev(runtimes))\n",
    "        client.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "381ccd5e",
   "metadata": {},
   "source": [
    "query1[0][\"influx\"],query1[1][\"influx\"] = Influx.query(i_q1, max_duration[1], rangesUnit[1], n_it)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8bf6696",
   "metadata": {},
   "source": [
    "query2[0][\"influx\"],query2[1][\"influx\"] = Influx.query(i_q2, max_duration[2], rangesUnit[2], n_it)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27b039a7",
   "metadata": {},
   "source": [
    "query3[0][\"influx\"],query3[1][\"influx\"] = Influx.query(i_q3, max_duration[3], rangesUnit[3], n_it)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed02c312",
   "metadata": {},
   "source": [
    "query4[0][\"influx\"],query4[1][\"influx\"] = Influx.query(i_q4, max_duration[4], rangesUnit[4], n_it)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6add7f0",
   "metadata": {},
   "source": [
    "query5[0][\"influx\"],query5[1][\"influx\"] = Influx.query(i_q5, max_duration[5], rangesUnit[5], n_it)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43238efe",
   "metadata": {},
   "source": [
    "# MonetDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b2d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_q1 = \"\"\"WITH series AS (\n",
    "   SELECT time, s<sid> FROM d1 WHERE id_station='st<stid>' AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND time < TIMESTAMP '<timestamp>'\n",
    ")\n",
    "SELECT\n",
    "   time,\n",
    "   (s<sid> - (avg(s<sid>) OVER ())) / (stddev_samp(s<sid>) OVER ()) as zscore\n",
    "FROM\n",
    "   series;\"\"\"\n",
    "\n",
    "\n",
    "m_q2 = \"\"\"WITH series AS (\n",
    "   SELECT time, s<sid> FROM  d1 WHERE id_station='st<stid>' AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND time < TIMESTAMP '<timestamp>'\n",
    "),\n",
    "bounds AS (\n",
    "   SELECT\n",
    "       avg(s<sid>) - stddev_samp(s<sid>) AS lower_bound,\n",
    "       avg(s<sid>) + stddev_samp(s<sid>) AS upper_bound\n",
    "   FROM\n",
    "       series\n",
    ")\n",
    "SELECT\n",
    "   time, s<sid>,\n",
    "   s<sid> NOT BETWEEN lower_bound AND upper_bound AS is_anomaly\n",
    "FROM\n",
    "   series,\n",
    "   bounds;\"\"\"\n",
    "\n",
    "\n",
    "# m_q3 = \"\"\"SELECT id_station, avg(s<sid>) as mean,\n",
    "# sum(s<sid> *\n",
    "# (60 - extract(second from (timestamptz '<timestamp>' - interval '<nb>' <rangesUnit>)))\n",
    "# ) / (60 * 61 / 2) as weighted_mean\n",
    "# FROM d1 WHERE \"time\" > timestamptz '<timestamp>'\n",
    "# GROUP BY id_station;\"\"\"\n",
    "\n",
    "m_q3 = \"\"\"\n",
    "SELECT\n",
    "id_station,\n",
    "avg(s<sid>) as mean,\n",
    "sum(\n",
    "s<sid> *\n",
    "(60 - extract(second from (timestamptz '<timestamp>'  - interval '1' minute)))\n",
    ") / (60 * 61 / 2) as weighted_mean\n",
    "FROM\n",
    "d1\n",
    "WHERE\n",
    "\"time\" > timestamptz '<timestamp>'  - interval '1' minute\n",
    "and \"time\" < timestamptz '<timestamp>' \n",
    "GROUP BY\n",
    "id_station;\n",
    "\"\"\"\n",
    "\n",
    "# m_q3 = \"\"\"\n",
    "# WITH setup AS (\n",
    "# \tSELECT lag(s<sid>) OVER (PARTITION BY id_station ORDER BY time) as prev_temp, \n",
    "# \t\tsys.epoch(time) as ts_e, \n",
    "# \t\tsys.epoch(lag(time) OVER (PARTITION BY id_station ORDER BY time)) as prev_ts_e, \n",
    "# \t\ts<sid>, id_station\n",
    "# \tFROM  d1 WHERE \"time\" > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND \"time\" < TIMESTAMP '<timestamp>'), \n",
    "# nextstep AS (\n",
    "# \tSELECT CASE WHEN prev_temp is NULL THEN NULL \n",
    "# \t\tELSE (prev_temp + s<sid>) / 2 * (ts_e - prev_ts_e) END as weighted_sum, \n",
    "# \t\t* \n",
    "# \tFROM setup)\n",
    "# SELECT id_station,\n",
    "#     avg(s<sid>), -- the regular average\n",
    "# \tsum(weighted_sum) / (max(ts_e) - min(ts_e)) as time_weighted_average -- our derived average\n",
    "# FROM nextstep\n",
    "# GROUP BY id_station;\n",
    "# \"\"\"\n",
    "\n",
    "m_q4 = \"\"\"\n",
    "SELECT ((SUM(s<sid1> * s<sid2>) - (SUM(s<sid1>) * SUM(s<sid2>)) / COUNT(*))) / \n",
    "    (SQRT(SUM(s<sid1> * s<sid1>) - (SUM(s<sid1>) * SUM (s<sid1>)) / COUNT(*)) * SQRT(SUM(s<sid2> * s<sid2>) - (SUM(s<sid2>) * SUM(s<sid2>)) / COUNT(*) )) \n",
    "    AS pearson_corr FROM d1  \n",
    "    WHERE id_station='st<stid>' AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND time < TIMESTAMP '<timestamp>';\n",
    "\"\"\"\n",
    "\n",
    "m_q5 = \"\"\"\n",
    "select sum(power(s<sid1>-s<sid2>,2)) from d1 WHERE id_station='st<stid>' AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND time < TIMESTAMP '<timestamp>';\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46700c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymonetdb\n",
    "import time\n",
    "\n",
    "class MonetDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it):\n",
    "        connection = pymonetdb.connect(username=\"monetdb\", port=54320, password=\"monetdb\", hostname=\"diufrm118\", database=\"mydb\")\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"\"\"select time, s91 FROM d1 where id_station='st4' AND time > TIMESTAMP '2019-03-09T13:43:54' - INTERVAL '3' day AND time < TIMESTAMP '2019-03-09T13:43:54'\"\"\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        for duration in tqdm(range(int(max_d/5), max_d + 1, int(max_d/5))):\n",
    "            runtimes = []\n",
    "            for i in range(n_it):\n",
    "                date = random_date(\"2019-04-01T00:00\", \"2019-05-01T00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M')\n",
    "                temp = query.replace(\"<timestamp>\", date)\n",
    "                temp = temp.replace(\"<nb>\", str(duration))\n",
    "                temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "                temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<sid1>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<sid2>\", str(set_s[(duration*(i+1))%500]))\n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "#                 print(temp)\n",
    "                start = time.time()\n",
    "                cursor.execute(temp)\n",
    "                cursor.fetchall()\n",
    "                runtimes.append((time.time()-start)*1000)\n",
    "            #print(temp)\n",
    "            results[0].append(stats.mean(runtimes))\n",
    "            results[1].append(percentile(runtimes,95))\n",
    "#             results[1].append(stats.stdev(runtimes))\n",
    "        connection.close()\n",
    "        return results\n",
    "\n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def queryZ(query, max_d, rangesUnit, n_it):\n",
    "        connection = pymonetdb.connect(username=\"monetdb\", port=54320, password=\"monetdb\", hostname=\"diufrm118\", database=\"mydb\")\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"\"\"select time, s91 FROM d1 where id_station='st4' AND time > TIMESTAMP '2019-03-09T13:43:54' - INTERVAL '3' day AND time < TIMESTAMP '2019-03-09T13:43:54'\"\"\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        for duration in tqdm(range(int(max_d/5), max_d + 1, int(max_d/5))):\n",
    "            runtimes = []\n",
    "            for i in range(n_it):\n",
    "                date = random_date(\"2019-04-01 00:00\", \"2019-05-01 00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%d %H:%M')\n",
    "                temp = query.replace(\"<timestamp>\", date)\n",
    "                temp = temp.replace(\"<nb>\", str(duration))\n",
    "                temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "                temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "                #print(temp)\n",
    "                start = time.time()\n",
    "                cursor.execute(temp)\n",
    "                cursor.fetchall()\n",
    "                runtimes.append((time.time()-start)*1000)\n",
    "            #print(temp)\n",
    "            results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,95))\n",
    "            results[1].append(stats.stdev(runtimes))\n",
    "        connection.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858da087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query1[0][\"monetdb\"],query1[1][\"monetdb\"] = MonetDB.query(m_q1, max_duration[1], rangesUnit[1], n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49804f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2[0][\"monetdb\"],query2[1][\"monetdb\"] = MonetDB.query(m_q2, max_duration[2], rangesUnit[2], n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd6c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3[0][\"monetdb\"],query3[1][\"monetdb\"] = MonetDB.query(m_q3, max_duration[3], rangesUnit[3], n_it)\n",
    "query3[0][\"monetdb\"],query3[1][\"monetdb\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0fb97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4[0][\"monetdb\"],query3[1][\"monetdb\"] = MonetDB.query(m_q4, max_duration[4], rangesUnit[4], n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5[0][\"monetdb\"],query5[1][\"monetdb\"] = MonetDB.query(m_q5, max_duration[5], rangesUnit[5], n_it)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19c16a",
   "metadata": {},
   "source": [
    "# QuestDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95f64f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_q1 = \"\"\"\n",
    "# WITH series AS (\n",
    "#     SELECT time, s<sid> FROM  d1 WHERE id_station='st<stid>' AND ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L '\n",
    "# ),\n",
    "# stats AS (\n",
    "#    SELECT\n",
    "#        avg(s<sid>) as series_mean ,\n",
    "#        avg(s<sid>) as series_stddev\n",
    "#    FROM\n",
    "#        series\n",
    "# )\n",
    "# SELECT\n",
    "#    s<sid>,\n",
    "#    (s<sid> - series_mean) / series_stddev as zscore\n",
    "# FROM\n",
    "#    series CROSS JOIN stats\n",
    "# \"\"\"\n",
    "\n",
    "# q_q2 = \"\"\"\"\"\"\n",
    "\n",
    "\n",
    "# q_q3 = \"\"\"SELECT id_station, avg(s<sid>) as mean,\n",
    "# sum(s<sid> *\n",
    "# (60 - extract(second from (timestamptz '<timestamp>' - interval '1' minute)))\n",
    "# ) / (60 * 61 / 2) as weighted_mean\n",
    "# FROM d1 WHERE ts IN '<timestamp>;1m'\n",
    "# GROUP BY id_station;\"\"\"\n",
    "\n",
    "# m_q3 = \"\"\"\n",
    "# WITH setup AS (\n",
    "# \tSELECT lag(s<sid>) OVER (PARTITION BY id_station ORDER BY time) as prev_temp, \n",
    "# \t\tsys.epoch(time) as ts_e, \n",
    "# \t\tsys.epoch(lag(time) OVER (PARTITION BY id_station ORDER BY time)) as prev_ts_e, \n",
    "# \t\ts<sid>, id_station\n",
    "# \tFROM  d1 WHERE \"time\" > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND \"time\" < TIMESTAMP '<timestamp>'), \n",
    "# nextstep AS (\n",
    "# \tSELECT CASE WHEN prev_temp is NULL THEN NULL \n",
    "# \t\tELSE (prev_temp + s<sid>) / 2 * (ts_e - prev_ts_e) END as weighted_sum, \n",
    "# \t\t* \n",
    "# \tFROM setup)\n",
    "# SELECT id_station,\n",
    "#     avg(s<sid>), -- the regular average\n",
    "# \tsum(weighted_sum) / (max(ts_e) - min(ts_e)) as time_weighted_average -- our derived average\n",
    "# FROM nextstep\n",
    "# GROUP BY id_station;\n",
    "# \"\"\"\n",
    "\n",
    "q_q4 = \"\"\"\n",
    "SELECT ((SUM(s<sid1> * s<sid2>) - (SUM(s<sid1>) * SUM(s<sid2>)) / COUNT())) / \n",
    "    (SQRT(SUM(s<sid1> * s<sid1>) - (SUM(s<sid1>) * SUM (s<sid1>)) / COUNT()) * SQRT(SUM(s<sid2> * s<sid2>) - (SUM(s<sid2>) * SUM(s<sid2>)) / COUNT() )) \n",
    "    AS pearson_corr FROM d1 \n",
    "    WHERE  id_station='st<stid>' AND ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "q_q5 = \"\"\"\n",
    "select sum(power(s<sid1>-s<sid2>,2)) from d1\n",
    "WHERE  id_station='st<stid>' AND ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08c9269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QuestDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it):\n",
    "        import psycopg2\n",
    "        import time\n",
    "        connection = psycopg2.connect(user=\"admin\",\n",
    "                                          password=\"quest\",\n",
    "                                          host=\"diufrm118\",\n",
    "                                          port=\"8812\",\n",
    "                                          database=\"d1\")\n",
    "        options = {\"day\" : 60 * 60* 24,\n",
    "                   \"week\" : 60 * 60* 24 * 7,\n",
    "                   \"minute\" : 60,\n",
    "                   \"hour\" : 60 * 60,\n",
    "                   \"second\" : 1,\n",
    "                   \"month\" : 60 * 60 * 24 * 30,\n",
    "                   \"year\" :  60 * 60 * 24 * 30 * 12\n",
    "        }\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select ts, s9 FROM d1 where id_station='st4' AND ts IN '2019-03-23;1d'\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        for duration in tqdm(range(int(max_d/5), max_d + 1, int(max_d/5))):\n",
    "            runtimes = []\n",
    "            for i in range(n_it):\n",
    "                date = random_date(\"2019-03-01\", \"2019-04-01\", set_date[(duration*i)%500], dform = '%Y-%m-%d')\n",
    "                temp = query.replace(\"<timestamp>\", date)\n",
    "                temp = temp.replace(\"<nb>\", str(duration))\n",
    "                temp = temp.replace(\"<rangesUnit>\", str(options[rangesUnit]))\n",
    "                temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<sid1>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<sid2>\", str(set_s[(duration*(i+1))%500]))\n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "                start = time.time()\n",
    "                print(temp)\n",
    "                cursor.execute(temp)\n",
    "                cursor.fetchall()\n",
    "                #print(temp, cursor.rowcount)\n",
    "                #print(len)\n",
    "                runtimes.append((time.time()-start)*1000)\n",
    "#             print(temp)\n",
    "            results[0].append(stats.mean(runtimes))\n",
    "            print(runtimes)\n",
    "#             results[1].append(percentile(runtimes,95))\n",
    "            results[1].append(stats.stdev(runtimes))\n",
    "        connection.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3de6f10",
   "metadata": {},
   "source": [
    "query1[0][\"questdb\"],query1[1][\"questdb\"] = QuestDB.query(q_q1, max_duration[1], rangesUnit[1], n_it)\n",
    "query1[1][\"questdb\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dff5ac21",
   "metadata": {},
   "source": [
    "query2[0][\"questdb\"],query2[1][\"questdb\"] = QuestDB.query(q_q2, max_duration[2], rangesUnit[2], n_it)\n",
    "query2[1][\"questdb\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2d1ad0e",
   "metadata": {},
   "source": [
    "query3[0][\"questdb\"],query3[1][\"questdb\"] = QuestDB.query(q_q3, max_duration[3], rangesUnit[3], n_it)\n",
    "query3[1][\"questdb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb0109",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4[0][\"questdb\"],query4[1][\"questdb\"] = QuestDB.query(q_q4, max_duration[4], rangesUnit[4], n_it)\n",
    "query4[1][\"questdb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f4c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5[0][\"questdb\"],query5[1][\"questdb\"] = QuestDB.query(q_q5, max_duration[5], rangesUnit[5], n_it)\n",
    "query5[1][\"questdb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02153fd3",
   "metadata": {},
   "source": [
    "# TimescaleDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "014e1337",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_q1 = \"\"\"WITH series AS (\n",
    "   SELECT time, s<sid> FROM d1 WHERE id_station='st<stid>' AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND time < TIMESTAMP '<timestamp>'\n",
    ")\n",
    "SELECT\n",
    "   time,\n",
    "   (s<sid> - (avg(s<sid>) OVER ())) / (stddev_samp(s<sid>) OVER ()) as zscore\n",
    "FROM\n",
    "   series;\"\"\"\n",
    "\n",
    "\n",
    "t_q2 = \"\"\"WITH series AS (\n",
    "   SELECT time, s<sid> FROM  d1 WHERE id_station='st<stid>' AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND time < TIMESTAMP '<timestamp>'\n",
    "),\n",
    "bounds AS (\n",
    "   SELECT\n",
    "       avg(s<sid>) - stddev(s<sid>) AS lower_bound,\n",
    "       avg(s<sid>) + stddev(s<sid>) AS upper_bound\n",
    "   FROM\n",
    "       series\n",
    ")\n",
    "SELECT\n",
    "   time, s<sid>,\n",
    "   s<sid> NOT BETWEEN lower_bound AND upper_bound AS is_anomaly\n",
    "FROM\n",
    "   series,\n",
    "   bounds;\"\"\"\n",
    "\n",
    "\n",
    "t_q3 = \"\"\"SELECT id_station, avg(s<sid>) as mean, sum(\n",
    "s<sid> *\n",
    "(60 - extract(seconds from '<timestamp>'::timestamptz - interval '1 minute'))\n",
    ") / (60 * 61 / 2) as weighted_mean\n",
    "FROM d1 WHERE \"time\" > TIMESTAMP '<timestamp>'::timestamptz - INTERVAL '1 minute' \n",
    "AND time < TIMESTAMP '<timestamp>'\n",
    "GROUP BY id_station;\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# t_q3 = \"\"\"\n",
    "# WITH setup AS (\n",
    "# \tSELECT lag(s<sid>) OVER (PARTITION BY id_station ORDER BY time) as prev_temp, \n",
    "# \t\textract('epoch' FROM time) as ts_e, \n",
    "# \t\textract('epoch' FROM lag(time) OVER (PARTITION BY id_station ORDER BY time)) as prev_ts_e, \n",
    "# \t\ts<sid>, id_station\n",
    "# \tFROM  d1 WHERE \"time\" > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND \"time\" < TIMESTAMP '<timestamp>'), \n",
    "# nextstep AS (\n",
    "# \tSELECT CASE WHEN prev_temp is NULL THEN NULL \n",
    "# \t\tELSE (prev_temp + s<sid>) / 2 * (ts_e - prev_ts_e) END as weighted_sum, \n",
    "# \t\t*\n",
    "# \tFROM setup)\n",
    "# SELECT id_station,\n",
    "#     avg(s<sid>), -- the regular average\n",
    "# \tsum(weighted_sum) / (max(ts_e) - min(ts_e)) as time_weighted_average -- our derived average\n",
    "# FROM nextstep\n",
    "# GROUP BY id_station;\n",
    "# \"\"\"\n",
    "\n",
    "t_q4 = \"\"\"\n",
    "SELECT corr(s<sid1>, s<sid2>)\n",
    "FROM d1\n",
    "WHERE id_station='st<stid>' \n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>';\n",
    "\"\"\"\n",
    "\n",
    "# t_q4 = \"\"\"\n",
    "# SELECT ((SUM(s<sid1> * s<sid2>) - (SUM(s<sid1>) * SUM(s<sid2>)) / COUNT(*))) / \n",
    "#     (SQRT(SUM(s<sid1> * s<sid1>) - (SUM(s<sid1>) * SUM (s<sid1>)) / COUNT(*)) * SQRT(SUM(s<sid2> * s<sid2>) - (SUM(s<sid2>) * SUM(s<sid2>)) / COUNT(*) )) \n",
    "#     AS pearson_corr FROM d1  \n",
    "#     WHERE id_station='st<stid>' AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND time < TIMESTAMP '<timestamp>';\n",
    "# \"\"\"\n",
    "\n",
    "t_q5 = \"\"\"\n",
    "select sum(power(s<sid1>-s<sid2>,2)) from d1\n",
    "    WHERE id_station='st<stid>' AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> AND time < TIMESTAMP '<timestamp>';\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64495fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TimescaleDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it):\n",
    "        import psycopg2\n",
    "        CONNECTION = \"postgres://postgres:postgres@diufrm118:5432/postgres\"\n",
    "        conn = psycopg2.connect(CONNECTION)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select time, s4 FROM d1 where id_station='st1' AND time > TIMESTAMP '2019-03-06T16:57:36' - INTERVAL '1' day AND time < TIMESTAMP '2019-03-06T16:57:36';\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        for duration in tqdm(range(int(max_d/5), max_d + 1, int(max_d/5))):\n",
    "            runtimes = []\n",
    "            for i in range(n_it):\n",
    "                date = random_date(\"2019-04-01T00:00\", \"2019-05-01T00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M')\n",
    "                temp = query.replace(\"<timestamp>\", date)\n",
    "                temp = temp.replace(\"<nb>\", str(duration))\n",
    "                temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "                temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<sid1>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<sid2>\", str(set_s[(duration*(i+1))%500]))\n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "                start = time.time()\n",
    "#                 print(temp)\n",
    "                cursor.execute(temp)\n",
    "                cursor.fetchall()\n",
    "                #print(cursor.fetchall())\n",
    "                runtimes.append((time.time()-start)*1000)\n",
    "            #print(temp)\n",
    "            results[0].append(stats.mean(runtimes))\n",
    "            results[1].append(percentile(runtimes,95))\n",
    "#             results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def queryZ(query, max_d, rangesUnit, n_it):\n",
    "        import psycopg2\n",
    "        CONNECTION = \"postgres://postgres:postgres@diufrm118:5432/postgres\"\n",
    "        conn = psycopg2.connect(CONNECTION)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select time, s4 FROM d1 where id_station='st1' AND time > TIMESTAMP '2019-03-06T16:57:36' - INTERVAL '1' day AND time < TIMESTAMP '2019-03-06T16:57:36';\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        for duration in tqdm(range(int(max_d/5), max_d + 1, int(max_d/5))):\n",
    "            runtimes = []\n",
    "            for i in range(n_it):\n",
    "                date = random_date(\"2019-04-01 00:00 UTC\", \"2019-05-01 00:00 UTC\", set_date[(duration*i)%500], dform = '%Y-%m-%d %H:%M UTC')\n",
    "                temp = query.replace(\"<timestamp>\", date)\n",
    "                temp = temp.replace(\"<nb>\", str(duration))\n",
    "                temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "                temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "                start = time.time()\n",
    "                #print(temp)\n",
    "                cursor.execute(temp)\n",
    "                cursor.fetchall()\n",
    "                #print(cursor.fetchall())\n",
    "                runtimes.append((time.time()-start)*1000)\n",
    "            #print(temp)\n",
    "            results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,95))\n",
    "            results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1[0][\"timescaledb\"],query1[1][\"timescaledb\"] = TimescaleDB.query(t_q1, max_duration[1], rangesUnit[1], n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2903c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2[0][\"timescaledb\"],query2[1][\"timescaledb\"] = TimescaleDB.query(t_q2, max_duration[2], rangesUnit[2], n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3[0][\"timescaledb\"],query3[1][\"timescaledb\"] = TimescaleDB.query(t_q3, max_duration[3], rangesUnit[3], n_it)\n",
    "query3[0][\"timescaledb\"],query3[1][\"timescaledb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4[0][\"timescaledb\"],query4[1][\"timescaledb\"] = TimescaleDB.query(t_q4, max_duration[4], rangesUnit[4], n_it)\n",
    "query4[0][\"timescaledb\"],query4[1][\"timescaledb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5[0][\"timescaledb\"],query5[1][\"timescaledb\"] = TimescaleDB.query(t_q5, max_duration[5], rangesUnit[5], n_it)\n",
    "query5[0][\"timescaledb\"],query5[1][\"timescaledb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca7ff1",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "colors = ['r', 'b', 'g', 'm', 'c', 'y']\n",
    "colors_dic = {}\n",
    "for i in range(len(list(query1[0].keys()))): \n",
    "    colors_dic[list(query1[0].keys())[i]] = colors[i]\n",
    "colors = colors_dic\n",
    "queries = [query1, query2, query3]\n",
    "\n",
    "for q in queries:\n",
    "    plt.figure()\n",
    "    pp = []\n",
    "    for i in range(len(q[0].keys())):\n",
    "        sys = list(q[0])[i]\n",
    "        x = [j for j in range(int(max_duration[1]/5), max_duration[1] + 1, int(max_duration[1]/5))]\n",
    "        y = q[0][sys]\n",
    "        yerr = q[1][list(q[0])[i]]\n",
    "        p = plt.plot(x, y, '-', color='%s' % colors[sys])\n",
    "        plt.yscale('log')\n",
    "        pp.append(p[0])\n",
    "        plt.errorbar(x, y=y, yerr=yerr, color='%s' % colors[sys]) \n",
    "    plt.legend(pp, q[0].keys(), numpoints=1)\n",
    "    plt.plot()\n",
    "\n",
    "\n",
    "#     fig = plt.figure()\n",
    "#     plt.errorbar(np.arange(len(query1[0][k])), query1[0][k], yerr=query1[1][k], label = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfs = [\n",
    "    pd.DataFrame.from_dict(query1[0],orient='index').transpose(),\n",
    "    pd.DataFrame.from_dict(query2[0],orient='index').transpose(),\n",
    "    pd.DataFrame.from_dict(query3[0],orient='index').transpose(),\n",
    "    pd.DataFrame.from_dict(query4[0],orient='index').transpose(),\n",
    "    pd.DataFrame.from_dict(query5[0],orient='index').transpose()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4283f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b66a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in range(len(dfs)): \n",
    "    rang = [j for j in range(int(max_duration[1+i]/5), max_duration[1+i] + 1, int(max_duration[1+i]/5))]\n",
    "    dfs[i].index = np.array(rang)\n",
    "    dfs[i].set_index([pd.Index(rang)]).plot(title='query' + str(i+1), xlabel='window range ('+rangesUnit[i+1] + ')', ylabel='time (ms)', logy = True,kind = 'line')\n",
    "    print(dfs[i].head())\n",
    "    dfs[i].to_csv('results/q'+str(i)+'.txt', sep = '\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b68673e4",
   "metadata": {},
   "source": [
    "query1[\"druid\"]\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.errorbar(np.arange(len(query1[\"druid\"][0])), query1[\"druid\"][0], yerr=query1[\"druid\"][1], title='query1')\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_program = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Benchmark Runtime: %s minutes' % str((stop_program - start_program)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e4f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyGnuplot as gp\n",
    "# import numpy as np\n",
    "# X = np.arange(10)\n",
    "# Y = np.sin(X/(2*np.pi))\n",
    "# Z = Y**2.0\n",
    "# gp.s([X,Y,Z])\n",
    "# gp.c('plot \"tmp.dat\" u 1:2 w lp')\n",
    "# gp.c('replot \"tmp.dat\" u 1:3 w lp')\n",
    "# gp.p('myfigure.ps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2105fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# db1 = exdb.open_database(\"d1_v\")\n",
    "# print(db1)\n",
    "# con1 = db1.connect();\n",
    "# cursor = con1.cursor()\n",
    "# cursor.execute(\"SELECT count(*) FROM d1_v\")\n",
    "# res = cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d458d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryAll(duration_range):\n",
    "    \n",
    "    max_d = 1000\n",
    "    rangesUnit = \"minute\"\n",
    "    results = [{} for i in range(5)]\n",
    "    for i in range(5):\n",
    "        results[i][\"druid\"] = []\n",
    "        results[i][\"extremedb\"] = []\n",
    "        results[i][\"influx\"] = []\n",
    "        results[i][\"monetdb\"] = []\n",
    "        results[i][\"questdb\"] = []\n",
    "        results[i][\"timescaledb\"] = []\n",
    "        \n",
    "    for duration in tqdm(duration_range):\n",
    "        Dduration = duration\n",
    "        DrangesUnit = rangesUnit\n",
    "        if Dduration > 99: \n",
    "            Dduration = Dduration // 60\n",
    "            Dduration -= Dduration%5\n",
    "            DrangesUnit = \"hour\"  \n",
    "            if Dduration > 99: \n",
    "                Dduration = Dduration // 24\n",
    "                Dduration -= Dduration%5\n",
    "                DrangesUnit = \"day\"          \n",
    "        results[0][\"druid\"].append(Druid.query(d_q1, Dduration, DrangesUnit, n_it)[0][-1])\n",
    "        results[0][\"extremedb\"].append(EXtremeDB.query(e_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[0][\"influx\"].append(Influx.query(i_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[0][\"monetdb\"].append(MonetDB.query(m_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[0][\"questdb\"].append(QuestDB.query(q_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[0][\"timescaledb\"].append(TimescaleDB.query(t_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "\n",
    "        results[1][\"druid\"].append(Druid.query(d_q2, Dduration, DrangesUnit, n_it)[0][-1])\n",
    "        results[1][\"extremedb\"].append(EXtremeDB.query(e_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[1][\"influx\"].append(Influx.query(i_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"monetdb\"].append(MonetDB.query(m_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[1][\"questdb\"].append(QuestDB.query(q_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"timescaledb\"].append(TimescaleDB.query(t_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "\n",
    "#         results[2][\"druid\"].append(Druid.query(d_q3, Dduration, DrangesUnit, n_it)[0][-1])\n",
    "        results[2][\"extremedb\"].append(EXtremeDB.query(e_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[2][\"influx\"].append(Influx.query(i_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"monetdb\"].append(MonetDB.query(m_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[2][\"questdb\"].append(QuestDB.query(q_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"timescaledb\"].append(TimescaleDB.query(t_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "\n",
    "        results[3][\"druid\"].append(Druid.query(d_q4, Dduration, DrangesUnit, n_it)[0][-1])\n",
    "        results[3][\"extremedb\"].append(EXtremeDB.query(e_q4, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[3][\"influx\"].append(Influx.query(i_q4, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[3][\"monetdb\"].append(MonetDB.query(m_q4, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[3][\"questdb\"].append(QuestDB.query(q_q4, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[3][\"timescaledb\"].append(TimescaleDB.query(t_q4, duration, rangesUnit, n_it)[0][-1])\n",
    "\n",
    "        \n",
    "        results[4][\"druid\"].append(Druid.query(d_q5, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[4][\"extremedb\"].append(EXtremeDB.query(e_q5, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[4][\"influx\"].append(Influx.query(i_q5, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[\"monetdb\"].append(MonetDB.query(m_q5, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[4][\"questdb\"].append(QuestDB.query(q_q5, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[4][\"timescaledb\"].append(TimescaleDB.query(t_q5, duration, rangesUnit, n_it)[0][-1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbd7ac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                   | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "range() arg 3 must not be zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m max_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      2\u001b[0m duration_range \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mi \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mlog2(max_range)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)) ]\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mqueryAll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration_range\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m results[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m=\u001b[39m { k: results[\u001b[38;5;241m4\u001b[39m][k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextremedb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minflux\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestdb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimescaledb\u001b[39m\u001b[38;5;124m'\u001b[39m] }\n\u001b[1;32m      6\u001b[0m results\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mqueryAll\u001b[0;34m(duration_range)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 Dduration \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m Dduration\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     24\u001b[0m                 DrangesUnit \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m\"\u001b[39m          \n\u001b[0;32m---> 25\u001b[0m         results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdruid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mDruid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_q1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDrangesUnit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_it\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     26\u001b[0m         results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextremedb\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(EXtremeDB\u001b[38;5;241m.\u001b[39mquery(e_q1, duration, rangesUnit, n_it)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#         results[0][\"influx\"].append(Influx.query(i_q1, duration, rangesUnit, n_it)[0][-1])\u001b[39;00m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mDruid.query\u001b[0;34m(query, max_d, rangesUnit, n_it)\u001b[0m\n\u001b[1;32m     15\u001b[0m curs\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m     16\u001b[0m results \u001b[38;5;241m=\u001b[39m [[],[]]\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m duration \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_d\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_d\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_d\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     18\u001b[0m     runtimes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_it):\n",
      "\u001b[0;31mValueError\u001b[0m: range() arg 3 must not be zero"
     ]
    }
   ],
   "source": [
    "max_range = 1*60*24*30*2\n",
    "duration_range = [ 2**i for i in range(1, int(math.log2(max_range)+1)) ]\n",
    "results = queryAll(duration_range)\n",
    "results[4] = { k: results[4][k] for k in ['extremedb', 'influx', 'questdb', 'timescaledb'] }\n",
    "\n",
    "results       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c0df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
