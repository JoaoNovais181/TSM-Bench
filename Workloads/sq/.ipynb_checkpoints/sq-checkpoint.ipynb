{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0773e3",
   "metadata": {},
   "source": [
    "# Simple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841e5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics as stats\n",
    "start_program = time.time()\n",
    "import pandas as pd\n",
    "import time\n",
    "import statistics as stats\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63a19ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "    \n",
    "def str_time_prop(start, end, time_format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formatted in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.mktime(time.strptime(start, time_format))\n",
    "    etime = time.mktime(time.strptime(end, time_format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return time.strftime(time_format, time.localtime(ptime))\n",
    "\n",
    "\n",
    "def random_date(start, end, prop, dform = '%Y-%m-%dT%H:%M:%S'):\n",
    "    return str_time_prop(start, end, dform, prop)\n",
    "    \n",
    "def get_list(elm, n_elm, max_r = 10, prefix = '', suffix = '', apostrophe = True):\n",
    "    res = ''\n",
    "    elms = random.sample(range(max_r), n_elm)\n",
    "    for i in range(n_elm): \n",
    "        item = prefix + elm + str(elms[i]) +  suffix \n",
    "        if apostrophe: \n",
    "            item = \"'\" + item + \"'\"\n",
    "        res += item \n",
    "        if i < n_elm - 1: \n",
    "            res += \", \"\n",
    "    return res\n",
    "\n",
    "import math\n",
    "\n",
    "def percentile(data, perc: int):\n",
    "    size = len(data)\n",
    "    return sorted(data)[int(math.ceil((size * perc) / 100)) - 1]\n",
    "\n",
    "def to_pm(v):\n",
    "    return str(round(v[0][0],2)) + \"$\" + '\\\\' + \"pm$\" + str(round(v[1][0],2))\n",
    "\n",
    "def queryClickHouse():\n",
    "    start_sys('clickhouse')\n",
    "    for i in range(5):\n",
    "        results[i][\"clickhouse\"] = []\n",
    "    for n_st in [1] + [i for i in range(2, 11, 2)]:\n",
    "        results[0]['clickhouse'].append(to_pm(ClickHouse.query(c_q1, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[1]['clickhouse'].append(to_pm(ClickHouse.query(c_q2, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[2]['clickhouse'].append(to_pm(ClickHouse.query(c_q3, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[3]['clickhouse'].append(to_pm(ClickHouse.query(c_q4, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[4]['clickhouse'].append(to_pm(ClickHouse.query(c_q5, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "    for n_s in [1] + [i for i in range(10, 101, 10)]:\n",
    "        results[0]['clickhouse'].append(to_pm(ClickHouse.query(c_q1, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[1]['clickhouse'].append(to_pm(ClickHouse.query(c_q2, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[2]['clickhouse'].append(to_pm(ClickHouse.query(c_q3, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[3]['clickhouse'].append(to_pm(ClickHouse.query(c_q4, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[4]['clickhouse'].append(to_pm(ClickHouse.query(c_q5, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "    for r in ['minute', 'hour', 'day', 'week', 'month']:\n",
    "        results[0]['clickhouse'].append(to_pm(ClickHouse.query(c_q1, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[1]['clickhouse'].append(to_pm(ClickHouse.query(c_q2, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[2]['clickhouse'].append(to_pm(ClickHouse.query(c_q3, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[3]['clickhouse'].append(to_pm(ClickHouse.query(c_q4, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[4]['clickhouse'].append(to_pm(ClickHouse.query(c_q5, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "    stop_sys('clickhouse')\n",
    "\n",
    "def queryDruid():\n",
    "    start_sys('druid')\n",
    "    for i in range(5):\n",
    "        results[i][\"druid\"] = []\n",
    "    for n_st in [1] + [i for i in range(2, 11, 2)]:\n",
    "        results[0]['druid'].append(to_pm(Druid_Wide.query(dw_q1, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[1]['druid'].append(to_pm(Druid_Wide.query(dw_q2, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[2]['druid'].append(to_pm(Druid_Wide.query(dw_q3, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[3]['druid'].append(to_pm(Druid_Wide.query(dw_q4, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[4]['druid'].append(None)\n",
    "    for n_s in [1] + [i for i in range(10, 101, 10)]:\n",
    "        results[0]['druid'].append(to_pm(Druid_Wide.query(dw_q1, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[1]['druid'].append(to_pm(Druid_Wide.query(dw_q2, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[2]['druid'].append(to_pm(Druid_Wide.query(dw_q3, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[3]['druid'].append(to_pm(Druid_Wide.query(dw_q4, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[4]['druid'].append(None)\n",
    "    for r in [(1,'minute'), (1,'hour'), (1,'day'), (7,'day'), (1,'month')]:\n",
    "        results[0]['druid'].append(to_pm(Druid_Wide.query(dw_q1, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[1]['druid'].append(to_pm(Druid_Wide.query(dw_q2, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[2]['druid'].append(to_pm(Druid_Wide.query(dw_q3, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[3]['druid'].append(to_pm(Druid_Wide.query(dw_q4, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[4]['druid'].append(None)\n",
    "    stop_sys('druid')\n",
    "\n",
    "def queryExtremeDB():  \n",
    "    start_sys('extremedb')\n",
    "    for i in range(5):\n",
    "        results[i][\"extremedb\"] = []    \n",
    "    for n_st in [1] + [i for i in range(2, 11, 2)]:\n",
    "        results[0]['extremedb'].append(to_pm(EXtremeDB.query(e_q1, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[1]['extremedb'].append(to_pm(EXtremeDB.query(e_q2, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[2]['extremedb'].append(to_pm(EXtremeDB.query(e_q3, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[3]['extremedb'].append(to_pm(EXtremeDB.query(e_q4, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[4]['extremedb'].append(to_pm(EXtremeDB.query(e_q5, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "    for n_s in [1] + [i for i in range(10, 101, 10)]:\n",
    "        results[0]['extremedb'].append(to_pm(EXtremeDB.query(e_q1, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[1]['extremedb'].append(to_pm(EXtremeDB.query(e_q2, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[2]['extremedb'].append(to_pm(EXtremeDB.query(e_q3, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[3]['extremedb'].append(to_pm(EXtremeDB.query(e_q4, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[4]['extremedb'].append(to_pm(EXtremeDB.query(e_q5, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "    for r in ['minute', 'hour', 'day', 'week', 'month']:\n",
    "        results[0]['extremedb'].append(to_pm(EXtremeDB.query(e_q1, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[1]['extremedb'].append(to_pm(EXtremeDB.query(e_q2, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[2]['extremedb'].append(to_pm(EXtremeDB.query(e_q3, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[3]['extremedb'].append(to_pm(EXtremeDB.query(e_q4, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[4]['extremedb'].append(to_pm(EXtremeDB.query(e_q5, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "    stop_sys('extremedb')\n",
    "    \n",
    "def queryInflux():\n",
    "    start_sys('influx')\n",
    "    for i in range(5):\n",
    "        results[i][\"influx\"] = [] \n",
    "    for n_st in [1] + [i for i in range(2, 11, 2)]:\n",
    "        results[0]['influx'].append(to_pm(Influx_Wide.query(iw_q1, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[1]['influx'].append(to_pm(Influx_Wide.query(iw_q2, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[2]['influx'].append(to_pm(Influx_Wide.query(iw_q3, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[3]['influx'].append(to_pm(Influx_Wide.query(iw_q4, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[4]['influx'].append(to_pm(Influx_Wide.query(iw_q5, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "    for n_s in [1] + [i for i in range(10, 101, 10)]:\n",
    "        results[0]['influx'].append(to_pm(Influx_Wide.query(iw_q1, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[1]['influx'].append(to_pm(Influx_Wide.query(iw_q2, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[2]['influx'].append(to_pm(Influx_Wide.query(iw_q3, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[3]['influx'].append(to_pm(Influx_Wide.query(iw_q4, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[4]['influx'].append(to_pm(Influx_Wide.query(iw_q5, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "    for r in [(1,'minute'), (1,'hour'), (1,'day'), (7,'day'), (30,'day')]:\n",
    "#     for r in [(30,'day')]:\n",
    "        results[0]['influx'].append(to_pm(Influx_Wide.query(iw_q1, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[1]['influx'].append(to_pm(Influx_Wide.query(iw_q2, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[2]['influx'].append(to_pm(Influx_Wide.query(iw_q3, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[3]['influx'].append(to_pm(Influx_Wide.query(iw_q4, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[4]['influx'].append(to_pm(Influx_Wide.query(iw_q5, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "    stop_sys('influx')\n",
    "\n",
    "def queryMonetDB():\n",
    "    start_sys('monetdb')\n",
    "    for i in range(5):\n",
    "        results[i][\"monetdb\"] = [] \n",
    "    for n_st in [1] + [i for i in range(2, 11, 2)]:\n",
    "        results[0]['monetdb'].append(to_pm(MonetDB.query(m_q1, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[1]['monetdb'].append(to_pm(MonetDB.query(m_q2, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[2]['monetdb'].append(to_pm(MonetDB.query(m_q3, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[3]['monetdb'].append(to_pm(MonetDB.query(m_q4, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[4]['monetdb'].append(None)\n",
    "    for n_s in [1] + [i for i in range(10, 101, 10)]:\n",
    "        results[0]['monetdb'].append(to_pm(MonetDB.query(m_q1, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[1]['monetdb'].append(to_pm(MonetDB.query(m_q2, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[2]['monetdb'].append(to_pm(MonetDB.query(m_q3, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[3]['monetdb'].append(to_pm(MonetDB.query(m_q4, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[4]['monetdb'].append(None)\n",
    "    for r in [(1,'minute'), (1,'hour'), (1,'day'), (7,'day'), (1,'month')]:\n",
    "#     for r in [(7,'day'), (1,'month')]:\n",
    "        results[0]['monetdb'].append(to_pm(MonetDB.query(m_q1, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[1]['monetdb'].append(to_pm(MonetDB.query(m_q2, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[2]['monetdb'].append(to_pm(MonetDB.query(m_q3, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[3]['monetdb'].append(to_pm(MonetDB.query(m_q4, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[4]['monetdb'].append(None)\n",
    "    stop_sys('monetdb')\n",
    "\n",
    "def queryQuestDB():\n",
    "    start_sys('questdb')\n",
    "    for i in range(5):\n",
    "        results[i][\"questdb\"] = [] \n",
    "    for n_st in [1] + [i for i in range(2, 11, 2)]:\n",
    "        results[0]['questdb'].append(to_pm(QuestDB.query(q_q1, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[1]['questdb'].append(to_pm(QuestDB.query(q_q2, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[2]['questdb'].append(to_pm(QuestDB.query(q_q3, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[3]['questdb'].append(to_pm(QuestDB.query(q_q4, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[4]['questdb'].append(to_pm(QuestDB.query(q_q5, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "    for n_s in [1] + [i for i in range(10, 101, 10)]:\n",
    "        results[0]['questdb'].append(to_pm(QuestDB.query(q_q1, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[1]['questdb'].append(to_pm(QuestDB.query(q_q2, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[2]['questdb'].append(to_pm(QuestDB.query(q_q3, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[3]['questdb'].append(to_pm(QuestDB.query(q_q4, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[4]['questdb'].append(to_pm(QuestDB.query(q_q5, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "    for r in ['minute', 'hour', 'day', 'week', 'month']:\n",
    "        results[0]['questdb'].append(to_pm(QuestDB.query(q_q1, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[1]['questdb'].append(to_pm(QuestDB.query(q_q2, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[2]['questdb'].append(to_pm(QuestDB.query(q_q3, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[3]['questdb'].append(to_pm(QuestDB.query(q_q4, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[4]['questdb'].append(to_pm(QuestDB.query(q_q5, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "    stop_sys('questdb')\n",
    "    \n",
    "\n",
    "def queryTimescaleDB():\n",
    "    start_sys('questdb')\n",
    "    for i in range(5):\n",
    "        results[i][\"timescaledb\"] = [] \n",
    "    for n_st in [1] + [i for i in range(2, 11, 2)]:\n",
    "        results[0]['timescaledb'].append(to_pm(TimescaleDB.query(t_q1, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[1]['timescaledb'].append(to_pm(TimescaleDB.query(t_q2, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[2]['timescaledb'].append(to_pm(TimescaleDB.query(t_q3, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[3]['timescaledb'].append(to_pm(TimescaleDB.query(t_q4, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "        results[4]['timescaledb'].append(to_pm(TimescaleDB.query(t_q5, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "    for n_s in [1] + [i for i in range(10, 101, 10)]:\n",
    "        results[0]['timescaledb'].append(to_pm(TimescaleDB.query(t_q1, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[1]['timescaledb'].append(to_pm(TimescaleDB.query(t_q2, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[2]['timescaledb'].append(to_pm(TimescaleDB.query(t_q3, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[3]['timescaledb'].append(to_pm(TimescaleDB.query(t_q4, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "        results[4]['timescaledb'].append(to_pm(TimescaleDB.query(t_q5, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "    for r in [(1,'minute'), (1,'hour'), (1,'day'), (7,'day'), (1,'month')]:\n",
    "        results[0]['timescaledb'].append(to_pm(TimescaleDB.query(t_q1, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[1]['timescaledb'].append(to_pm(TimescaleDB.query(t_q2, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[2]['timescaledb'].append(to_pm(TimescaleDB.query(t_q3, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[3]['timescaledb'].append(to_pm(TimescaleDB.query(t_q4, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "        results[4]['timescaledb'].append(to_pm(TimescaleDB.query(t_q5, r[0], r[1], n_it, n_st = def_st, n_s = def_s)))\n",
    "    stop_sys('questdb')\n",
    "\n",
    "def queryAll():\n",
    "    queryClickHouse()\n",
    "    queryDruidWide()\n",
    "    queryExtremeDB()\n",
    "    queryInflux()\n",
    "    queryInfluxWide()\n",
    "    queryMonetDB()\n",
    "    queryQuestDB()\n",
    "    queryTimescaleDB()\n",
    "    return results\n",
    "\n",
    "def start_sys(sys):\n",
    "    print('starting ', sys)\n",
    "    s = subprocess.getoutput(\"cd ../../Databases/\" + sys + '/; sudo sh launch.sh')\n",
    "#     s = subprocess.getoutput(\"cd ../../Databases/\" + sys + '/; sudo sh launch.sh')\n",
    "    return s\n",
    "\n",
    "def stop_sys(sys):\n",
    "    print('stopping ', sys)\n",
    "    s = subprocess.getoutput(\"cd ../../Databases/\" + sys + '/; sudo sh stop.sh')\n",
    "    for i in range(9,0,-1):\n",
    "        print(f\"{i}\", end=\"\\r\", flush=True)\n",
    "        time.sleep(1)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e4dfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sys_config = {\n",
    "#     \"clickhouse_hostname\" : \"localhost\",\n",
    "#     \"druid_hostname\" : \"localhost\",\n",
    "#     \"extreme_hostname\" : \"localhost\",\n",
    "#     \"influx_hostname\" : \"localhost\",\n",
    "#     \"monetdb_hostname\" : \"localhost\",\n",
    "#     \"questdb_hostname\" : \"localhost\",\n",
    "#     \"timescaledb_hostname\" : \"localhost\"\n",
    "# }\n",
    "# with open(\"sys_config.json\", \"w\") as jsonfile:\n",
    "#     jsonfile.write(json.dumps(sys_config))\n",
    "#     print(\"Write successful\")\n",
    "    \n",
    "# query_config = {\n",
    "#     \"seed\" : \"131\",\n",
    "#     \"number_stations\" : 10,\n",
    "#     \"number_sensors\" : 100,\n",
    "#     \"n_it\" : 100,\n",
    "#     \"def_st\" : 1,\n",
    "#     \"def_s\" : 3,\n",
    "#     \"def_r\" : \"day\",\n",
    "#     \"max_duration\" : 1,\n",
    "#     \"rangeUnit\" : \"day\"\n",
    "# }\n",
    "# with open(\"query_config.json\", \"w\") as jsonfile:\n",
    "#     jsonfile.write(json.dumps(query_config))\n",
    "#     print(\"Write successful\")\n",
    "    \n",
    "\n",
    "sys_config = json.load(open(\"sys_config.json\", \"r\"))\n",
    "query_config = json.load(open(\"query_config.json\", \"r\"))\n",
    "print(\"Read successful\")\n",
    "\n",
    "number_stations = query_config[\"number_stations\"]\n",
    "number_sensors = query_config[\"number_sensors\"]\n",
    "n_it = query_config[\"n_it\"]\n",
    "def_st = query_config[\"def_st\"]\n",
    "def_s = query_config[\"def_s\"]\n",
    "def_r = query_config[\"def_r\"]\n",
    "max_duration = query_config[\"max_duration\"]\n",
    "rangeUnit = query_config[\"rangeUnit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c9d2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(query_config['seed'])\n",
    "\n",
    "set_st = [str(random.randint(0,query_config['def_st'])) for i in range(500)]\n",
    "set_s = [str(random.randint(0,query_config['def_s'])) for i in range(500)]\n",
    "set_date = [random.random() for i in range(500)]\n",
    "\n",
    "\n",
    "results = [{} for i in range(5)]\n",
    "\n",
    "for i in range(5):\n",
    "    for sys in ['clickhouse', 'druid', 'extremedb', 'influx', 'monetdb', 'questdb', 'timescaledb']:\n",
    "        results[i][sys] = []\n",
    "        \n",
    "query1, query2, query3, query4, query5 = [{},{}],[{},{}],[{},{}],[{},{}],[{},{}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96bd9e",
   "metadata": {},
   "source": [
    "# ClickHouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cec060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple class\n",
    "# attribute\n",
    "\n",
    "c_q1 = \"\"\"select time, id_station, <sid> FROM d1_wide where id_station in <stid>\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "# c_q1 = \"\"\"select time, s<sid> FROM d1_wide where id_station='st<stid>'\n",
    "# AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "# AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "c_q2 = \"\"\"select time, id_station, <sid> FROM d1_wide where id_station in <stid>\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' and <sfilter>\"\"\" # s<sid> > 0.95;\n",
    "\n",
    "c_q3 = \"\"\"SELECT id_station, <avg_s> FROM d1_wide \n",
    "WHERE time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' \n",
    "AND id_station in <stid>\n",
    "GROUP BY id_station;\"\"\"   #avg(s<sid>)\n",
    "\n",
    "c_q4 = \"\"\"SELECT id_station, EXTRACT(YEAR FROM time) AS \"year\",\n",
    "date_trunc('month', time) AS \"month\", \n",
    "date_trunc('day', time) AS \"day\", \n",
    "date_trunc('hour', time) AS \"hour\", \n",
    "<avg_s> \n",
    "FROM d1_wide where  time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' \n",
    "AND id_station in <stid>\n",
    "GROUP BY id_station, \"year\", \"month\", \"day\", \"hour\";\"\"\" # AVG(s<sid>) AS avg_s<sid>\n",
    "\n",
    "c_q5 = \"\"\"select time, id_station, <sid> FROM d1_wide where id_station in <stid>\n",
    "\tAND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "\tAND time < TIMESTAMP '<timestamp>' ORDER BY\n",
    "\tid_station ASC,\n",
    "\ttime ASC WITH FILL STEP 5\n",
    "\tINTERPOLATE ( <sid>, id_station AS id_station );\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c04d54cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "from clickhouse_driver import connect as connect_ClickHouse\n",
    "\n",
    "class ClickHouse:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1, n_s = 10):\n",
    "#         client = Client('diufrm102')\n",
    "        conn = connect_ClickHouse(\"clickhouse://\" + sys_config[\"clickhouse_hostname\"])\n",
    "        cursor = conn.cursor()\n",
    "#         print(client.execute('SHOW TABLES'))\n",
    "#         return None, None\n",
    "        duration = max_d\n",
    "        results = [[],[]]       \n",
    "        runtimes = []\n",
    "        full_time = time.time()\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-04-01T00:00:00\", \"2019-04-30T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "#             temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            # st\n",
    "            li = ['st' + str(z) for z in random.sample(range(query_config[\"number_stations\"]), n_st)]\n",
    "            q = '(' + \"'\" + li[0] + \"'\"\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + \"'\" + j + \"'\"\n",
    "            q += \")\"\n",
    "            temp = temp.replace(\"<stid>\", q)\n",
    "            \n",
    "            # sensor\n",
    "            li = ['s' + str(z) for z in random.sample(range(query_config[\"number_sensors\"]), n_s)]\n",
    "            q = li[0]\n",
    "            q_filter = '(' + li[0] + ' > 0.95'\n",
    "            q_avg = 'avg(' + li[0] + ')'\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + j\n",
    "#                 q_filter += ' OR ' + j + ' > 0.95'\n",
    "                q_avg += ', ' + 'avg(' + j + ')'\n",
    "            temp = temp.replace(\"<sid>\", q)\n",
    "            temp = temp.replace(\"<sfilter>\", q_filter + ')')\n",
    "            temp = temp.replace(\"<avg_s>\", q_avg)\n",
    "            \n",
    "\n",
    "            start = time.time()\n",
    "#             print(temp)\n",
    "            cursor.execute(temp)\n",
    "    \n",
    "            cursor.fetchall()\n",
    "            diff = (time.time()-start)*1000\n",
    "#                 print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "            if time.time() - full_time > 20 and i > 5: \n",
    "                break              \n",
    "#             print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results[0], results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2f3d1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 19.61it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.69it/s]\n",
      " 63%|██████▎   | 63/100 [00:01<00:00, 54.11it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d55c94384a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqueryClickHouse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-5e8150407fc4>\u001b[0m in \u001b[0;36mqueryClickHouse\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clickhouse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClickHouse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clickhouse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClickHouse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_q2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clickhouse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClickHouse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_q3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clickhouse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClickHouse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_q4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clickhouse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClickHouse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_q5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-12beb822e5c4>\u001b[0m in \u001b[0;36mquery\u001b[0;34m(query, max_d, rangesUnit, n_it, n_st, n_s)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#             print(temp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/clickhouse_driver/dbapi/cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, parameters)\u001b[0m\n\u001b[1;32m    111\u001b[0m             response = execute(\n\u001b[1;32m    112\u001b[0m                 \u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_column_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mexecute_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/clickhouse_driver/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, params, with_column_types, external_tables, query_id, settings, types_check, columnar)\u001b[0m\n\u001b[1;32m    359\u001b[0m                     \u001b[0mexternal_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexternal_tables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0mquery_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtypes_check\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                     \u001b[0mcolumnar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumnar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m                 )\n\u001b[1;32m    363\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_elapsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/clickhouse_driver/client.py\u001b[0m in \u001b[0;36mprocess_ordinary_query\u001b[0;34m(self, query, params, with_column_types, external_tables, query_id, types_check, columnar)\u001b[0m\n\u001b[1;32m    550\u001b[0m                                              types_check=types_check)\n\u001b[1;32m    551\u001b[0m         return self.receive_result(with_column_types=with_column_types,\n\u001b[0;32m--> 552\u001b[0;31m                                    columnar=columnar)\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     def iter_process_ordinary_query(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/clickhouse_driver/client.py\u001b[0m in \u001b[0;36mreceive_result\u001b[0;34m(self, with_column_types, progress, columnar)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_column_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_column_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumnar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumnar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             )\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miter_receive_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_column_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/clickhouse_driver/result.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \"\"\"\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpacket\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpacket_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/clickhouse_driver/client.py\u001b[0m in \u001b[0;36mpacket_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mpacket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpacket\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/clickhouse_driver/client.py\u001b[0m in \u001b[0;36mreceive_packet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreceive_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mpacket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpacket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mServerPacketTypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/clickhouse_driver/connection.py\u001b[0m in \u001b[0;36mreceive_packet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mpacket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPacket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mpacket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacket_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_varint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpacket_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mServerPacketTypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mclickhouse_driver/varint.pyx\u001b[0m in \u001b[0;36mclickhouse_driver.varint.read_varint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mclickhouse_driver/bufferedreader.pyx\u001b[0m in \u001b[0;36mclickhouse_driver.bufferedreader.BufferedReader.read_one\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mclickhouse_driver/bufferedreader.pyx\u001b[0m in \u001b[0;36mclickhouse_driver.bufferedreader.BufferedSocketReader.read_into_buffer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "queryClickHouse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ClickHouse.query(c_q1, query_config[\"max_duration\"], query_config[\"rangeUnit\"], query_config[\"n_it\"], n_st = query_config[\"def_st\"], n_s = query_config[\"def_s\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb965d1",
   "metadata": {},
   "source": [
    "# Druid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e465b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#druid = Druid()\n",
    "\n",
    "# A simple class\n",
    "# attribute\n",
    "dw_q1 = \"\"\"select __time, id_station, <sid> FROM d1 where id_station in <stid>\n",
    "    and __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "    and __time < TIMESTAMP '<timestamp>'\"\"\"\n",
    "\n",
    "\n",
    "# dw_q1 = \"\"\"select __time, \"s<sid>\" FROM d1 where id_station = 'st<stid>' \n",
    "#     and __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "#     and __time < TIMESTAMP '<timestamp>'\"\"\"\n",
    "\n",
    "\n",
    "dw_q2 = \"\"\"SELECT __time, id_station, <sid> FROM d1 WHERE  id_station in <stid>\n",
    "    AND __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit>  \n",
    "    and __time < TIMESTAMP '<timestamp>' AND <sfilter>\"\"\" #\"s<sid>\"; \"s<sid>\" > 0.95\n",
    "\n",
    "dw_q3 = \"\"\"select id_station,<avg_s>  FROM d1 where __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \\\n",
    "    and __time < TIMESTAMP '<timestamp>' \n",
    "    AND id_station in <stid>\n",
    "    GROUP BY id_station\"\"\" #AVG(\"s<sid>\")\n",
    "\n",
    "dw_q4 = \"\"\"SELECT \"id_station\", TIME_EXTRACT(__time, 'YEAR')  AS \"yearP\",\n",
    "    TIME_EXTRACT(__time, 'MONTH') AS \"month\", \n",
    "    TIME_EXTRACT(__time, 'DAY') AS \"day\", \n",
    "    TIME_EXTRACT(__time, 'HOUR') AS \"hour\", \n",
    "    <avg_s> \n",
    "    FROM d1 where __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "    AND __time < TIMESTAMP '<timestamp>' \n",
    "    and id_station in <stid>\n",
    "    GROUP BY 1,2,3,4,5\"\"\"#AVG(\"s<sid>\") \n",
    "\n",
    "#druid = Druid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2d29a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydruid.client import *\n",
    "from pydruid.db import connect\n",
    "from pydruid.utils.aggregators import *\n",
    "from pydruid.utils.filters import *\n",
    "\n",
    "class Druid_Wide:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1, n_s = 10):\n",
    "        conn = connect(host=sys_config[\"druid_hostname\"], port=8082, path='/druid/v2/sql/', scheme='http')\n",
    "        curs = conn.cursor()\n",
    "#         curs.execute(\"select * FROM d1 where id_station in ('st5') and s='s14' and __time > TIMESTAMP '2019-03-04 00:00:00' - INTERVAL '1' DAY and __time < TIMESTAMP '2019-03-04 00:00:00' \")\n",
    "#         curs.fetchall()\n",
    "        results = [[],[]]\n",
    "        duration = max_d\n",
    "        runtimes = []\n",
    "        full_time = time.time()\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-04-01 00:00:00\", \"2019-04-30 00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%d %H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "#             temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "#             if n_st == 1: \n",
    "#                 temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "#             else: \n",
    "#                 li = ['st' + str(set_st[(duration*i)%500]) for i in range(n_st)]\n",
    "# #                     print(li)\n",
    "#                 q = '(' + \"'\" + li[0] + \"'\"\n",
    "#                 for i in li[1:]:\n",
    "#                     q += ',' + \"'\" + i + \"'\"\n",
    "#                 q += \")\"\n",
    "#                 temp = temp.replace(\"<stid>\", q)\n",
    "    \n",
    "            li = ['st' + str(z) for z in random.sample(range(number_stations), n_st)]\n",
    "            q = '(' + \"'\" + li[0] + \"'\"\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + \"'\" + j + \"'\"\n",
    "            q += \")\"\n",
    "            temp = temp.replace(\"<stid>\", q)\n",
    "            \n",
    "            # sensor\n",
    "            li = ['s' + str(z) for z in random.sample(range(number_sensors), n_s)]\n",
    "            q = li[0]\n",
    "            q_filter = '(' + li[0] + ' > 0.95'\n",
    "            q_avg = 'avg(' + li[0] + ')'\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + j\n",
    "#                 q_filter += ' OR ' + j + ' > 0.95'\n",
    "                q_avg += ', ' + 'avg(' + j + ')'\n",
    "            temp = temp.replace(\"<sid>\", q)\n",
    "            temp = temp.replace(\"<sfilter>\", q_filter + ')')\n",
    "            temp = temp.replace(\"<avg_s>\", q_avg)    \n",
    "#             print(temp)\n",
    "   \n",
    "            start = time.time()\n",
    "            curs.execute(temp)\n",
    "            curs.fetchall()\n",
    "            #print(temp, curs.rowcount)\n",
    "            diff = (time.time()-start)*1000\n",
    "            runtimes.append(diff)\n",
    "            if time.time() - full_time > 20 and i > 5: \n",
    "                break                  \n",
    "\n",
    "#                 print(temp, diff)\n",
    "        #print(runtimes)\n",
    "#         print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "#             results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results[0],results[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91b80142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting  druid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:02<00:21,  4.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a0bcf1a4593b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqueryDruid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Druid_Wide.query(dw_q1, query_config[\"max_duration\"], query_config[\"rangeUnit\"], query_config[\"n_it\"], n_st = query_config[\"def_st\"], n_s = query_config[\"def_s\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# # for st in range(2, 11, 2):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-aa4778bc2a5d>\u001b[0m in \u001b[0;36mqueryDruid\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"druid\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_st\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'druid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDruid_Wide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw_q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'druid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDruid_Wide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw_q2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'druid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDruid_Wide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw_q3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-2bc18734ad16>\u001b[0m in \u001b[0;36mquery\u001b[0;34m(query, max_d, rangesUnit, n_it, n_st, n_s)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mcurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mcurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;31m#print(temp, curs.rowcount)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydruid/db/api.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Called before `execute`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydruid/db/api.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;34m\"{klass} already closed\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydruid/db/api.py\u001b[0m in \u001b[0;36mfetchall\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0marraysize\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0mcan\u001b[0m \u001b[0maffect\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperformance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \"\"\"\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcheck_closed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydruid/db/api.py\u001b[0m in \u001b[0;36m_stream_query\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mRow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0mRow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Row\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(_cls, _0, id_station, s57, s80, s51)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_sys(\"druid\")\n",
    "queryDruid()\n",
    "stop_sys(\"druid\")\n",
    "# Druid_Wide.query(dw_q1, query_config[\"max_duration\"], query_config[\"rangeUnit\"], query_config[\"n_it\"], n_st = query_config[\"def_st\"], n_s = query_config[\"def_s\"])\n",
    "\n",
    "# # for st in range(2, 11, 2):\n",
    "# # for s in range(10, 101, 10):\n",
    "# for r in [\"minute\", \"hour\", \"day\", \"month]:\n",
    "#     print(Druid_Wide.query(dw_q4, max_duration[1], r, 2, n_st= 1 , n_s = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27fc749",
   "metadata": {},
   "source": [
    "# eXtremeDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb690017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple class\n",
    "# attribute\n",
    "# e_q1 = \"\"\"select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, s<sid>@tt FROM d1_v WHERE id_station = 'st<stid>';\"\"\"\n",
    "e_q1 = \"\"\"select id_station, seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, <sid> FROM d1_v WHERE id_station in <stid>;\"\"\"\n",
    "\n",
    "\n",
    "e_q2 = \"\"\"select id_station, tfe, <sidlist> from (\n",
    "select id_station, seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, <sfilter> as fe, t@fe as tfe, <sid_filtered> FROM d1_v WHERE id_station in <stid>\n",
    "); \"\"\" #!seq_filter_search(s<sid>@tt > 0.95, tt),. <sid>@fe \n",
    "\n",
    "e_q2AND = \"\"\"select id_station, seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, <sfilterAND> as fe, <sid_filtered> FROM d1_v WHERE id_station in <stid>; \"\"\" #!seq_filter_search(s<sid>@tt > 0.95, tt),. <sid>@fe \n",
    "\n",
    "\n",
    "e_q3 = \"\"\"SELECT id_station, ! seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, <seq_avg> FROM d1_v WHERE id_station in <stid>;\"\"\" # where id_station = 'st<stid>', <seq_avg>(<sid>@tt)\n",
    "\n",
    "\n",
    "e_q4 = \"\"\"select id_station, ts, <sidlist> from (\n",
    "select id_station, seq_search(t,<timestamp> - <nb> * <rangesUnit>, <timestamp>) as tt, seq_group_agg_avg(t@tt , t@tt/3600) as ts, <seq_group_agg_avg> FROM d1_v where id_station in <stid>\n",
    ");\"\"\" #seq_group_agg_avg(s<sid>@tt, t@tt/3600) \n",
    "\n",
    "\n",
    "e_q5 = \"\"\"select seq_aprogres_datetime(<timestamp> -  <nb> * <rangesUnit>, 5, <nb> * <rangesUnit>) as ts5, <seq_stretch> from d1_v where id_station in <stid>;\"\"\" #seq_stretch(ts5,t,s<sid>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXtremeDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1, n_s = 10):\n",
    "        # map the inputs to the function blocks\n",
    "        import exdb \n",
    "        import datetime\n",
    "        exdb.init_runtime(debug = False, shm = False, disk = False, tmgr = 'mursiw')\n",
    "        con = exdb.connect(sys_config[\"extremedb\"], 5001)\n",
    "        curs = con.cursor()\n",
    "        curs.execute(\"SELECT s23 FROM d1_v where id_station = 'st3'\")\n",
    "        curs.fetchall()\n",
    "        results = [[],[]]\n",
    "        options = {\"day\" : 60 * 60* 24,\n",
    "                   \"week\" : 60 * 60* 24 * 7,\n",
    "                   \"minute\" : 60,\n",
    "                   \"hour\" : 60 * 60,\n",
    "                   \"second\" : 1,\n",
    "                   \"month\" : 60 * 60 * 24 * 30,\n",
    "                   \"year\" :  60 * 60 * 24 * 30 * 12\n",
    "        }\n",
    "        duration = max_d\n",
    "        runtimes = []\n",
    "        full_time = time.time()\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-04-01 00:00:00\", \"2019-04-30 00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%d %H:%M:%S')\n",
    "            date = int(time.mktime(datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S').timetuple()))\n",
    "            temp = query.replace(\"<timestamp>\", str(date))\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "#             temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(options[rangesUnit]))\n",
    "        \n",
    "            li = ['st' + str(z) for z in random.sample(range(number_stations), n_st)]\n",
    "            q = '(' + \"'\" + li[0] + \"'\"\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + \"'\" + j + \"'\"\n",
    "            q += \")\"\n",
    "            temp = temp.replace(\"<stid>\", q)\n",
    "            \n",
    "            # sensor\n",
    "            rand = [str(z) for z in random.sample(range(number_sensors), n_s)]\n",
    "#             print(rand)\n",
    "            sidlist = 's' + rand[0]\n",
    "            for j in rand[1:]:\n",
    "                sidlist += ',' + 's' +  j\n",
    "#             print(sidlist)\n",
    "            li = ['s' + str(z) + \"@tt\" for z in rand]\n",
    "            li_filtered = ['s' + str(z) + \"@fe as s\" + str(z) for z in rand]\n",
    "#             <seq_group_agg_avg> seq_group_agg_avg(s<sid>@tt, t@tt/3600), \n",
    "#             <seq_stretch> #seq_stretch(ts5,t,s<sid>), \n",
    "#             <sfilter> !seq_filter_search(s<sid>@tt > 0.95, tt)\n",
    "            \n",
    "            q = li[0]\n",
    "            q_filtered = li_filtered[0] \n",
    "            q_seq_group_agg_avg = \"seq_group_agg_avg(\" + li[0] + \" , t@tt/3600) as \" + li[0].split('@')[0]\n",
    "            q_seq_avg = \"seq_avg(\" + li[0] + \")\" \n",
    "            q_seq_stretch = \"seq_stretch(ts5,t,\" + li[0].split('@')[0] + \")\" \n",
    "#             q_filter = \"!seq_filter_search(\" +li[0] + \"> 0.95, tt)\"\n",
    "            q_filter = \"!seq_filter_search(\" +li[0] + \"> 0.95\"\n",
    "            q_filterAND = \"!seq_filter_search(\" +li[0] + \"> 0.95\"\n",
    "            \n",
    "#             q_avg = 'avg(' + li[0] + ')'\n",
    "            for j in range(1,len(li_filtered)):\n",
    "                q_filtered += ', ' + li_filtered[j] \n",
    "    \n",
    "            for j in li[1:]:\n",
    "                q += ', ' + j\n",
    "                q_seq_avg += \", seq_avg(\" + j + \")\" \n",
    "                q_seq_group_agg_avg += \", seq_group_agg_avg(\" + j + \" , t@tt/3600)\" + \" as \" +  j.split('@')[0] #        li[0] + ' > 0.95'\n",
    "                q_seq_stretch += \", seq_stretch(ts5,t,\" + j.split('@')[0] + \")\" \n",
    "# #                 q_filter += \", !seq_filter_search(\" + j + \"> 0.95, tt)\"\n",
    "#                 q_filter += \" OR \" + j + \"> 0.95\"\n",
    "#                 q_filterAND += \" AND \" + j + \"> 0.95\"\n",
    "# #                 q_filter += ' OR ' + j + ' > 0.95'\n",
    "# #                 q_avg += ', ' + 'avg(' + j + ')'\n",
    "            temp = temp.replace(\"<sid>\", q)\n",
    "            temp = temp.replace(\"<sidlist>\", sidlist)\n",
    "            temp = temp.replace(\"<seq_avg>\", q_seq_avg)\n",
    "            temp = temp.replace(\"<sid_filtered>\", q_filtered)\n",
    "            temp = temp.replace(\"<seq_group_agg_avg>\", q_seq_group_agg_avg)\n",
    "            temp = temp.replace(\"<sfilter>\", q_filter + \", tt)\")\n",
    "            temp = temp.replace(\"<sfilterAND>\", q_filterAND + \", tt)\")\n",
    "            temp = temp.replace(\"<seq_stretch>\", q_seq_stretch)\n",
    "#             temp = temp.replace(\"<avg_s>\", q_avg)            \n",
    "        \n",
    "#             print(temp)\n",
    "            start = time.time()\n",
    "            curs.execute(temp)\n",
    "            curs.fetchall()\n",
    "            # print(curs.rowcount)\n",
    "#             print(curs.fetchall()[0])\n",
    "            diff = (time.time()-start)*1000\n",
    "#                 print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "            if time.time() - full_time > 20 and i > 5: \n",
    "                break  \n",
    "#         print(runtimes)\n",
    "#         print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        con.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EXtremeDB.query(e_q4, 1, \"day\", 2, n_st = 1, n_s = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d26ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for st in range(2, 11, 2):\n",
    "# for s in range(10, 101, 10):\n",
    "for r in [\"minute\", \"hour\", \"day\", \"week\", \"month\"]:\n",
    "    print(EXtremeDB.query(e_q2, 1, r, 2, n_st = 1, n_s = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43238efe",
   "metadata": {},
   "source": [
    "# Influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iw_q1 = \"\"\"\n",
    "    select time, id_station, <sid> FROM \"d1_wide\".\"autogen\".\"sensor\" \n",
    "    where <stid> \n",
    "    AND time > '<timestamp>Z' - <nb><rangesUnit> \n",
    "    AND  time < '<timestamp>Z'\n",
    "\"\"\"\n",
    "\n",
    "iw_q2 = \"\"\"\n",
    "    select time, id_station, <sid> FROM \"d1_wide\".\"autogen\".\"sensor\" \n",
    "    where <stid> \n",
    "    AND time > '<timestamp>Z' - <nb><rangesUnit> \n",
    "    AND  time < '<timestamp>Z' \n",
    "    and <sfilter>\n",
    "\"\"\" #s<sid>\n",
    "\n",
    "iw_q3 = \"\"\"\n",
    "    SELECT <avg_s> FROM \"d1_wide\".\"autogen\".\"sensor\" \n",
    "    WHERE  time > '<timestamp>Z' - <nb><rangesUnit> \n",
    "    AND time < '<timestamp>Z' \n",
    "    and <stid> \n",
    "    GROUP BY \"id_station\"  \n",
    "\"\"\"  #mean(s<sid>)\n",
    "\n",
    "iw_q4 = \"\"\"\n",
    "    SELECT first(id_station), <avg_s> FROM \"d1_wide\".\"autogen\".\"sensor\" \n",
    "    WHERE time > '<timestamp>Z' - <nb><rangesUnit> \n",
    "    and time < '<timestamp>Z' \n",
    "    and <stid> \n",
    "    GROUP BY id_station,time(1h)\n",
    "\"\"\" #mean(s<sid>)\n",
    "iw_q5 = \"\"\"\n",
    "    SELECT id_station, mean_value FROM (SELECT <avg_s> as mean_value FROM \"d1_wide\".\"autogen\".\"sensor\" \n",
    "    WHERE time > '<timestamp>Z' - <nb><rangesUnit> \n",
    "    AND time < '<timestamp>Z' \n",
    "    and <stid> \n",
    "    GROUP BY id_station,time(5s) FILL(0)) \n",
    "    GROUP BY id_station\n",
    "\"\"\" #mean(s<sid>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from influxdb import InfluxDBClient\n",
    "\n",
    "class Influx_Wide:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1, n_s = 10):\n",
    "        client = InfluxDBClient(host=sys_config[\"influx\"], port=8086, username='abdel')\n",
    "        results = [[],[]]\n",
    "        client.query(\"select * FROM \\\"d1\\\".\\\"autogen\\\".\\\"sensor\\\" where \\\"id_station\\\" ='st8' AND \\\"s\\\" ='s8' AND time > '2019-03-29T02:37:39Z' - 1d  AND  time < '2019-03-29T02:37:39Z'\")\n",
    "        \n",
    "        duration = max_d\n",
    "        runtimes = []\n",
    "        full_time = time.time()\n",
    "        for i in tqdm(range(n_it)):\n",
    "            date = random_date(\"2019-04-01T00:00:00\", \"2019-04-30T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit[0]))\n",
    "#             temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            \n",
    "            \n",
    "            \n",
    "            li = ['st' + str(z) for z in random.sample(range(number_stations), n_st)]\n",
    "#                     print(li)\n",
    "            q = '(id_station =' + \"'\" + li[0] + \"'\"\n",
    "            for j in li[1:]:\n",
    "                q += ' OR '  + 'id_station =' + \"'\" + j + \"'\"\n",
    "            q += \")\"\n",
    "            temp = temp.replace(\"<stid>\", q)\n",
    "            \n",
    "            \n",
    "            # sensor\n",
    "            li = ['s' + str(z) for z in random.sample(range(number_sensors), n_s)]\n",
    "            q = li[0]\n",
    "            q_filter = \"( \" + li[0] + ' > 0.95'\n",
    "            q_avg = 'mean(' + li[0] + ')'\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + j\n",
    "#                 q_filter += ' OR ' + j + ' > 0.95'\n",
    "                q_avg += ', ' + 'mean(' + j + ')'\n",
    "            temp = temp.replace(\"<sid>\", q)\n",
    "            temp = temp.replace(\"<sfilter>\", q_filter + \")\")\n",
    "            temp = temp.replace(\"<avg_s>\", q_avg)                \n",
    "            \n",
    "            \n",
    "            start = time.time()\n",
    "            result = client.query(temp)\n",
    "            diff = (time.time()-start)*1000\n",
    "#             print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "            if time.time() - full_time > 20 and i > 5: \n",
    "                break              \n",
    "#         print(temp)\n",
    "#             print(runtimes)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        client.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef33d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for st in range(2, 11, 2):\n",
    "# for s in range(10, 101, 10):\n",
    "for r in [\"minute\", \"hour\", \"day\", \"week\", \"month\"]:\n",
    "    print(Influx_Wide.query(iw_q2, 1, r, 2, n_st = 1, n_s = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951c954",
   "metadata": {},
   "source": [
    "# MonetDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m_q1 = \"\"\"select time, id_station, <sid> FROM d1 where id_station in <stid> \\\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \\\n",
    "AND time < TIMESTAMP '<timestamp>'\"\"\"\n",
    "# m_q1 = \"\"\"select time, s<sid> FROM d1 where id_station='st<stid>' \\\n",
    "# AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \\\n",
    "# AND time < TIMESTAMP '<timestamp>'\"\"\"\n",
    "m_q2 = \"\"\"select time, id_station, <sid> FROM d1 where id_station in <stid>\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' AND <sfilter>\"\"\"\n",
    "m_q3 = \"\"\"SELECT id_station, <avg_s> FROM d1 \n",
    "WHERE time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>'\n",
    "AND id_station in <stid>\n",
    "GROUP BY id_station\"\"\"\n",
    "m_q4 = \"\"\"SELECT id_station, EXTRACT(YEAR FROM time) AS \"year\",\n",
    "EXTRACT(MONTH FROM time) AS \"month\", \n",
    "EXTRACT(DAY FROM time) AS \"day\", \n",
    "EXTRACT(HOUR FROM time) \n",
    "AS \"hour\", <avg_s> \n",
    "FROM d1 where  time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>'\n",
    "AND id_station in <stid>\n",
    "GROUP BY id_station, \"year\", \"month\", \"day\", \"hour\" \"\"\"\n",
    "m_q5 = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46700c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymonetdb\n",
    "import time\n",
    "\n",
    "class MonetDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1, n_s = 10):\n",
    "        connection = pymonetdb.connect(username=\"monetdb\", port=54320, password=\"monetdb\", hostname=sys_config[\"monetdb\"], database=\"mydb\")\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"\"\"select time, s91 FROM d1 where id_station='st4' AND time > TIMESTAMP '2019-03-09T13:43:54' - INTERVAL '3' day AND time < TIMESTAMP '2019-03-09T13:43:54'\"\"\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        \n",
    "        duration = max_d\n",
    "        \n",
    "        runtimes = []\n",
    "        full_time = time.time()\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-04-01T00:00:00\", \"2019-04-30T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "            li = ['st' + str(z) for z in random.sample(range(number_stations), n_st)]\n",
    "            q = '(' + \"'\" + li[0] + \"'\"\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + \"'\" + j + \"'\"\n",
    "            q += \")\"\n",
    "            temp = temp.replace(\"<stid>\", q)\n",
    "            \n",
    "            # sensor\n",
    "            li = ['s' + str(z) for z in random.sample(range(number_sensors), n_s)]\n",
    "            q = li[0]\n",
    "            q_filter = \"(\" + li[0] + ' > 0.95'\n",
    "            q_avg = 'avg(' + li[0] + ')'\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + j\n",
    "#                 q_filter += ' OR ' + j + ' > 0.95'\n",
    "                q_avg += ', ' + 'avg(' + j + ')'\n",
    "            temp = temp.replace(\"<sid>\", q)\n",
    "            temp = temp.replace(\"<sfilter>\", q_filter + \")\")\n",
    "            temp = temp.replace(\"<avg_s>\", q_avg)\n",
    "            \n",
    "            start = time.time()\n",
    "            cursor.execute(temp)\n",
    "            cursor.fetchall()\n",
    "            diff = (time.time()-start)*1000\n",
    "            runtimes.append(diff)\n",
    "            if time.time() - full_time > 20 and i > 5: \n",
    "                break                   \n",
    "#                 print(temp, diff)\n",
    "#         print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        connection.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "MonetDB.query(m_q4, 1, \"hour\", 2, n_st = 2, n_s = 10)\n",
    "\n",
    "# # Druid_Wide.query(dw_q1, max_duration[1], 'minute', n_it, n_st= 3 , n_s = 3)\n",
    "\n",
    "# # for st in range(2, 11, 2):\n",
    "# # for s in range(10, 101, 10):\n",
    "# for r in [\"minute\", \"hour\", \"day\", \"month\"]:\n",
    "#     print(MonetDB.query(m_q4, max_duration[1], r, 2, n_st = 1, n_s = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a893e0",
   "metadata": {},
   "source": [
    "# QuestDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_q1 = \"\"\"select ts, s<sid> FROM d1 where id_station='st<stid>' AND  ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L \"\"\"\n",
    "q_q1 = \"\"\"\n",
    "    select ts, id_station, <sid> FROM d1 \n",
    "    where id_station in <stid>\n",
    "    AND  ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L \n",
    "\"\"\"\n",
    "q_q2 = \"\"\"\n",
    "    select ts, id_station, <sid> FROM d1 \n",
    "    where id_station in <stid>\n",
    "    AND  ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L \n",
    "    and <sfilter>;\n",
    "\"\"\"\n",
    "q_q3 = \"\"\"\n",
    "    SELECT id_station, <avg_s> FROM d1 \n",
    "    WHERE  ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L \n",
    "    AND id_station in <stid>\n",
    "    GROUP BY id_station;\n",
    "\"\"\"\n",
    "q_q4 = \"\"\"\n",
    "    SELECT id_station, ts, <avg_s> FROM d1 \n",
    "    WHERE ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L \n",
    "    AND id_station in <stid> \n",
    "    SAMPLE BY 1h;\n",
    "\"\"\"\n",
    "# q_q5 = \"\"\"SELECT id_station, ts, avg(s<sid>) FROM d1 WHERE ts IN '<timestamp>;<nb><rangesUnit>' SAMPLE BY 5s FILL(LINEAR) GROUP BY id_station,ts ORDER BY id_station, ts;\"\"\"\n",
    "q_q5 = \"\"\"\n",
    "    SELECT id_station, ts, <avg_s> FROM d1 \n",
    "    WHERE  ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L \n",
    "    AND id_station in <stid> \n",
    "    SAMPLE BY 5s FILL(LINEAR) \n",
    "    GROUP BY ts, id_station \n",
    "    ORDER BY ts;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QuestDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1, n_s = 10):\n",
    "        import psycopg2\n",
    "        import time\n",
    "        connection = psycopg2.connect(user=\"admin\",\n",
    "                                          password=\"quest\",\n",
    "                                          host=sys_config[\"questdb\"],\n",
    "                                          port=\"8812\",\n",
    "                                          database=\"d1\")\n",
    "        options = {\"day\" : 60 * 60* 24,\n",
    "                   \"week\" : 60 * 60* 24 * 7,\n",
    "                   \"minute\" : 60,\n",
    "                   \"hour\" : 60 * 60,\n",
    "                   \"second\" : 1,\n",
    "                   \"month\" : 60 * 60 * 24 * 30,\n",
    "                   \"year\" :  60 * 60 * 24 * 30 * 12\n",
    "        }\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select ts, s9 FROM d1 where id_station='st4' AND ts IN '2019-03-23;1d'\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        \n",
    "        duration = max_d\n",
    "        \n",
    "        runtimes = []\n",
    "        full_time = time.time()\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-04-01\", \"2019-04-30\", set_date[(duration*i)%500], dform = '%Y-%m-%d')\n",
    "            temp = query.replace(\"<timestamp>\", date+'T12:15')\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(options[rangesUnit]))\n",
    "            \n",
    "            li = ['st' + str(z) for z in random.sample(range(number_stations), n_st)]\n",
    "            q = '(' + \"'\" + li[0] + \"'\"\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + \"'\" + j + \"'\"\n",
    "            q += \")\"\n",
    "            temp = temp.replace(\"<stid>\", q)\n",
    "            \n",
    "            # sensor\n",
    "            li = ['s' + str(z) for z in random.sample(range(number_sensors), n_s)]\n",
    "            q = li[0]\n",
    "            q_filter = \"(\" + li[0] + ' > 0.95'\n",
    "            q_avg = 'avg(' + li[0] + ')'\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + j\n",
    "#                 q_filter += ' OR ' + j + ' > 0.95'\n",
    "                q_avg += ', ' + 'avg(' + j + ')'\n",
    "            temp = temp.replace(\"<sid>\", q)\n",
    "            temp = temp.replace(\"<sfilter>\", q_filter + \")\")\n",
    "            temp = temp.replace(\"<avg_s>\", q_avg)\n",
    "            \n",
    "            start = time.time()\n",
    "#             print(temp)\n",
    "            cursor.execute(temp)\n",
    "            #print(temp, cursor.rowcount)\n",
    "            #print(len)\n",
    "            diff = (time.time()-start)*1000\n",
    "            cursor.fetchall()\n",
    "#             print(diff)\n",
    "#                 print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "            if time.time() - full_time > 20 and i > 5: \n",
    "                break                 \n",
    "#         print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             print(runtimes)\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        connection.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Druid_Wide.query(dw_q1, max_duration[1], 'minute', n_it, n_st= 3 , n_s = 3)\n",
    "\n",
    "# # for st in range(2, 11, 2):\n",
    "# # for s in range(10, 101, 10):\n",
    "# for r in [\"minute\", \"hour\", \"day\", \"week\", \"month\"]:\n",
    "#     print(QuestDB.query(q_q5, 1, r, 2, n_st = 1, n_s = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68c136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44bbc4c8",
   "metadata": {},
   "source": [
    "# TimescaleDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_q1 = \"\"\"select time, id_station, <sid> FROM d1 where id_station in <stid>\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "# t_q1 = \"\"\"select time, s<sid> FROM d1 where id_station='st<stid>'\n",
    "# AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "# AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "t_q2 = \"\"\"select time, id_station, <sid> FROM d1 where id_station in <stid>\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' and <sfilter>;\"\"\"\n",
    "\n",
    "t_q3 = \"\"\"SELECT id_station, <avg_s> FROM d1 \n",
    "WHERE time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' \n",
    "AND id_station in <stid>\n",
    "GROUP BY id_station;\"\"\"\n",
    "\n",
    "t_q4 = \"\"\"SELECT id_station, EXTRACT(YEAR FROM time) AS \"year\",\n",
    "date_trunc('month', time) AS \"month\", \n",
    "date_trunc('DAY', time) AS \"day\", \n",
    "date_trunc('HOUR', time) AS \"hour\", \n",
    "<avg_s>\n",
    "FROM d1 where  time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' \n",
    "AND id_station in <stid>\n",
    "GROUP BY id_station, \"year\", \"month\", \"day\", \"hour\";\"\"\"\n",
    "\n",
    "t_q5 = \"\"\"SELECT\n",
    "  time_bucket_gapfill('5 second', time) AS NEWTIME,\n",
    "  id_station,\n",
    "  <avg_s>,\n",
    "  <interpolate_avg>\n",
    "FROM d1\n",
    "WHERE time < '<timestamp>' AND time > timestamp '<timestamp>' - interval '<nb> <rangesUnit>'\n",
    "AND id_station in <stid> \n",
    "GROUP BY NEWTIME, id_station\n",
    "ORDER BY NEWTIME;\"\"\" # interpolate(avg(s<sid>))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimescaleDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1, n_s = 10):\n",
    "        import psycopg2\n",
    "        CONNECTION = \"postgres://postgres:postgres@\" + sys_config[\"timescaledb\"] + \":5432/postgres\"\n",
    "        conn = psycopg2.connect(CONNECTION)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select time, s4 FROM d1 where id_station='st1' AND time > TIMESTAMP '2019-03-06T16:57:36' - INTERVAL '1' day AND time < TIMESTAMP '2019-03-06T16:57:36';\")\n",
    "        cursor.fetchall()\n",
    "#         cursor.execute(\"set jit = off;\")\n",
    "        results = [[],[]]\n",
    "        \n",
    "        duration = max_d\n",
    "        \n",
    "        \n",
    "        runtimes = []\n",
    "        full_time = time.time()\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-04-01T00:00:00\", \"2019-04-30T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "            \n",
    "            li = ['st' + str(z) for z in random.sample(range(number_stations), n_st)]\n",
    "            q = '(' + \"'\" + li[0] + \"'\"\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + \"'\" + j + \"'\"\n",
    "            q += \")\"\n",
    "            temp = temp.replace(\"<stid>\", q)\n",
    "            \n",
    "            # sensor\n",
    "            li = ['s' + str(z) for z in random.sample(range(number_sensors), n_s)]\n",
    "            q = li[0]\n",
    "            q_filter = \"(\" + li[0] + ' > 0.95'\n",
    "            q_interpolate_avg = 'interpolate(avg(' + li[0] + '))'\n",
    "            q_avg = 'avg(' + li[0] + ')'\n",
    "            for j in li[1:]:\n",
    "                q += ', ' + j\n",
    "#                 q_filter += ' OR ' + j + ' > 0.95'\n",
    "                q_avg += ', ' + 'avg(' + j + ')'\n",
    "                q_interpolate_avg += ', interpolate(avg(' + j + '))'\n",
    "\n",
    "            temp = temp.replace(\"<sid>\", q)\n",
    "            temp = temp.replace(\"<sfilter>\", q_filter + \")\")\n",
    "            temp = temp.replace(\"<interpolate_avg>\", q_interpolate_avg)\n",
    "            temp = temp.replace(\"<avg_s>\", q_avg)\n",
    "\n",
    "            start = time.time()\n",
    "#             print(temp)\n",
    "            cursor.execute(temp)\n",
    "            cursor.fetchall()\n",
    "            diff = (time.time()-start)*1000\n",
    "#             print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "            if time.time() - full_time > 20 and i > 5: \n",
    "                break                \n",
    "#         print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e6f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TimescaleDB.query(t_q4, 1, r, 2, n_st = 1, n_s = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486ad10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for st in range(2, 11, 2):\n",
    "# for s in range(10, 101, 10):\n",
    "for r in [\"minute\", \"hour\", \"day\", \"week\", \"month\"]:\n",
    "    print(TimescaleDB.query(t_q5, 1, r, 2, n_st = 1, n_s = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "res.append([str(round(i[0], 2)) for i in TimescaleDB.query(t_q1, max_duration[1], rangesUnit[1], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in TimescaleDB.query(t_q2, max_duration[2], rangesUnit[2], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in TimescaleDB.query(t_q3, max_duration[3], rangesUnit[3], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in TimescaleDB.query(t_q4, max_duration[4], rangesUnit[4], n_it, n_st = 5)])\n",
    "res.append([str(round(i[0], 2)) for i in TimescaleDB.query(t_q5, max_duration[5], rangesUnit[5], n_it, n_st = 5)])\n",
    "\n",
    "s = ''\n",
    "for r in res: \n",
    "    s += r[0] + \"$\\\\pm$\" + r[1] + '\\t&\\t'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca7ff1",
   "metadata": {},
   "source": [
    "# Run all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_pm(ClickHouse.query(c_q1, 7, \"day\", 5, n_st = 1, n_s = 10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4509ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_pm(EXtremeDB.query(e_q1, 7, \"day\", 5, n_st = 1, n_s = 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d065d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac5386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1] + [i for i in range(10, 101, 10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c0df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ad24f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TimescaleDB.query(t_q5, 7, \"day\", 100, n_st = 1, n_s = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Influx_Wide.query(iw_q5, 1, 'month', 5, n_st = def_st, n_s = def_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7d12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8155b23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_program = time.time()\n",
    "# results = queryAll(duration_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d9bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queryClickHouse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99402ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queryDruid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fee07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queryExtremeDB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce00d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queryInflux()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66675a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "queryMonetDB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea7e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queryQuestDB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed07292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queryTimescaleDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = queryAllClickHouse(duration_range)\n",
    "# results = queryAllClickHouse(duration_range)\n",
    "stop_program = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Benchmark Runtime: %s minutes' % str((stop_program - start_program)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f7250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(results[4]['timescaledb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ff42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in results[0].items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc06c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(results)):\n",
    "    results[i][\"none\"] = [\"0.0$\\pm$0.0\" for i in range(22)]\n",
    "    results[i][\"none2\"] = [\"0.0$\\pm$0.0\" for i in range(22)]\n",
    "    results[i][\"none3\"] = [\"0.0$\\pm$0.0\" for i in range(22)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_5(x):\n",
    "    x = [i for i in x if i == i]\n",
    "    # print(x)\n",
    "    x = np.array(x)\n",
    "    # x -= x.min()\n",
    "    x /= x.max()\n",
    "    # print(list(x))\n",
    "    # x = 1-x\n",
    "    # x *= 4\n",
    "    # x += 1\n",
    "    # print(list(x))\n",
    "    # x /= 5\n",
    "    # x = 1 - x\n",
    "    # print(list(x))\n",
    "    x = -1*np.log(x)+1\n",
    "    x /= x.max()\n",
    "    x *= 5\n",
    "    # print(x)\n",
    "    x = np.rint(x)\n",
    "    x = x.astype(int)\n",
    "    return list(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3994fc",
   "metadata": {},
   "source": [
    "results[0] = { k: results[0][k] for k in [\"clickhouse\",\"druid_wide\",\"extremedb\",\"influx\", \"influx_wide\", \"monetdb\",\"questdb\",\"timescaledb\"] }\n",
    "results[1] = { k: results[1][k] for k in [\"clickhouse\",\"druid_wide\",\"extremedb\",\"influx\", \"influx_wide\", \"monetdb\",\"questdb\",\"timescaledb\"] }\n",
    "results[2] = { k: results[2][k] for k in [\"clickhouse\",\"druid_wide\",\"extremedb\",\"influx\", \"influx_wide\", \"monetdb\",\"questdb\",\"timescaledb\"] }\n",
    "results[3] = { k: results[3][k] for k in [\"clickhouse\",\"druid_wide\",\"extremedb\",\"influx\", \"influx_wide\", \"monetdb\",\"questdb\",\"timescaledb\"] }\n",
    "results[4] = { k: results[4][k] for k in ['extremedb', \"influx\", \"influx_wide\", 'questdb', 'timescaledb'] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879b9e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "systems_to_plot = ['clickhouse',  'druid', 'extremedb', 'influx', 'monetdb', 'questdb', 'timescaledb']\n",
    "# systems_to_plot = ['clickhouse',  'druid', 'extremedb', 'none2', 'none3', 'questdb', 'timescaledb']\n",
    "\n",
    "# colors = {'clickhouse': \"#584A9D\", 'druid': \"#CF3650\", 'extremedb': \"#9966CC\", 'influx': \"green\", 'monetdb': \"#915C83\", 'questdb': \"#3D2B1F\", 'timescaledb': \"orange\"}\n",
    "for i in tqdm(range(len(results))): \n",
    "# for i in [1]: \n",
    "    print('query ', i+1)\n",
    "    font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "    matplotlib.rc('font', **font)    \n",
    "    \n",
    "    plt.figure(figsize=(30,6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.suptitle('Query ' + str(i+1) +  '; default: Station = 1, Sensor = 10, Range = ' + str(def_r) + ';')\n",
    "\n",
    "    res = {s: results[i][s] for s in systems_to_plot}\n",
    "    \n",
    "    df_all = pd.DataFrame(res)\n",
    "    df_all.index = [1] + [i for i in range(2, 11, 2)] + [1] + [i for i in range(10, 101, 10)] + [\"minute\", \"hour\", \"day\", \"week\", \"month\"]\n",
    "#     df_all.style.highlight_max(color = 'lightgreen', axis = 1)\n",
    "#     print(df_all)\n",
    "#     print('problematic: ')\n",
    "#     for col in df_all: \n",
    "#         temp = df_all[df_all[col].str.split('$').str[2].astype(float) / df_all[col].str.split('$').str[0].astype(float) > 0.3]\n",
    "#         if not temp.empty: print(temp, col)\n",
    "    \n",
    "    df = df_all[:6]\n",
    "#     print(df)\n",
    "#     df.index = [1] + [i for i in range(2, 11, 2)]\n",
    "    df_runtime = df.copy()\n",
    "    df_variance = df.copy()\n",
    "    for col in df: \n",
    "        df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "        df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#         df_runtime[col].plot(logy = True, marker='o', logx = False, xticks = df_runtime.index, title = \"Query \" + str(i+1), xlabel = \"# Stations\", ylabel = \"Runtime (ms)\")\n",
    "        plt.errorbar(df_runtime[col].index, df_runtime[col], linewidth=4, elinewidth=2, markeredgewidth=2, yerr=df_variance[col], marker='o') #, color = colors[col])\n",
    "    print(df_runtime)\n",
    "#     plt.yscale('log')\n",
    "#     plt.title(\"Query \" + str(i+1))\n",
    "    plt.ylabel(\"Runtime (ms)\")\n",
    "    plt.xlabel(\"# Stations\")\n",
    "#     plt.legend(['clickhouse', 'druid', 'extremedb', 'influx', 'monetdb', 'questdb', 'timescaledb'], loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "    print('stations')\n",
    "    print(list(scale_to_5(df_runtime.iloc[0])))\n",
    "    print(list(scale_to_5(df_runtime.iloc[-1])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    df = df_all[6:17]\n",
    "#     df.index = [1] + [i for i in range(10, 101, 10)]\n",
    "    df_runtime = df.copy()\n",
    "    df_variance = df.copy()\n",
    "    for col in df: \n",
    "        df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "        df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#         df_runtime[col].plot(logy = True, marker='o', logx = False, xticks = df_runtime.index, title = \"Query \" + str(i+1), xlabel = \"# Stations\", ylabel = \"Runtime (ms)\")\n",
    "        plt.errorbar(df_runtime[col].index, df_runtime[col], linewidth=4, elinewidth=2, markeredgewidth=2, yerr=df_variance[col], marker='o') #, color = colors[col])\n",
    "    print(df_runtime)\n",
    "#     plt.yscale('log')\n",
    "#     plt.xscale('log')\n",
    "#     plt.title(\"Query \" + str(i+1))\n",
    "    plt.ylabel(\"Runtime (ms)\")\n",
    "    plt.xlabel(\"# Sensors\")\n",
    "#     plt.legend(['clickhouse', 'druid', 'extremedb', 'influx', 'monetdb', 'questdb', 'timescaledb'], loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "    print('sensors')\n",
    "    print(list(scale_to_5(df_runtime.iloc[0])))\n",
    "    print(list(scale_to_5(df_runtime.iloc[-1])))\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    df = df_all[17:22]\n",
    "#     df.index = [\"minute\", \"hour\", \"day\", \"week\", \"month\"]\n",
    "    df_runtime = df.copy()\n",
    "    df_variance = df.copy()\n",
    "    for col in df: \n",
    "        df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "        df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#         df_runtime[col].plot(logy = True, marker='o', logx = False, xticks = df_runtime.index, title = \"Query \" + str(i+1), xlabel = \"# Stations\", ylabel = \"Runtime (ms)\")\n",
    "        plt.errorbar(df_runtime[col].index, df_runtime[col], linewidth=4, elinewidth=2, markeredgewidth=2, yerr=df_variance[col], marker='o') #, color = colors[col])\n",
    "    plt.xticks(range(0,len(df_runtime.index)), df_runtime.index)\n",
    "\n",
    "    print('range')\n",
    "    print(df_runtime)\n",
    "    print(list(scale_to_5(df_runtime.iloc[0])))\n",
    "    print(list(scale_to_5(df_runtime.iloc[-1])))\n",
    "    \n",
    "#     print(list(df_runtime.iloc[0] / df_runtime.iloc[0].max()))\n",
    "#     print(5 - df_runtime.iloc[0] / df_runtime.iloc[0].max() * 5  )\n",
    "#     print(5 - df_runtime.iloc[-1] / df_runtime.iloc[-1].max() * 5  )\n",
    "#     plt.yscale('log')\n",
    "#     plt.title(\"Query \" + str(i+1))\n",
    "    plt.ylabel(\"Runtime (ms)\")\n",
    "    plt.xlabel(\"Range\")\n",
    "    plt.legend(systems_to_plot, loc='upper left', bbox_to_anchor=(0.9, 1))\n",
    "    plt.savefig('query' + str(i+1) +'.pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "#     print('query', i+1)\n",
    "#     df = pd.DataFrame(results[i])[3:6]\n",
    "#     df.index = [1,10,100]\n",
    "#     df_runtime = df.copy()\n",
    "#     df_variance = df.copy()\n",
    "#     for col in df: \n",
    "#         df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "#         df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#     print(df_runtime)\n",
    "#     df_runtime.plot(logy = True, marker='o', logx = True, xticks = df_runtime.index, title = \"Query \" + str(i+1), xlabel = \"# Sensors\", ylabel = \"Runtime (ms)\")\n",
    "#     print(df_variance)\n",
    "#     print()\n",
    "\n",
    "#     print('query', i+1)\n",
    "#     df = pd.DataFrame(results[i])[6:]\n",
    "#     df.index = [\"minute\", \"hour\", \"day\", \"week\", \"month\"]\n",
    "#     df_runtime = df.copy()\n",
    "#     df_variance = df.copy()\n",
    "#     for col in df: \n",
    "#         df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "#         df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#     print(df_runtime)\n",
    "#     df_runtime.plot(logy = True, marker='o', title = \"Query \" + str(i+1), xlabel = \"Range\", ylabel = \"Runtime (ms)\")\n",
    "#     plt.xticks(range(0,len(df_runtime.index)), df_runtime.index)\n",
    "#     print(df_variance)\n",
    "#     print()\n",
    "\n",
    "                \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def to_latex(df):\n",
    "    cols = df.columns\n",
    "    rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        l = row.tolist()\n",
    "#         for i in range(len(l)): \n",
    "#             if l[i]: \n",
    "#                 l[i] = float(l[i].split('$')[0])\n",
    "        l_sorted = sorted(l, key=lambda x: float('inf') if x is None else float(x.split('$')[0]))\n",
    "        l[l.index(l_sorted[0])] = '\\\\textbf{'+ str(l[l.index(l_sorted[0])]) + '$^{I}$}'\n",
    "        l[l.index(l_sorted[1])] = '\\\\textbf{'+ str(l[l.index(l_sorted[1])]) + '$^{II}$}'\n",
    "#         print(l)\n",
    "        rows.append(l)\n",
    "#     print(rows)\n",
    "    df = pd.DataFrame(np.array(rows),\n",
    "                   columns=cols, index= df.index)  \n",
    "    return df\n",
    "    return df.to_latex(index=False,\n",
    "            header=cols,\n",
    "            escape=False)                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_5(x):\n",
    "    x = [i for i in x if i == i]\n",
    "    # print(x)\n",
    "    x = np.array(x)\n",
    "    # x -= x.min()\n",
    "    x /= x.max()\n",
    "    # print(list(x))\n",
    "    # x = 1-x\n",
    "    # x *= 4\n",
    "    # x += 1\n",
    "    # print(list(x))\n",
    "    # x /= 5\n",
    "    # x = 1 - x\n",
    "    # print(list(x))\n",
    "    x = -1*np.log(x)+1\n",
    "    x /= x.max()\n",
    "    x *= 5\n",
    "    # print(x)\n",
    "    x = np.rint(x)\n",
    "    x = x.astype(int)\n",
    "    return list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a6d2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(results))): \n",
    "for i in tqdm(range(5)): \n",
    "    print('query ', i+1)\n",
    "    df_all = pd.DataFrame(results[i])\n",
    "    df_all.index = [1] + [i for i in range(2, 11, 2)] + [1] + [i for i in range(10, 101, 10)] + [\"minute\", \"hour\", \"day\", \"week\", \"month\"]\n",
    "    print(to_latex(df_all))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2404af61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "import matplotlib\n",
    "\n",
    "systems_to_plot = ['clickhouse', 'extremedb', 'monetdb']\n",
    "\n",
    "# colors = {'clickhouse': \"#584A9D\", 'druid': \"#CF3650\", 'extremedb': \"#9966CC\", 'influx': \"green\", 'monetdb': \"#915C83\", 'questdb': \"#3D2B1F\", 'timescaledb': \"orange\"}\n",
    "for i in tqdm(range(len(results))): \n",
    "    print('query ', i+1)\n",
    "    font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "    matplotlib.rc('font', **font)    \n",
    "    \n",
    "    plt.figure(figsize=(30,6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.suptitle('Query ' + str(i+1) +  '; default: Station = 1, Sensor = 10, Range = hour;')\n",
    "\n",
    "\n",
    "    df_all = pd.DataFrame(results[i])\n",
    "    df_all.index = [1] + [i for i in range(2, 11, 2)] + [1] + [i for i in range(10, 101, 10)] + [\"minute\", \"hour\", \"day\", \"week\", \"month\"]\n",
    "#     df_all.style.highlight_max(color = 'lightgreen', axis = 1)\n",
    "#     print(df_all)\n",
    "#     print('problematic: ')\n",
    "#     for col in df_all: \n",
    "#         temp = df_all[df_all[col].str.split('$').str[2].astype(float) / df_all[col].str.split('$').str[0].astype(float) > 0.3]\n",
    "#         if not temp.empty: print(temp, col)\n",
    "    \n",
    "    df = df_all[:6]\n",
    "#     df.index = [1] + [i for i in range(2, 11, 2)]\n",
    "    df_runtime = df.copy()\n",
    "    df_variance = df.copy()\n",
    "    for col in systems_to_plot: \n",
    "        df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "        df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#         df_runtime[col].plot(logy = True, marker='o', logx = False, xticks = df_runtime.index, title = \"Query \" + str(i+1), xlabel = \"# Stations\", ylabel = \"Runtime (ms)\")\n",
    "        plt.errorbar(df_runtime[col].index, df_runtime[col], linewidth=4, elinewidth=2, markeredgewidth=2, yerr=df_variance[col], marker='o') #, color = colors[col])\n",
    "    print(list(scale_to_5(df_runtime.iloc[0])))\n",
    "    print(list(scale_to_5(df_runtime.iloc[-1])))\n",
    "#     plt.yscale('log')\n",
    "#     plt.title(\"Query \" + str(i+1))\n",
    "    plt.ylabel(\"Runtime (ms)\")\n",
    "    plt.xlabel(\"# Stations\")\n",
    "#     plt.legend(['clickhouse', 'druid', 'extremedb', 'influx', 'monetdb', 'questdb', 'timescaledb'], loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "    print()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    df = df_all[6:17]\n",
    "#     df.index = [1] + [i for i in range(10, 101, 10)]\n",
    "    df_runtime = df.copy()\n",
    "    df_variance = df.copy()\n",
    "    for col in systems_to_plot: \n",
    "        df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "        df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#         df_runtime[col].plot(logy = True, marker='o', logx = False, xticks = df_runtime.index, title = \"Query \" + str(i+1), xlabel = \"# Stations\", ylabel = \"Runtime (ms)\")\n",
    "        plt.errorbar(df_runtime[col].index, df_runtime[col], linewidth=4, elinewidth=2, markeredgewidth=2, yerr=df_variance[col], marker='o') #, color = colors[col])\n",
    "#     plt.yscale('log')\n",
    "#     plt.xscale('log')\n",
    "#     plt.title(\"Query \" + str(i+1))\n",
    "    print(list(scale_to_5(df_runtime.iloc[0])))\n",
    "    print(list(scale_to_5(df_runtime.iloc[-1])))\n",
    "    plt.ylabel(\"Runtime (ms)\")\n",
    "    plt.xlabel(\"# Sensors\")\n",
    "#     plt.legend(['clickhouse', 'druid', 'extremedb', 'influx', 'monetdb', 'questdb', 'timescaledb'], loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    df = df_all[17:22]\n",
    "#     df.index = [\"minute\", \"hour\", \"day\", \"week\", \"month\"]\n",
    "    df_runtime = df.copy()\n",
    "    df_variance = df.copy()\n",
    "    for col in systems_to_plot: \n",
    "        df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "        df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#         df_runtime[col].plot(logy = True, marker='o', logx = False, xticks = df_runtime.index, title = \"Query \" + str(i+1), xlabel = \"# Stations\", ylabel = \"Runtime (ms)\")\n",
    "        plt.errorbar(df_runtime[col].index, df_runtime[col], linewidth=4, elinewidth=2, markeredgewidth=2, yerr=df_variance[col], marker='o') #, color = colors[col])\n",
    "    print(list(scale_to_5(df_runtime.iloc[0])))\n",
    "    print(list(scale_to_5(df_runtime.iloc[-1])))\n",
    "    plt.xticks(range(0,len(df_runtime.index)), df_runtime.index)\n",
    "#     plt.yscale('log')\n",
    "#     plt.title(\"Query \" + str(i+1))\n",
    "    plt.ylabel(\"Runtime (ms)\")\n",
    "    plt.xlabel(\"Range\")\n",
    "    plt.legend(systems_to_plot, loc='upper left', bbox_to_anchor=(0.9, 1))\n",
    "    plt.savefig('query' + str(i+1) +'.pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "#     print('query', i+1)\n",
    "#     df = pd.DataFrame(results[i])[3:6]\n",
    "#     df.index = [1,10,100]\n",
    "#     df_runtime = df.copy()\n",
    "#     df_variance = df.copy()\n",
    "#     for col in df: \n",
    "#         df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "#         df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#     print(df_runtime)\n",
    "#     df_runtime.plot(logy = True, marker='o', logx = True, xticks = df_runtime.index, title = \"Query \" + str(i+1), xlabel = \"# Sensors\", ylabel = \"Runtime (ms)\")\n",
    "#     print(df_variance)\n",
    "#     print()\n",
    "\n",
    "#     print('query', i+1)\n",
    "#     df = pd.DataFrame(results[i])[6:]\n",
    "#     df.index = [\"minute\", \"hour\", \"day\", \"week\", \"month\"]\n",
    "#     df_runtime = df.copy()\n",
    "#     df_variance = df.copy()\n",
    "#     for col in df: \n",
    "#         df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "#         df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#     print(df_runtime)\n",
    "#     df_runtime.plot(logy = True, marker='o', title = \"Query \" + str(i+1), xlabel = \"Range\", ylabel = \"Runtime (ms)\")\n",
    "#     plt.xticks(range(0,len(df_runtime.index)), df_runtime.index)\n",
    "#     print(df_variance)\n",
    "#     print()\n",
    "\n",
    "                \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d37001",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = []\n",
    "click = []\n",
    "for r in ['minute', 'hour', 'day', 'week', 'month']:\n",
    "#     ex.append(to_pm(EXtremeDB.query(e_q1, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "#     ex.append(to_pm(EXtremeDB.query(e_q2, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "#     ex.append(to_pm(EXtremeDB.query(e_q3, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "    ex.append(to_pm(EXtremeDB.query(e_q3, 1, r, n_it, n_st = 1, n_s = 100)))\n",
    "#     ex.append(to_pm(EXtremeDB.query(e_q5, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "for r in ['minute', 'hour', 'day', 'week', 'month']:\n",
    "# #     click.append(to_pm(ClickHouse.query(c_q1, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "# #     click.append(to_pm(ClickHouse.query(c_q2, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "    click.append(to_pm(ClickHouse.query(c_q3, 1, r, n_it, n_st = 1, n_s = 100)))\n",
    "#     click.append(to_pm(ClickHouse.query(c_q4, 1, r, n_it, n_st = def_st, n_s = def_s)))\n",
    "# #     click.append(to_pm(ClickHouse.query(c_q5, 1, r, n_it, n_st = def_st, n_s = def_s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.append(to_pm(EXtremeDB.query(e_q3, 2, 'month', n_it, n_st = 1, n_s = 100)))\n",
    "click.append(to_pm(ClickHouse.query(c_q3, 2, 'month', n_it, n_st = 1, n_s = 100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80af254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(click)\n",
    "print(ex)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'click': click, 'ex': ex})\n",
    "df.index =['minute', 'hour', 'day', 'week', 'month', '2months']\n",
    "df_runtime = df.copy()\n",
    "df_variance = df.copy()\n",
    "for col in df: \n",
    "    df_runtime[col] = df[col].str.split('$').str[0].astype(float)\n",
    "    df_variance[col] = df[col].str.split('$').str[2].astype(float)\n",
    "#         df_runtime[col].plot(logy = True, marker='o', logx = False, xticks = df_runtime.index, title = \"Query \" + str(i+1), xlabel = \"# Stations\", ylabel = \"Runtime (ms)\")\n",
    "    plt.errorbar(df_runtime[col].index, df_runtime[col], linewidth=4, elinewidth=2, markeredgewidth=2, yerr=df_variance[col], marker='o') #, color = colors[col])\n",
    "plt.legend(['clickhouse', 'extremedb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d01cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443d781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1][\"clickhouse\"] = []\n",
    "for n_st in [1] + [i for i in range(2, 11, 2)]:\n",
    "    results[1]['clickhouse'].append(to_pm(ClickHouse.query(c_q2, 1, def_r, n_it, n_st = n_st, n_s = def_s)))\n",
    "for n_s in [1] + [i for i in range(10, 101, 10)]:\n",
    "    results[1]['clickhouse'].append(to_pm(ClickHouse.query(c_q2, 1, def_r, n_it, n_st = def_st, n_s = n_s)))\n",
    "for r in ['minute', 'hour', 'day', 'week', 'month']:\n",
    "    results[1]['clickhouse'].append(to_pm(ClickHouse.query(c_q2, 1, r, n_it, n_st = def_st, n_s = def_s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1][\"clickhouse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f452446f",
   "metadata": {},
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217ad6e",
   "metadata": {},
   "source": [
    "results[4] = { k: results[4][k] for k in ['extremedb', 'influx', \"influx_wide\", 'questdb', 'timescaledb'] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a585a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[4]['influx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dede61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f6492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "408cd5c1",
   "metadata": {},
   "source": [
    "print('ClickHouse')\n",
    "res = ClickHouse.query(c_q1, 60, rangesUnit, n_it)\n",
    "res = round(res[0][0],2), round(res[1][0],2)\n",
    "print(str(res[0])+'$\\\\pm$'+str(res[1]))\n",
    "\n",
    "res = ClickHouse.query(c_q2, 60, rangesUnit, n_it)\n",
    "res = round(res[0][0],2), round(res[1][0],2)\n",
    "print(str(res[0])+'$\\\\pm$'+str(res[1]))\n",
    "\n",
    "res = ClickHouse.query(c_q3, 60, rangesUnit, n_it)\n",
    "res = round(res[0][0],2), round(res[1][0],2)\n",
    "print(str(res[0])+'$\\\\pm$'+str(res[1]))\n",
    "\n",
    "res = ClickHouse.query(c_q4, 60, rangesUnit, n_it, n_st = 5)\n",
    "res = round(res[0][0],2), round(res[1][0],2)\n",
    "print(str(res[0])+'$\\\\pm$'+str(res[1]))\n",
    "\n",
    "print('Druid')\n",
    "print(Druid_Wide.query(dw_q1, 60, 'hour', n_it))\n",
    "print(Druid_Wide.query(dw_q2, 60, 'hour', n_it))\n",
    "print(Druid_Wide.query(dw_q3, 60, 'hour', n_it))\n",
    "print(Druid_Wide.query(dw_q4, 60, 'hour', n_it, n_st = 5))\n",
    "#         results[\"druid\"].append(Druid.query(d_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "print('ExtremeDB')\n",
    "print(EXtremeDB.query(e_q1, 60, rangesUnit, n_it))\n",
    "print(EXtremeDB.query(e_q2, 60, rangesUnit, n_it))\n",
    "print(EXtremeDB.query(e_q3, 60, rangesUnit, n_it))\n",
    "print(EXtremeDB.query(e_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "print(EXtremeDB.query(e_q5, 60, rangesUnit, n_it, n_st = 5))\n",
    "\n",
    "print('Influx')    \n",
    "print(Influx.query(i_q1, 60, rangesUnit, n_it))\n",
    "print(Influx.query(i_q2, 60, rangesUnit, n_it))\n",
    "print(Influx.query(i_q3, 60, rangesUnit, n_it))\n",
    "print(Influx.query(i_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "print(Influx.query(i_q5, 60, rangesUnit, n_it, n_st = 5))\n",
    "\n",
    "print('Influx_Wide')    \n",
    "print(Influx_Wide.query(iw_q1, 60, rangesUnit, n_it))\n",
    "print(Influx_Wide.query(iw_q2, 60, rangesUnit, n_it))\n",
    "print(Influx_Wide.query(iw_q3, 60, rangesUnit, n_it))\n",
    "print(Influx_Wide.query(iw_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "print(Influx_Wide.query(iw_q5, 60, rangesUnit, n_it, n_st = 5))\n",
    "\n",
    "    \n",
    "print('MonetDB')    \n",
    "print(MonetDB.query(m_q1, 60, rangesUnit, n_it))\n",
    "print(MonetDB.query(m_q2, 60, rangesUnit, n_it))\n",
    "print(MonetDB.query(m_q3, 60, rangesUnit, n_it))\n",
    "print(MonetDB.query(m_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "#         results[\"monetdb\"].append(MonetDB.query(m_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "\n",
    "    \n",
    "print('QuestDB')    \n",
    "print(QuestDB.query(q_q1, 60, rangesUnit, n_it))\n",
    "print(QuestDB.query(q_q2, 60, rangesUnit, n_it))\n",
    "print(QuestDB.query(q_q3, 60, rangesUnit, n_it))\n",
    "print(QuestDB.query(q_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "print(QuestDB.query(q_q5, 60, rangesUnit, n_it, n_st = 5))\n",
    "\n",
    "    \n",
    "print('TimescaleDB')    \n",
    "print(TimescaleDB.query(t_q1, 60, rangesUnit, n_it))\n",
    "print(TimescaleDB.query(t_q2, 60, rangesUnit, n_it))\n",
    "print(TimescaleDB.query(t_q3, 60, rangesUnit, n_it))\n",
    "print(TimescaleDB.query(t_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "print(TimescaleDB.query(t_q5, 60, rangesUnit, n_it, n_st = 5))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
