{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0773e3",
   "metadata": {},
   "source": [
    "# Basic Queries D2 ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "841e5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics as stats\n",
    "#import os\n",
    "#os.system('sudo sync; echo 3 > /proc/sys/vm/drop_caches')\n",
    "start_program = time.time()\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a19ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "    \n",
    "def str_time_prop(start, end, time_format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formatted in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.mktime(time.strptime(start, time_format))\n",
    "    etime = time.mktime(time.strptime(end, time_format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return time.strftime(time_format, time.localtime(ptime))\n",
    "\n",
    "\n",
    "def random_date(start, end, prop, dform = '%Y-%m-%dT%H:%M:%S'):\n",
    "    return str_time_prop(start, end, dform, prop)\n",
    "    \n",
    "def get_list(elm, n_elm, max_r = 10, prefix = '', suffix = '', apostrophe = True):\n",
    "    res = ''\n",
    "    elms = random.sample(range(max_r), n_elm)\n",
    "    for i in range(n_elm): \n",
    "        item = prefix + elm + str(elms[i]) +  suffix \n",
    "        if apostrophe: \n",
    "            item = \"'\" + item + \"'\"\n",
    "        res += item \n",
    "        if i < n_elm - 1: \n",
    "            res += \", \"\n",
    "    return res\n",
    "\n",
    "import math\n",
    "\n",
    "def percentile(data, perc: int):\n",
    "    size = len(data)\n",
    "    return sorted(data)[int(math.ceil((size * perc) / 100)) - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5709e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1, query2, query3, query4, query5 = [{},{}],[{},{}],[{},{}],[{},{}],[{},{}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6e3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_duration = {\n",
    "#     1: 10,\n",
    "#     2: 15,\n",
    "#     3: 30,\n",
    "#     4: 5,\n",
    "#     5: 75\n",
    "# }\n",
    "max_duration = {\n",
    "    1: 1,\n",
    "    2: 1,\n",
    "    3: 1,\n",
    "    4: 1,\n",
    "    5: 1\n",
    "}\n",
    "rangesUnit = {\n",
    "    1: \"hour\",\n",
    "    2: \"day\",\n",
    "    3: \"day\",\n",
    "    4: \"day\",\n",
    "    5: \"hour\",\n",
    "}\n",
    "\n",
    "n_it = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e4dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "\n",
    "set_st = [str(random.randint(0,1999)) for i in range(500)]\n",
    "set_s = [str(random.randint(0,99)) for i in range(500)]\n",
    "set_date = [random.random() for i in range(500)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96bd9e",
   "metadata": {},
   "source": [
    "# ClickHouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple class\n",
    "# attribute\n",
    "\n",
    "c_q1 = \"\"\"select * FROM d2 where id_station='st<stid>'\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "# c_q1 = \"\"\"select time, s<sid> FROM d2 where id_station='st<stid>'\n",
    "# AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "# AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "c_q2 = \"\"\"select time, s<sid> FROM d2 where id_station='st<stid>'\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' and s<sid> > 0.95;\"\"\"\n",
    "\n",
    "c_q3 = \"\"\"SELECT id_station, avg(s<sid>) FROM d2 \n",
    "WHERE time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' \n",
    "GROUP BY id_station;\"\"\"\n",
    "\n",
    "c_q4 = \"\"\"SELECT id_station, EXTRACT(YEAR FROM time) AS \"year\",\n",
    "date_trunc('month', time) AS \"month\", \n",
    "date_trunc('day', time) AS \"day\", \n",
    "date_trunc('hour', time) AS \"hour\", \n",
    "AVG(s<sid>) AS avg_s<sid>\n",
    "FROM d2 where  time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND id_station in <stid> \n",
    "AND time < TIMESTAMP '<timestamp>' \n",
    "GROUP BY id_station, \"year\", \"month\", \"day\", \"hour\";\"\"\"\n",
    "\n",
    "# c_q5 = \"\"\"SELECT\n",
    "#   time_bucket_gapfill('5 second', time) AS NEWTIME,\n",
    "#   id_station,\n",
    "#   avg(s<sid>) AS avg_value,\n",
    "#   interpolate(avg(s<sid>))\n",
    "# FROM d1_wide\n",
    "# WHERE time < '<timestamp>' AND time > timestamp '<timestamp>' - interval '<nb> <rangesUnit>'\n",
    "# AND id_station in <stid> \n",
    "# GROUP BY NEWTIME, id_station\n",
    "# ORDER BY NEWTIME;\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#druid = Druid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d54cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "from clickhouse_driver import connect as connect_ClickHouse\n",
    "\n",
    "class ClickHouse:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1):\n",
    "#         client = Client('diufrm102')\n",
    "        conn = connect_ClickHouse(\"clickhouse://diufrm102\")\n",
    "        cursor = conn.cursor()\n",
    "#         print(client.execute('SHOW TABLES'))\n",
    "#         return None, None\n",
    "        duration = max_d\n",
    "        results = [[],[]]       \n",
    "        runtimes = []\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-02-02T00:00:00\", \"2019-02-05T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "            temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            if n_st == 1: \n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "            else: \n",
    "                li = ['st' + str(set_st[(duration*i)%500]) for i in range(n_st)]\n",
    "#                     print(li)\n",
    "                q = '(' + \"'\" + li[0] + \"'\"\n",
    "                for i in li[1:]:\n",
    "                    q += ',' + \"'\" + i + \"'\"\n",
    "                q += \")\"\n",
    "                temp = temp.replace(\"<stid>\", q)\n",
    "\n",
    "            start = time.time()\n",
    "#             print(temp)\n",
    "            cursor.execute(temp)\n",
    "            cursor.fetchall()\n",
    "            diff = (time.time()-start)*1000\n",
    "#                 print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "#             print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results[0], results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "res.append([str(round(i[0], 2)) for i in ClickHouse.query(c_q1, max_duration[1], rangesUnit[1], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in ClickHouse.query(c_q2, max_duration[2], rangesUnit[2], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in ClickHouse.query(c_q3, max_duration[3], rangesUnit[3], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in ClickHouse.query(c_q4, max_duration[4], rangesUnit[4], n_it, n_st = 5)])\n",
    "\n",
    "s = ''\n",
    "for r in res: \n",
    "    s += r[0] + \"$\\\\pm$\" + r[1] + '\\t&\\t'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29343312",
   "metadata": {},
   "source": [
    "# Druid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = PyDruid('http://diufrm118:8083', 'druid/v2/')\n",
    "\n",
    "# ts = query.timeseries(\n",
    "#     datasource='d1',\n",
    "#     granularity={\"type\": \"duration\", \"duration\": 5000},\n",
    "#     aggregations={\"value\": stringfirst(\"value\")},\n",
    "#     intervals='2019-03-01/pt1h',\n",
    "#     filter=Dimension('s') == 's4',\n",
    "#     context={\"skipEmptyBuckets\": \"false\"}   \n",
    "# )\n",
    "\n",
    "\n",
    "# # print(ts)\n",
    "\n",
    "# query.export_pandas()\n",
    "\n",
    "# # query.execute(d_q5)\n",
    "# # print((time.time()-start)*1000)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92f24187",
   "metadata": {},
   "source": [
    "# A simple class\n",
    "# attribute\n",
    "d_q1 = \"\"\"select __time, \"value\" FROM d2 where id_station = 'st<stid>' and s='s<sid>' \n",
    "    and __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "    and __time < TIMESTAMP '<timestamp>'\"\"\"\n",
    "\n",
    "d_q2 = \"\"\"SELECT __time\", value\" FROM d2 WHERE  id_station = 'st<stid>' \n",
    "    AND __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit>  \n",
    "    and __time < TIMESTAMP '<timestamp>' AND \"value\" > 0.95 AND s = 's<sid>'\"\"\"\n",
    "\n",
    "d_q3 = \"\"\"select id_station,AVG(\"value\")  FROM d2 where __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \\\n",
    "    and __time < TIMESTAMP '<timestamp>' and s = 's<sid>'\n",
    "    GROUP BY id_station\"\"\"\n",
    "\n",
    "d_q4 = \"\"\"SELECT \"id_station\", TIME_EXTRACT(__time, 'YEAR')  AS \"yearP\",\n",
    "    TIME_EXTRACT(__time, 'MONTH') AS \"month\", \n",
    "    TIME_EXTRACT(__time, 'DAY') AS \"day\", \n",
    "    TIME_EXTRACT(__time, 'HOUR') AS \"hour\", \n",
    "    AVG(\"value\") \n",
    "    FROM d2 where __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "    AND __time < TIMESTAMP '<timestamp>' \n",
    "    AND s = 's<sid>'\n",
    "    and id_station in <stid>\n",
    "    GROUP BY 1,2,3,4,5\"\"\"\n",
    "\n",
    "d_q5 = \"\"\"\n",
    "{\n",
    "  \"queryType\": \"timeseries\",\n",
    "  \"dataSource\": \"d2\",\n",
    "  \"granularity\": {\"type\": \"duration\", \"duration\": 5000},\n",
    "    \"filter\": {\n",
    "    \"type\": \"and\",\n",
    "    \"fields\": [\n",
    "      {\n",
    "        \"type\": \"in\",\n",
    "        \"dimension\": \"id_station\",\n",
    "        \"values\": ['st3', 'st7', 'st9', 'st2', 'st2']\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"selector\",\n",
    "        \"dimension\": \"s\",\n",
    "        \"value\": \"s47\",\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"aggregations\": [\n",
    "    { \"type\": \"doubleFirst\", \"name\": \"value\", \"fieldName\": \"value\" }\n",
    "  ],\n",
    "  \"intervals\": [ \"2019-03-01T00:00:00.000/2019-03-04T00:00:00.000\" ],\n",
    "  \"context\" : {\n",
    "    \"skipEmptyBuckets\": \"false\"\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#druid = Druid()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36bdd834",
   "metadata": {},
   "source": [
    "from pydruid.client import *\n",
    "from pylab import plt\n",
    "from pydruid.db import connect\n",
    "from pydruid.utils.aggregators import *\n",
    "from pydruid.utils.filters import *\n",
    "\n",
    "class Druid:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1):\n",
    "        conn = connect(host='diufrm102', port=8082, path='/druid/v2/sql/', scheme='http')\n",
    "        curs = conn.cursor()\n",
    "        curs.execute(\"select * FROM d1 where id_station in ('st5') and s='s14' and __time > TIMESTAMP '2019-03-04 00:00:00' - INTERVAL '1' DAY and __time < TIMESTAMP '2019-03-04 00:00:00' \")\n",
    "        curs.fetchall()\n",
    "        results = [[],[]]\n",
    "        duration = max_d\n",
    "        runtimes = []\n",
    "        for i in range(n_it):\n",
    "            date = random_date(\"2019-02-02T00:00:00\", \"2019-02-05T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%d %H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            if n_st == 1: \n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "            else: \n",
    "                li = ['st' + str(set_st[(duration*i)%500]) for i in range(n_st)]\n",
    "#                     print(li)\n",
    "                q = '(' + \"'\" + li[0] + \"'\"\n",
    "                for i in li[1:]:\n",
    "                    q += ',' + \"'\" + i + \"'\"\n",
    "                q += \")\"\n",
    "                temp = temp.replace(\"<stid>\", q)\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "            start = time.time()\n",
    "#                 print(temp)\n",
    "            curs.execute(temp)\n",
    "            curs.fetchall()\n",
    "            #print(temp, curs.rowcount)\n",
    "            diff = (time.time()-start)*1000\n",
    "            runtimes.append(diff)\n",
    "#                 print(temp, diff)\n",
    "        #print(runtimes)\n",
    "        #print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "#             results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results[0],results[1]\n",
    "    \n",
    "    def query5(max_d, rangesUnit, n_it):\n",
    "        results = [[],[]]\n",
    "        query = PyDruid('http://diufrm102:8083', 'druid/v2/')\n",
    "        for duration in tqdm(range(int(max_d/5), max_d + 1, int(max_d/5))):\n",
    "            runtimes = []\n",
    "            for i in range(n_it):\n",
    "                start = time.time()\n",
    "                date = random_date(\"2019-02-02T00:00:00\", \"2019-02-05T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "                query.timeseries(\n",
    "                    datasource='d1',\n",
    "                    granularity={\"type\": \"duration\", \"duration\": 5000},\n",
    "                    aggregations={\"value\": stringfirst(\"value\")},\n",
    "                    intervals= date + '/p' +  str(duration) + str(rangesUnit)[0],\n",
    "                    filter=Dimension('s') == 's' + str(set_s[(duration*i)%500]),\n",
    "                    context={\"skipEmptyBuckets\": \"false\"}   \n",
    "                )\n",
    "                print(date + '/p' +  str(duration) + str(rangesUnit)[0])\n",
    "                diff = (time.time()-start)*1000\n",
    "                runtimes.append(diff)\n",
    "            print(runtimes)\n",
    "            results[0].append(stats.mean(runtimes))\n",
    "            results[1].append(stats.stdev(runtimes,85))\n",
    "#             results[1].append(stats.stdev(runtimes))\n",
    "        return results[0], results[1]\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb965d1",
   "metadata": {},
   "source": [
    "# Druid Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple class\n",
    "# attribute\n",
    "# dw_q1 = \"\"\"select __time, \"s<sid>\" FROM d2_hour where st = 'st<stid>' \n",
    "#     and __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "#     and __time < TIMESTAMP '<timestamp>'\"\"\"\n",
    "\n",
    "\n",
    "dw_q1 = \"\"\"select * FROM d2_hour where st = 'st<stid>' \n",
    "    and __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "    and __time < TIMESTAMP '<timestamp>'\"\"\"\n",
    "\n",
    "\n",
    "dw_q2 = \"\"\"SELECT __time, \"s<sid>\" FROM d2_hour WHERE  st = 'st<stid>' \n",
    "    AND __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit>  \n",
    "    and __time < TIMESTAMP '<timestamp>' AND \"s<sid>\" > 0.95\"\"\"\n",
    "\n",
    "dw_q3 = \"\"\"select st,AVG(\"s<sid>\")  FROM d2_hour \n",
    "    where __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \\\n",
    "    and __time < TIMESTAMP '<timestamp>' \n",
    "    GROUP BY st\"\"\"\n",
    "\n",
    "dw_q4 = \"\"\"SELECT \"st\", TIME_EXTRACT(__time, 'YEAR')  AS \"yearP\",\n",
    "    TIME_EXTRACT(__time, 'MONTH') AS \"month\", \n",
    "    TIME_EXTRACT(__time, 'DAY') AS \"day\", \n",
    "    TIME_EXTRACT(__time, 'HOUR') AS \"hour\", \n",
    "    AVG(\"s<sid>\") \n",
    "    FROM d2_hour where __time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "    AND __time < TIMESTAMP '<timestamp>' \n",
    "    and st in <stid>\n",
    "    GROUP BY 1,2,3,4,5\"\"\"\n",
    "\n",
    "#druid = Druid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d29a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydruid.client import *\n",
    "from pylab import plt\n",
    "from pydruid.db import connect\n",
    "from pydruid.utils.aggregators import *\n",
    "from pydruid.utils.filters import *\n",
    "\n",
    "class Druid_Wide:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1):\n",
    "        conn = connect(host='diufrm102', port=8082, path='/druid/v2/sql/', scheme='http')\n",
    "        curs = conn.cursor()\n",
    "#         curs.execute(\"select * FROM d1 where id_station in ('st5') and s='s14' and __time > TIMESTAMP '2019-03-04 00:00:00' - INTERVAL '1' DAY and __time < TIMESTAMP '2019-03-04 00:00:00' \")\n",
    "#         curs.fetchall()\n",
    "        results = [[],[]]\n",
    "        duration = max_d\n",
    "        runtimes = []\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-02-02 00:00:00\", \"2019-02-05 00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%d %H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            if n_st == 1: \n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "            else: \n",
    "                li = ['st' + str(set_st[(duration*i)%500]) for i in range(n_st)]\n",
    "#                     print(li)\n",
    "                q = '(' + \"'\" + li[0] + \"'\"\n",
    "                for i in li[1:]:\n",
    "                    q += ',' + \"'\" + i + \"'\"\n",
    "                q += \")\"\n",
    "                temp = temp.replace(\"<stid>\", q)\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "            start = time.time()\n",
    "#             print(temp)\n",
    "            curs.execute(temp)\n",
    "            curs.fetchall()\n",
    "            #print(temp, curs.rowcount)\n",
    "            diff = (time.time()-start)*1000\n",
    "            runtimes.append(diff)\n",
    "#                 print(temp, diff)\n",
    "        #print(runtimes)\n",
    "        #print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "#             results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results[0],results[1]\n",
    "    \n",
    "    def query5(max_d, rangesUnit, n_it):\n",
    "        results = [[],[]]\n",
    "        query = PyDruid('http://diufrm102:8083', 'druid/v2/')\n",
    "        for duration in tqdm(range(int(max_d/5), max_d + 1, int(max_d/5))):\n",
    "            runtimes = []\n",
    "            for i in range(n_it):\n",
    "                start = time.time()\n",
    "                date = random_date(\"2019-02-02T00:00:00\", \"2019-02-05T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "                query.timeseries(\n",
    "                    datasource='d2',\n",
    "                    granularity={\"type\": \"duration\", \"duration\": 5000},\n",
    "                    aggregations={\"value\": stringfirst(\"value\")},\n",
    "                    intervals= date + '/p' +  str(duration) + str(rangesUnit)[0],\n",
    "                    filter=Dimension('s') == 's' + str(set_s[(duration*i)%500]),\n",
    "                    context={\"skipEmptyBuckets\": \"false\"}   \n",
    "                )\n",
    "                print(date + '/p' +  str(duration) + str(rangesUnit)[0])\n",
    "                diff = (time.time()-start)*1000\n",
    "                runtimes.append(diff)\n",
    "            print(runtimes)\n",
    "            results[0].append(stats.mean(runtimes))\n",
    "            results[1].append(stats.stdev(runtimes,85))\n",
    "#             results[1].append(stats.stdev(runtimes))\n",
    "        return results[0], results[1]\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc07d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "res.append([str(round(i[0], 2)) for i in Druid_Wide.query(dw_q1, max_duration[1], rangesUnit[1], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in Druid_Wide.query(dw_q2, max_duration[2], rangesUnit[2], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in Druid_Wide.query(dw_q3, max_duration[3], rangesUnit[3], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in Druid_Wide.query(dw_q4, max_duration[4], rangesUnit[4], n_it, n_st = 5)])\n",
    "\n",
    "s = ''\n",
    "for r in res: \n",
    "    s += r[0] + \"$\\\\pm$\" + r[1] + '\\t&\\t'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ca1825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Druid_Wide.query(dw_q3, 1, \"hour\", 100)\n",
    "Druid_Wide.query(dw_q3, 1, \"hour\", 100, n_st = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27fc749",
   "metadata": {},
   "source": [
    "# eXtremeDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb690017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple class\n",
    "# attribute\n",
    "# e_q1 = \"\"\"select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, s<sid>@tt FROM d2_v WHERE id_station = 'st<stid>';\"\"\"\n",
    "e_q1 = \"\"\"select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, <allsensors> FROM d2_v WHERE id_station = 'st<stid>';\"\"\"\n",
    "\n",
    "\n",
    "e_q2 = \"\"\"select seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, !seq_filter_search(s<sid>@tt > 0.95, tt) as fe, s<sid>@fe FROM d2_v WHERE id_station = 'st<stid>'; \"\"\"\n",
    "\n",
    "\n",
    "e_q3 = \"\"\"SELECT id_station, ! seq_search(t,<timestamp> - <nb> * <rangesUnit>,<timestamp>) as tt, seq_avg(s<sid>@tt) FROM d2_v;\"\"\" # where id_station = 'st<stid>'\n",
    "\n",
    "\n",
    "e_q4 = \"\"\"select id_station, seq_search(t,<timestamp> - <nb> * <rangesUnit>, <timestamp>) as tt, t@tt/3600 as hour, seq_group_agg_dev(s<sid>@tt, t@tt/3600) FROM d2_v  where id_station in <stid>\"\"\"\n",
    "\n",
    "\n",
    "e_q5 = \"\"\"select seq_aprogres_datetime(<timestamp> -  <nb> * <rangesUnit>, 5, <nb> * <rangesUnit>) as ts5,seq_stretch(ts5,t,s<sid>) from d2_v where  id_station in <stid>;\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5015cf16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m     curs\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect seq_search(t,1555315999 - 12 * 86400,1555315999) as tt, !seq_filter_search(s87@tt > 0.95, tt) as fe, s87@fe FROM d1_v WHERE id_station = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mst4\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     curs\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import exdb \n",
    "import datetime\n",
    "exdb.init_runtime(debug = False, shm = False, disk = False, tmgr = 'mursiw', UsePerfmon = True)\n",
    "con = exdb.connect('diufrm118', 5001)\n",
    "curs = con.cursor()\n",
    "res = []\n",
    "for i in range(10):\n",
    "    start = time.time()\n",
    "    curs.execute(\"select seq_search(t,1555315999 - 12 * 86400,1555315999) as tt, !seq_filter_search(s87@tt > 0.95, tt) as fe, s87@fe FROM d2_v WHERE id_station = 'st4';\")\n",
    "    curs.fetchall()\n",
    "    res.append((time.time()-start)*1000)\n",
    "con.close()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378c7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXtremeDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1):\n",
    "        # map the inputs to the function blocks\n",
    "        import exdb \n",
    "        import datetime\n",
    "        exdb.init_runtime(debug = False, shm = False, disk = False, tmgr = 'mursiw')\n",
    "        con = exdb.connect('diufrm118', 5001)\n",
    "        curs = con.cursor()\n",
    "        curs.execute(\"SELECT s23 FROM d2_v where id_station = 'st3'\")\n",
    "        curs.fetchall()\n",
    "        results = [[],[]]\n",
    "        options = {\"day\" : 60 * 60* 24,\n",
    "                   \"week\" : 60 * 60* 24 * 7,\n",
    "                   \"minute\" : 60,\n",
    "                   \"hour\" : 60 * 60,\n",
    "                   \"second\" : 1,\n",
    "                   \"month\" : 60 * 60 * 24 * 30,\n",
    "                   \"year\" :  60 * 60 * 24 * 30 * 12\n",
    "        }\n",
    "        duration = max_d\n",
    "        runtimes = []\n",
    "        for i in tqdm(range(n_it)):    \n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-02-02 00:00:00\", \"2019-02-05 00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%d %H:%M:%S')\n",
    "            date = int(time.mktime(datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S').timetuple()))\n",
    "            temp = query.replace(\"<timestamp>\", str(date))\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            allsensors = ''\n",
    "            for i in range(100): \n",
    "                allsensors += 's' + str(i) + '@tt'\n",
    "                if i < 99: allsensors += ', '\n",
    "            temp = temp.replace(\"<allsensors>\", allsensors)\n",
    "            \n",
    "            if n_st == 1: \n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "            else: \n",
    "                li = ['st' + str(set_st[(duration*i)%500]) for i in range(n_st)]\n",
    "#                     print(li)\n",
    "                q = '(' + \"'\" + li[0] + \"'\"\n",
    "                for i in li[1:]:\n",
    "                    q += ',' + \"'\" + i + \"'\"\n",
    "                q += \")\"\n",
    "                temp = temp.replace(\"<stid>\", q)\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(options[rangesUnit]))\n",
    "#                 print(temp)\n",
    "            start = time.time()\n",
    "            curs.execute(temp)\n",
    "            # print(curs.rowcount)\n",
    "            curs.fetchall()\n",
    "            diff = (time.time()-start)*1000\n",
    "#                 print(temp, diff)\n",
    "            runtimes.append(diff )\n",
    "        #print(runtimes)\n",
    "        #print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        con.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18286d65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXtremeDB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mEXtremeDB\u001b[49m\u001b[38;5;241m.\u001b[39mquery(e_q3, max_duration[\u001b[38;5;241m3\u001b[39m], rangesUnit[\u001b[38;5;241m3\u001b[39m], n_it)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EXtremeDB' is not defined"
     ]
    }
   ],
   "source": [
    "EXtremeDB.query(e_q3, max_duration[3], rangesUnit[3], n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07cf732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 29.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 78.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [01:31<00:00,  3.04s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03<00:00,  8.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.27$\\pm$1.11\t&\t12.46$\\pm$0.38\t&\t3043.37$\\pm$127.78\t&\t110.86$\\pm$1.39\t&\t39.7$\\pm$1.55\t&\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "res.append([str(round(i[0], 2)) for i in EXtremeDB.query(e_q1, max_duration[1], rangesUnit[1], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in EXtremeDB.query(e_q2, max_duration[2], rangesUnit[2], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in EXtremeDB.query(e_q3, max_duration[3], rangesUnit[3], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in EXtremeDB.query(e_q4, max_duration[4], rangesUnit[4], n_it, n_st = 5)])\n",
    "res.append([str(round(i[0], 2)) for i in EXtremeDB.query(e_q5, max_duration[5], rangesUnit[5], n_it, n_st = 5)])\n",
    "\n",
    "s = ''\n",
    "for r in res: \n",
    "    s += r[0] + \"$\\\\pm$\" + r[1] + '\\t&\\t'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e6a4dd",
   "metadata": {},
   "source": [
    "# Influx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd9a8d05",
   "metadata": {},
   "source": [
    "i_q1 = \"\"\"select time, value FROM \"d2\".\"autogen\".\"sensor\" where \"id_station\" ='st<stid>' AND \"s\" ='s<sid>' AND time > '<timestamp>Z' - <nb><rangesUnit> AND  time < '<timestamp>Z'\"\"\"\n",
    "i_q2 = \"\"\"select time, value FROM \"d2\".\"autogen\".\"sensor\" where \"id_station\" ='st<stid>' AND \"s\" ='s<sid>' AND time > '<timestamp>Z' - <nb><rangesUnit> AND  time < '<timestamp>Z' and value > 0.95\"\"\"\n",
    "i_q3 = \"\"\"SELECT mean(value) FROM \"d2\".\"autogen\".\"sensor\" WHERE  \"s\" ='s<sid>' AND time > '<timestamp>Z' - <nb><rangesUnit> AND time < '<timestamp>Z' GROUP BY \"id_station\"  \"\"\"\n",
    "i_q4 = \"\"\"SELECT first(id_station), mean(value) FROM \"d2\".\"autogen\".\"sensor\" WHERE time > '<timestamp>Z' - <nb><rangesUnit> AND s='s<sid>' and time < '<timestamp>Z' and <stid> GROUP BY id_station,time(1h)\"\"\"\n",
    "i_q5 = \"\"\"SELECT id_station, mean_value FROM (SELECT mean(value) as mean_value FROM \"d2\".\"autogen\".\"sensor\" WHERE time > '<timestamp>Z' - <nb><rangesUnit> AND time < '<timestamp>Z' AND s='s<sid>' and <stid> GROUP BY id_station,time(5s) FILL(0)) GROUP BY id_station\"\"\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26ce0c54",
   "metadata": {},
   "source": [
    "import time\n",
    "from influxdb import InfluxDBClient\n",
    "\n",
    "class Influx:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1):\n",
    "        client = InfluxDBClient(host='diufrm118', port=8086, username='abdel')\n",
    "        results = [[],[]]\n",
    "        client.query(\"select * FROM \\\"d1\\\".\\\"autogen\\\".\\\"sensor\\\" where \\\"id_station\\\" ='st8' AND \\\"s\\\" ='s8' AND time > '2019-03-29T02:37:39Z' - 1d  AND  time < '2019-03-29T02:37:39Z'\")\n",
    "        \n",
    "        duration = max_d\n",
    "        runtimes = []\n",
    "        for i in range(10):\n",
    "            date = random_date(\"2019-02-02T00:00:00\", \"2019-02-05T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit[0]))\n",
    "            temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            if n_st == 1: \n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "            else: \n",
    "                li = ['st' + str(set_st[(duration*i)%500]) for i in range(n_st)]\n",
    "#                     print(li)\n",
    "                q = '(id_station =' + \"'\" + li[0] + \"'\"\n",
    "                for i in li[1:]:\n",
    "                    q += ' OR '  + 'id_station =' + \"'\" + i + \"'\"\n",
    "                q += \")\"\n",
    "                temp = temp.replace(\"<stid>\", q)\n",
    "            start = time.time()\n",
    "            result = client.query(temp)\n",
    "            diff = (time.time()-start)*1000\n",
    "#                 print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "#             print(runtimes)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        client.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43238efe",
   "metadata": {},
   "source": [
    "# MonetDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b2d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_q1 = \"\"\"select * FROM d2 where id_station='st<stid>' \\\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \\\n",
    "AND time < TIMESTAMP '<timestamp>'\"\"\"\n",
    "# m_q1 = \"\"\"select time, s<sid> FROM d2 where id_station='st<stid>' \\\n",
    "# AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \\\n",
    "# AND time < TIMESTAMP '<timestamp>'\"\"\"\n",
    "m_q2 = \"\"\"select time, s<sid> FROM d2 where id_station='st<stid>' \n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' AND s<sid>>0.95\"\"\"\n",
    "m_q3 = \"\"\"SELECT id_station, avg(s<sid>) FROM d2 \n",
    "WHERE time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>'\n",
    "GROUP BY id_station\"\"\"\n",
    "m_q4 = \"\"\"SELECT id_station, EXTRACT(YEAR FROM time) AS \"year\",\n",
    "EXTRACT(MONTH FROM time) AS \"month\", \n",
    "EXTRACT(DAY FROM time) AS \"day\", \n",
    "EXTRACT(HOUR FROM time) \n",
    "AS \"hour\", AVG(s<sid>) AS avg_s<sid>\n",
    "FROM d2 where  time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>'\n",
    "AND id_station in <stid>\n",
    "GROUP BY id_station, \"year\", \"month\", \"day\", \"hour\" \"\"\"\n",
    "m_q5 = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46700c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymonetdb\n",
    "import time\n",
    "\n",
    "class MonetDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1):\n",
    "        connection = pymonetdb.connect(username=\"monetdb\", port=54320, password=\"monetdb\", hostname=\"diufrm118\", database=\"mydb\")\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"\"\"select time, s91 FROM d2 where id_station='st4' AND time > TIMESTAMP '2019-03-09T13:43:54' - INTERVAL '3' day AND time < TIMESTAMP '2019-03-09T13:43:54'\"\"\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        \n",
    "        duration = max_d\n",
    "        \n",
    "        runtimes = []\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-02-02T00:00:00\", \"2019-02-05T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "            temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            if n_st == 1: \n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "            else: \n",
    "                li = ['st' + str(set_st[(duration*i)%500]) for i in range(n_st)]\n",
    "#                     print(li)\n",
    "                q = '(' + \"'\" + li[0] + \"'\"\n",
    "                for i in li[1:]:\n",
    "                    q += ',' + \"'\" + i + \"'\"\n",
    "                q += \")\"\n",
    "                temp = temp.replace(\"<stid>\", q)\n",
    "            start = time.time()\n",
    "            cursor.execute(temp)\n",
    "            cursor.fetchall()\n",
    "            diff = (time.time()-start)*1000\n",
    "#                 print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "        #print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        connection.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd9e2ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:18<00:00,  1.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03<00:00,  9.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03<00:00,  9.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605.28$\\pm$74.56\t&\t103.17$\\pm$1.87\t&\t102.32$\\pm$4.67\t&\t130.03$\\pm$5.77\t&\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "res.append([str(round(i[0], 2)) for i in MonetDB.query(m_q1, max_duration[1], rangesUnit[1], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in MonetDB.query(m_q2, max_duration[2], rangesUnit[2], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in MonetDB.query(m_q3, max_duration[3], rangesUnit[3], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in MonetDB.query(m_q4, max_duration[4], rangesUnit[4], n_it, n_st = 5)])\n",
    "\n",
    "s = ''\n",
    "for r in res: \n",
    "    s += r[0] + \"$\\\\pm$\" + r[1] + '\\t&\\t'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65493e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "MonetDB.query(m_q3, 60, \"minute\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "MonetDB.query(m_q4, 60, \"minute\", 100, n_st = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a893e0",
   "metadata": {},
   "source": [
    "# QuestDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4140a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_q1 = \"\"\"select * FROM d2 where id_station='st<stid>' AND  ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L \"\"\"\n",
    "# q_q1 = \"\"\"select ts, s<sid> FROM d2 where id_station='st<stid>' AND  ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L \"\"\"\n",
    "q_q2 = \"\"\"select ts, s<sid> FROM d2 where id_station='st<stid>' AND  ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L and s<sid> > 0.95;\"\"\"\n",
    "q_q3 = \"\"\"SELECT id_station, avg(s<sid>) FROM d2 WHERE  ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L GROUP BY id_station;\"\"\"\n",
    "q_q4 = \"\"\"SELECT id_station, ts, avg(s<sid>) FROM d2 WHERE ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L AND id_station in <stid> SAMPLE BY 1h;\"\"\"\n",
    "# q_q5 = \"\"\"SELECT id_station, ts, avg(s<sid>) FROM d1 WHERE ts IN '<timestamp>;<nb><rangesUnit>' SAMPLE BY 5s FILL(LINEAR) GROUP BY id_station,ts ORDER BY id_station, ts;\"\"\"\n",
    "q_q5 = \"\"\"SELECT id_station, ts, avg(s<sid>) FROM d2 WHERE  ts < '<timestamp>' AND ts >  '<timestamp>' - <nb>*<rangesUnit>* 1000000L AND id_station in <stid> SAMPLE BY 5s FILL(LINEAR) GROUP BY ts, id_station ORDER BY ts;\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d3a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QuestDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1):\n",
    "        import psycopg2\n",
    "        import time\n",
    "        connection = psycopg2.connect(user=\"admin\",\n",
    "                                          password=\"quest\",\n",
    "                                          host=\"diufrm146\",\n",
    "                                          port=\"8812\",\n",
    "                                          database=\"d2\")\n",
    "        options = {\"day\" : 60 * 60* 24,\n",
    "                   \"week\" : 60 * 60* 24 * 7,\n",
    "                   \"minute\" : 60,\n",
    "                   \"hour\" : 60 * 60,\n",
    "                   \"second\" : 1,\n",
    "                   \"month\" : 60 * 60 * 24 * 30,\n",
    "                   \"year\" :  60 * 60 * 24 * 30 * 12\n",
    "        }\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select ts, s9 FROM d1 where id_station='st4' AND ts IN '2019-03-23;1d'\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        \n",
    "        duration = max_d\n",
    "        \n",
    "        runtimes = []\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-02-02\", \"2019-02-05\", set_date[(duration*i)%500], dform = '%Y-%m-%d')\n",
    "            temp = query.replace(\"<timestamp>\", date+'T00:00')\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(options[rangesUnit]))\n",
    "            temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            if n_st == 1: \n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "            else: \n",
    "                li = ['st' + str(set_st[(duration*i)%500]) for i in range(n_st)]\n",
    "#                     print(li)\n",
    "                q = '(' + \"'\" + li[0] + \"'\"\n",
    "                for i in li[1:]:\n",
    "                    q += ',' + \"'\" + i + \"'\"\n",
    "                q += \")\"\n",
    "                temp = temp.replace(\"<stid>\", q)\n",
    "\n",
    "            start = time.time()\n",
    "#             print(temp)\n",
    "            cursor.execute(temp)\n",
    "            cursor.fetchall()\n",
    "            #print(temp, cursor.rowcount)\n",
    "            #print(len)\n",
    "            diff = (time.time()-start)*1000\n",
    "#                 print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "#             print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             print(runtimes)\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        connection.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5322ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:10<00:00,  9.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[104.05722141265869], [8.98755865623072]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QuestDB.query(q_q1, 60, \"minute\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aec27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "res.append([str(round(i[0], 2)) for i in QuestDB.query(q_q1, max_duration[1], rangesUnit[1], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in QuestDB.query(q_q2, max_duration[2], rangesUnit[2], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in QuestDB.query(q_q3, max_duration[3], rangesUnit[3], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in QuestDB.query(q_q4, max_duration[4], rangesUnit[4], n_it, n_st = 5)])\n",
    "res.append([str(round(i[0], 2)) for i in QuestDB.query(q_q5, max_duration[5], rangesUnit[5], n_it, n_st = 5)])\n",
    "\n",
    "s = ''\n",
    "for r in res: \n",
    "    s += r[0] + \"$\\\\pm$\" + r[1] + '\\t&\\t'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9921759",
   "metadata": {},
   "outputs": [],
   "source": [
    "QuestDB.query(q_q2, max_duration[2], rangesUnit[2], n_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbc4c8",
   "metadata": {},
   "source": [
    "# TimescaleDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f970b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_q1 = \"\"\"select * FROM d2 where id_station='st<stid>'\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "\n",
    "# t_q1 = \"\"\"select time, s<sid> FROM d2 where id_station='st<stid>'\n",
    "# AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "# AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "\n",
    "t_q2 = \"\"\"select time, s<sid> FROM d2 where id_station='st<stid>'\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' and s<sid> > 0.95;\"\"\"\n",
    "\n",
    "t_q3 = \"\"\"SELECT id_station, avg(s<sid>) FROM d2 \n",
    "WHERE time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' \n",
    "GROUP BY id_station;\"\"\"\n",
    "\n",
    "t_q4 = \"\"\"SELECT id_station, EXTRACT(YEAR FROM time) AS \"year\",\n",
    "date_trunc('month', time) AS \"month\", \n",
    "date_trunc('DAY', time) AS \"day\", \n",
    "date_trunc('HOUR', time) AS \"hour\", \n",
    "AVG(s<sid>) AS avg_s<sid>\n",
    "FROM d2 where  time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' \n",
    "AND id_station in <stid> \n",
    "GROUP BY id_station, \"year\", \"month\", \"day\", \"hour\";\"\"\"\n",
    "\n",
    "t_q5 = \"\"\"SELECT\n",
    "  time_bucket_gapfill('5 second', time) AS NEWTIME,\n",
    "  id_station,\n",
    "  avg(s<sid>) AS avg_value,\n",
    "  interpolate(avg(s<sid>))\n",
    "FROM d2\n",
    "WHERE time < '<timestamp>' AND time > timestamp '<timestamp>' - interval '<nb> <rangesUnit>'\n",
    "AND id_station in <stid> \n",
    "GROUP BY NEWTIME, id_station\n",
    "ORDER BY NEWTIME;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edfaa74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TimescaleDB:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1):\n",
    "        import psycopg2\n",
    "        CONNECTION = \"postgres://postgres:postgres@diufrm118:5432/postgres\"\n",
    "        conn = psycopg2.connect(CONNECTION)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select time, s4 FROM d2 where id_station='st1' AND time > TIMESTAMP '2019-03-06T16:57:36' - INTERVAL '1' day AND time < TIMESTAMP '2019-03-06T16:57:36';\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        \n",
    "        duration = max_d\n",
    "        \n",
    "        \n",
    "        runtimes = []\n",
    "        for i in tqdm(range(n_it)):\n",
    "#             time.sleep(0.5)\n",
    "            date = random_date(\"2019-02-02T00:00:00\", \"2019-02-05T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "            temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            if n_st == 1: \n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "            else: \n",
    "                li = ['st' + str(set_st[(duration*i)%500]) for i in range(n_st)]\n",
    "#                     print(li)\n",
    "                q = '(' + \"'\" + li[0] + \"'\"\n",
    "                for i in li[1:]:\n",
    "                    q += ',' + \"'\" + i + \"'\"\n",
    "                q += \")\"\n",
    "                temp = temp.replace(\"<stid>\", q)\n",
    "\n",
    "\n",
    "            start = time.time()\n",
    "            cursor.execute(temp)\n",
    "            cursor.fetchall()\n",
    "            diff = (time.time()-start)*1000\n",
    "#                 print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "#             print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c896c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [01:15<00:00,  2.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2511.985445022583], [80.31230766428372]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TimescaleDB.query(t_q3, max_duration[3], rangesUnit[3], n_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c212ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 207.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [01:16<00:00,  2.55s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 23.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 27.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.14$\\pm$2.79\t&\t4.65$\\pm$0.5\t&\t2548.52$\\pm$185.88\t&\t42.48$\\pm$2.02\t&\t35.47$\\pm$1.04\t&\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "res.append([str(round(i[0], 2)) for i in TimescaleDB.query(t_q1, max_duration[1], rangesUnit[1], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in TimescaleDB.query(t_q2, max_duration[2], rangesUnit[2], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in TimescaleDB.query(t_q3, max_duration[3], rangesUnit[3], n_it)])\n",
    "res.append([str(round(i[0], 2)) for i in TimescaleDB.query(t_q4, max_duration[4], rangesUnit[4], n_it, n_st = 5)])\n",
    "res.append([str(round(i[0], 2)) for i in TimescaleDB.query(t_q5, max_duration[5], rangesUnit[5], n_it, n_st = 5)])\n",
    "\n",
    "s = ''\n",
    "for r in res: \n",
    "    s += r[0] + \"$\\\\pm$\" + r[1] + '\\t&\\t'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TimescaleDB.query(t_q3, 60, \"minute\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57691fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TimescaleDB.query(t_q4, max_duration[4], rangesUnit[4], 10, n_st = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84032e5c",
   "metadata": {},
   "source": [
    "# TimescaleDB Narrow"
   ]
  },
  {
   "cell_type": "raw",
   "id": "654d20a1",
   "metadata": {},
   "source": [
    "tn_q1 = \"\"\"select time, value FROM d2_narrow where id_station='st<stid>' and sid='s<sid>'\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>';\"\"\"\n",
    "\n",
    "tn_q2 = \"\"\"select time, value FROM d2_narrow where id_station='st<stid>' and sid='s<sid>'\n",
    "AND time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' and value > 0.95;\"\"\"\n",
    "\n",
    "tn_q3 = \"\"\"SELECT id_station, avg(value) FROM d2_narrow \n",
    "WHERE time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' and sid='s<sid>'\n",
    "GROUP BY id_station;\"\"\"\n",
    "\n",
    "tn_q4 = \"\"\"SELECT id_station, EXTRACT(YEAR FROM time) AS \"year\",\n",
    "date_trunc('month', time) AS \"month\", \n",
    "date_trunc('DAY', time) AS \"day\", \n",
    "date_trunc('HOUR', time) AS \"hour\", \n",
    "AVG(value) AS avg_s<sid>\n",
    "FROM d2_narrow where  time > TIMESTAMP '<timestamp>' - INTERVAL '<nb>' <rangesUnit> \n",
    "AND time < TIMESTAMP '<timestamp>' and sid='s<sid>'\n",
    "GROUP BY id_station, \"year\", \"month\", \"day\", \"hour\";\"\"\"\n",
    "\n",
    "tn_q5 = \"\"\"SELECT\n",
    "  time_bucket_gapfill('5 second', time) AS NEWTIME,\n",
    "  id_station,\n",
    "  avg(value) AS avg_value,\n",
    "  interpolate(avg(value))\n",
    "FROM d2_narrow\n",
    "WHERE time < '<timestamp>' AND time > timestamp '<timestamp>' - interval '<nb> <rangesUnit>'\n",
    "AND id_station in <stid> and sid='s<sid>'\n",
    "GROUP BY NEWTIME, id_station\n",
    "ORDER BY NEWTIME;\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d5eb933",
   "metadata": {},
   "source": [
    "\n",
    "class TimescaleDB_Narrow:\n",
    " \n",
    "    # A sample method \n",
    "    @staticmethod\n",
    "    def query(query, max_d, rangesUnit, n_it, n_st = 1):\n",
    "        import psycopg2\n",
    "        CONNECTION = \"postgres://postgres:postgres@diufrm118:5432/postgres\"\n",
    "        conn = psycopg2.connect(CONNECTION)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select time, s4 FROM d1 where id_station='st1' AND time > TIMESTAMP '2019-03-06T16:57:36' - INTERVAL '1' day AND time < TIMESTAMP '2019-03-06T16:57:36';\")\n",
    "        cursor.fetchall()\n",
    "        results = [[],[]]\n",
    "        \n",
    "        duration = max_d\n",
    "        \n",
    "        \n",
    "        runtimes = []\n",
    "        for i in range(n_it):\n",
    "            date = random_date(\"2019-02-02T00:00:00\", \"2019-02-05T00:00:00\", set_date[(duration*i)%500], dform = '%Y-%m-%dT%H:%M:%S')\n",
    "            temp = query.replace(\"<timestamp>\", date)\n",
    "            temp = temp.replace(\"<nb>\", str(duration))\n",
    "            temp = temp.replace(\"<rangesUnit>\", str(rangesUnit))\n",
    "            temp = temp.replace(\"<sid>\", str(set_s[(duration*i)%500]))\n",
    "            if n_st == 1: \n",
    "                temp = temp.replace(\"<stid>\", str(set_st[(duration*i)%500]))\n",
    "            else: \n",
    "                li = ['st' + str(set_st[(duration*i)%500]) for i in range(n_st)]\n",
    "#                     print(li)\n",
    "                q = '(' + \"'\" + li[0] + \"'\"\n",
    "                for i in li[1:]:\n",
    "                    q += ',' + \"'\" + i + \"'\"\n",
    "                q += \")\"\n",
    "                temp = temp.replace(\"<stid>\", q)\n",
    "\n",
    "\n",
    "            start = time.time()\n",
    "            cursor.execute(temp)\n",
    "            cursor.fetchall()\n",
    "            diff = (time.time()-start)*1000\n",
    "#                 print(temp, diff)\n",
    "            runtimes.append(diff)\n",
    "            print(temp)\n",
    "        results[0].append(stats.mean(runtimes))\n",
    "#             results[1].append(percentile(runtimes,85))\n",
    "        results[1].append(stats.stdev(runtimes))\n",
    "        conn.close()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca7ff1",
   "metadata": {},
   "source": [
    "# Run all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee68102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryAllClickHouse(duration_range):\n",
    "    \n",
    "#     max_d = 1000\n",
    "    rangesUnit = \"minute\"\n",
    "    results = [{} for i in range(5)]\n",
    "    for i in range(5):\n",
    "        results[i][\"clickhouse\"] = []\n",
    "        results[i][\"extremedb\"] = []\n",
    "        results[i][\"questdb\"] = []\n",
    "        results[i][\"timescaledb\"] = []\n",
    "        \n",
    "    for duration in tqdm(duration_range):\n",
    "        \n",
    "        results[0][\"clickhouse\"].append(ClickHouse.query(c_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[0][\"extremedb\"].append(EXtremeDB.query(e_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[0][\"questdb\"].append(QuestDB.query(q_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[0][\"timescaledb\"].append(TimescaleDB.query(t_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        \n",
    "        results[1][\"clickhouse\"].append(ClickHouse.query(c_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"extremedb\"].append(EXtremeDB.query(e_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"questdb\"].append(QuestDB.query(q_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"timescaledb\"].append(TimescaleDB.query(t_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        \n",
    "        results[2][\"clickhouse\"].append(ClickHouse.query(c_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"extremedb\"].append(EXtremeDB.query(e_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"questdb\"].append(QuestDB.query(q_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"timescaledb\"].append(TimescaleDB.query(t_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        \n",
    "        results[3][\"clickhouse\"].append(ClickHouse.query(c_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        results[3][\"extremedb\"].append(EXtremeDB.query(e_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        results[3][\"questdb\"].append(QuestDB.query(q_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        results[3][\"timescaledb\"].append(TimescaleDB.query(t_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        \n",
    "        \n",
    "        results[4][\"extremedb\"].append(EXtremeDB.query(e_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        results[4][\"questdb\"].append(QuestDB.query(q_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        results[4][\"timescaledb\"].append(TimescaleDB.query(t_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c44d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_d = 1000\n",
    "rangesUnit = \"minute\"\n",
    "results = [{} for i in range(5)]\n",
    "\n",
    "for i in range(5):\n",
    "        results[i][\"clickhouse\"] = []\n",
    "#         results[i][\"druid\"] = []\n",
    "        results[i][\"druid_wide\"] = []\n",
    "        results[i][\"extremedb\"] = []\n",
    "        results[i][\"influx\"] = []\n",
    "        results[i][\"monetdb\"] = []\n",
    "        results[i][\"questdb\"] = []\n",
    "        results[i][\"timescaledb\"] = []\n",
    "#         results[i][\"timescaledb_narrow\"] = []\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryClickHouse(duration_range):\n",
    "    for i in range(5):\n",
    "        results[i][\"clickhouse\"] = []\n",
    "    for duration in tqdm(duration_range):\n",
    "        results[0][\"clickhouse\"].append(ClickHouse.query(c_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"clickhouse\"].append(ClickHouse.query(c_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"clickhouse\"].append(ClickHouse.query(c_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[3][\"clickhouse\"].append(ClickHouse.query(c_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "#         results[4][\"clickhouse\"].append(ClickHouse.query(c_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "\n",
    "def queryDruidWide(duration_range):\n",
    "    for i in range(5):\n",
    "        results[i][\"druid_wide\"] = []\n",
    "    for duration in tqdm(duration_range):\n",
    "        Dduration = duration\n",
    "        DrangesUnit = rangesUnit\n",
    "        if Dduration > 99: \n",
    "            Dduration = Dduration // 60\n",
    "            Dduration -= Dduration%5\n",
    "            DrangesUnit = \"hour\"  \n",
    "            if Dduration > 99: \n",
    "                Dduration = Dduration // 24\n",
    "                Dduration -= Dduration%5\n",
    "                DrangesUnit = \"day\"          \n",
    "#             results[0][\"druid\"].append(Druid.query(d_q1, Dduration, DrangesUnit, n_it)[0][-1])\n",
    "#             results[1][\"druid\"].append(Druid.query(d_q2, Dduration, DrangesUnit, n_it)[0][-1])\n",
    "#             results[2][\"druid\"].append(Druid.query(d_q3, Dduration, DrangesUnit, n_it)[0][-1])\n",
    "#             results[3][\"druid\"].append(Druid.query(d_q4, Dduration, DrangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        results[0][\"druid_wide\"].append(Druid_Wide.query(dw_q1, Dduration, DrangesUnit, n_it)[0][-1])\n",
    "        results[1][\"druid_wide\"].append(Druid_Wide.query(dw_q2, Dduration, DrangesUnit, n_it)[0][-1])\n",
    "        results[2][\"druid_wide\"].append(Druid_Wide.query(dw_q3, Dduration, DrangesUnit, n_it)[0][-1])\n",
    "        results[3][\"druid_wide\"].append(Druid_Wide.query(dw_q4, Dduration, DrangesUnit, n_it, n_st = 5)[0][-1])\n",
    "#         results[\"druid\"].append(Druid.query(d_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "\n",
    "def queryExtremeDB(duration_range):    \n",
    "    for i in range(5):\n",
    "        results[i][\"extremedb\"] = []    \n",
    "    for duration in tqdm(duration_range):\n",
    "        results[0][\"extremedb\"].append(EXtremeDB.query(e_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"extremedb\"].append(EXtremeDB.query(e_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"extremedb\"].append(EXtremeDB.query(e_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[3][\"extremedb\"].append(EXtremeDB.query(e_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        results[4][\"extremedb\"].append(EXtremeDB.query(e_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "    \n",
    "def queryInflux(duration_range):\n",
    "    for i in range(5):\n",
    "        results[i][\"influx\"] = [] \n",
    "    for duration in tqdm(duration_range):\n",
    "        results[0][\"influx\"].append(Influx.query(i_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"influx\"].append(Influx.query(i_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"influx\"].append(Influx.query(i_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[3][\"influx\"].append(Influx.query(i_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        results[4][\"influx\"].append(Influx.query(i_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "    \n",
    "def queryMonetDB(duration_range):\n",
    "    for i in range(5):\n",
    "        results[i][\"monetdb\"] = [] \n",
    "    for duration in tqdm(duration_range):\n",
    "        results[0][\"monetdb\"].append(MonetDB.query(m_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"monetdb\"].append(MonetDB.query(m_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"monetdb\"].append(MonetDB.query(m_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[3][\"monetdb\"].append(MonetDB.query(m_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "#         results[\"monetdb\"].append(MonetDB.query(m_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "\n",
    "    \n",
    "def queryQuestDB(duration_range):\n",
    "    for i in range(5):\n",
    "        results[i][\"questdb\"] = [] \n",
    "    for duration in tqdm(duration_range):\n",
    "        results[0][\"questdb\"].append(QuestDB.query(q_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"questdb\"].append(QuestDB.query(q_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"questdb\"].append(QuestDB.query(q_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[3][\"questdb\"].append(QuestDB.query(q_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        results[4][\"questdb\"].append(QuestDB.query(q_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "    \n",
    "def queryTimescaleDB(duration_range):\n",
    "    for i in range(5):\n",
    "        results[i][\"timescaledb\"] = [] \n",
    "    for duration in tqdm(duration_range):\n",
    "        results[0][\"timescaledb\"].append(TimescaleDB.query(t_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[1][\"timescaledb\"].append(TimescaleDB.query(t_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[2][\"timescaledb\"].append(TimescaleDB.query(t_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "        results[3][\"timescaledb\"].append(TimescaleDB.query(t_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "        results[4][\"timescaledb\"].append(TimescaleDB.query(t_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "#     for duration in tqdm(duration_range):\n",
    "#         results[0][\"timescaledb_narrow\"].append(TimescaleDB_Narrow.query(tn_q1, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[1][\"timescaledb_narrow\"].append(TimescaleDB_Narrow.query(tn_q2, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[2][\"timescaledb_narrow\"].append(TimescaleDB_Narrow.query(tn_q3, duration, rangesUnit, n_it)[0][-1])\n",
    "#         results[3][\"timescaledb_narrow\"].append(TimescaleDB_Narrow.query(tn_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "#         results[4][\"timescaledb_narrow\"].append(TimescaleDB_Narrow.query(tn_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "\n",
    "def queryAll(duration_range):\n",
    "    queryClickHouse(duration_range)\n",
    "    queryDruidWide(duration_range)\n",
    "    queryExtremeDB(duration_range)\n",
    "    queryInflux(duration_range)\n",
    "    queryMonetDB(duration_range)\n",
    "    queryQuestDB(duration_range)\n",
    "    queryTimescaleDB(duration_range)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d458d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics as stats\n",
    "#import os\n",
    "#os.system('sudo sync; echo 3 > /proc/sys/vm/drop_caches')\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8155b23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_range = 1*60*24*3\n",
    "# max_range = 1*60*24*30*2\n",
    "duration_range = [ 2**i for i in range(1, int(math.log2(max_range)+1)) ]\n",
    "\n",
    "start_program = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryClickHouse(duration_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea46ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryDruidWide(duration_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryExtremeDB(duration_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryInflux(duration_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryMonetDB(duration_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79467ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryQuestDB(duration_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79069c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryTimescaleDB(duration_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58948dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = queryAllClickHouse(duration_range)\n",
    "# results = queryAllClickHouse(duration_range)\n",
    "stop_program = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf232f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0] = { k: results[0][k] for k in [\"clickhouse\",\"druid_wide\",\"extremedb\",\"monetdb\",\"questdb\",\"timescaledb\"] }\n",
    "results[1] = { k: results[1][k] for k in [\"clickhouse\",\"druid_wide\",\"extremedb\",\"monetdb\",\"questdb\",\"timescaledb\"] }\n",
    "results[2] = { k: results[2][k] for k in [\"clickhouse\",\"druid_wide\",\"extremedb\",\"monetdb\",\"questdb\",\"timescaledb\"] }\n",
    "results[3] = { k: results[3][k] for k in [\"clickhouse\",\"druid_wide\",\"extremedb\",\"monetdb\",\"questdb\",\"timescaledb\"] }\n",
    "results[4] = { k: results[4][k] for k in ['extremedb', 'questdb', 'timescaledb'] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da29349",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(results))): \n",
    "    df = pd.DataFrame(results[i])\n",
    "    df.index = duration_range\n",
    "    print(df.round(2))\n",
    "    df.plot(title='query' + str(i+1), xlabel='window range (minutes)', ylabel='time (ms)', logy = True, logx = True)\n",
    "# type(results[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Benchmark Runtime: %s minutes' % str((stop_program - start_program)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83812085",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ClickHouse')\n",
    "res = ClickHouse.query(c_q1, 60, rangesUnit, n_it)\n",
    "res = round(res[0][0],2), round(res[1][0],2)\n",
    "print(str(res[0])+'$\\\\pm$'+str(res[1]))\n",
    "\n",
    "res = ClickHouse.query(c_q2, 60, rangesUnit, n_it)\n",
    "res = round(res[0][0],2), round(res[1][0],2)\n",
    "print(str(res[0])+'$\\\\pm$'+str(res[1]))\n",
    "\n",
    "res = ClickHouse.query(c_q3, 60, rangesUnit, n_it)\n",
    "res = round(res[0][0],2), round(res[1][0],2)\n",
    "print(str(res[0])+'$\\\\pm$'+str(res[1]))\n",
    "\n",
    "res = ClickHouse.query(c_q4, 60, rangesUnit, n_it, n_st = 5)\n",
    "res = round(res[0][0],2), round(res[1][0],2)\n",
    "print(str(res[0])+'$\\\\pm$'+str(res[1]))\n",
    "\n",
    "print('Druid')\n",
    "print(Druid_Wide.query(dw_q1, 60, 'hour', n_it))\n",
    "print(Druid_Wide.query(dw_q2, 60, 'hour', n_it))\n",
    "print(Druid_Wide.query(dw_q3, 60, 'hour', n_it))\n",
    "print(Druid_Wide.query(dw_q4, 60, 'hour', n_it, n_st = 5))\n",
    "#         results[\"druid\"].append(Druid.query(d_q4, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "print('ExtremeDB')\n",
    "print(EXtremeDB.query(e_q1, 60, rangesUnit, n_it))\n",
    "print(EXtremeDB.query(e_q2, 60, rangesUnit, n_it))\n",
    "print(EXtremeDB.query(e_q3, 60, rangesUnit, n_it))\n",
    "print(EXtremeDB.query(e_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "print(EXtremeDB.query(e_q5, 60, rangesUnit, n_it, n_st = 5))\n",
    "\n",
    "print('Influx')    \n",
    "print(Influx.query(i_q1, 60, rangesUnit, n_it))\n",
    "print(Influx.query(i_q2, 60, rangesUnit, n_it))\n",
    "print(Influx.query(i_q3, 60, rangesUnit, n_it))\n",
    "print(Influx.query(i_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "print(Influx.query(i_q5, 60, rangesUnit, n_it, n_st = 5))\n",
    "\n",
    "    \n",
    "print('MonetDB')    \n",
    "print(MonetDB.query(m_q1, 60, rangesUnit, n_it))\n",
    "print(MonetDB.query(m_q2, 60, rangesUnit, n_it))\n",
    "print(MonetDB.query(m_q3, 60, rangesUnit, n_it))\n",
    "print(MonetDB.query(m_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "#         results[\"monetdb\"].append(MonetDB.query(m_q5, duration, rangesUnit, n_it, n_st = 5)[0][-1])\n",
    "\n",
    "\n",
    "    \n",
    "print('QuestDB')    \n",
    "print(QuestDB.query(q_q1, 60, rangesUnit, n_it))\n",
    "print(QuestDB.query(q_q2, 60, rangesUnit, n_it))\n",
    "print(QuestDB.query(q_q3, 60, rangesUnit, n_it))\n",
    "print(QuestDB.query(q_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "print(QuestDB.query(q_q5, 60, rangesUnit, n_it, n_st = 5))\n",
    "\n",
    "    \n",
    "print('TimescaleDB')    \n",
    "print(TimescaleDB.query(t_q1, 60, rangesUnit, n_it))\n",
    "print(TimescaleDB.query(t_q2, 60, rangesUnit, n_it))\n",
    "print(TimescaleDB.query(t_q3, 60, rangesUnit, n_it))\n",
    "print(TimescaleDB.query(t_q4, 60, rangesUnit, n_it, n_st = 5))\n",
    "print(TimescaleDB.query(t_q5, 60, rangesUnit, n_it, n_st = 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b5c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf31636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52f021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
