{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000b289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "import hashing.lsh_main as lsh\n",
    "# import graph.graph_main as graph\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import graph.random_walk_ori as random_walk\n",
    "import pandas as pd\n",
    "import lshashpy3 as lshash\n",
    "import math \n",
    "from scipy import stats\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def moving_avg(x, n):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[n:] - cumsum[:-n]) / float(n)\n",
    "# data = moving_avg(data, 200).tolist()\n",
    "\n",
    "\n",
    "window = 3072\n",
    "\n",
    "nTS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9013eb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250379"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv('/localdata/ABench-IoT/Generation/gan/dcgan/Electric.csv')\n",
    "# data = data['Electric'].tolist()\n",
    "# df_segments = pd.read_csv('/localdata/ABench-IoT/Generation/gan/dcgan/fake_noise_23_raw_f3.txt', header = None)\n",
    "\n",
    "data = pd.read_csv('/localdata/ABench-IoT/Generation/gan/dcgan_Sauerstoff/Sauerstoff.csv')\n",
    "data = data['Sauerstoff'].tolist()\n",
    "data = stats.zscore(np.array(data))\n",
    "data = data.tolist()\n",
    "# data = data[:window * 6 ]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d391b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_segments = pd.read_csv('/localdata/ABench-IoT/Generation/gan/dcgan_Sauerstoff/fake_noise_23_raw_f3.txt', header = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd79b19",
   "metadata": {},
   "source": [
    "## Filter GAN generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba29e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import lfilter\n",
    "\n",
    "df_segments = df_segments.T\n",
    "\n",
    "n = 10  # the larger n is, the smoother curve will be\n",
    "b = [1.0 / n] * n\n",
    "a = 1\n",
    "\n",
    "for col in tqdm(df_segments):\n",
    "#     plt.plot(df_segments[col].tolist())\n",
    "    yy = lfilter(b,a,df_segments[col].tolist())\n",
    "    yy[:n] = yy[n:n+1]\n",
    "    df_segments[col] = yy.tolist()\n",
    "#     plt.plot(df_segments[col].tolist())\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "# df_segments = pd.DataFrame(segments)\n",
    "# df_segments = df_segments.T\n",
    "\n",
    "df_segments.iloc[: , :50].plot(subplots=True, layout=(10,6), figsize=(10, 10), legend = True, color = 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b98270",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = [] \n",
    "\n",
    "for col in df_segments:\n",
    "    segments += [df_segments[col].tolist()]\n",
    "print(len(segments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e7e07",
   "metadata": {},
   "source": [
    "# LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe694ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def LSH_update(ori, generated, window, nTS, n_top = 30, hash_length = window // 300, num_hashtables=8):\n",
    "#     # index synthetic segments\n",
    "#     lsh = lshash.LSHash(hash_length, window, num_hashtables=num_hashtables)\n",
    "#     for i in generated:\n",
    "#         lsh.index(i) \n",
    "#     to_query = [ori[i:i + window] for i in range(0, len(ori) - window, window)]\n",
    "#     lsh_res = []\n",
    "#     used = 0\n",
    "#     k = int(window * .03)\n",
    "#     for i in tqdm(range(nTS)):\n",
    "#         temp = list(random.choice( lsh.query(to_query[0], distance_func=\"euclidean\", num_results=n_top))[0][0])\n",
    "#         for i in range(1, len(to_query)): \n",
    "#             candidates = lsh.query(to_query[i], distance_func=\"euclidean\", num_results=n_top)\n",
    "#             s = list(random.choice(candidates)[0][0])\n",
    "#             temp_t = temp[-k:]\n",
    "#             s_h = s[:k]\n",
    "#             overlap = []\n",
    "#             for i in range(-k//2, k//2):\n",
    "#                 overlap.append((1 - sigmoid(i))*temp_t[i + k//2] + sigmoid(i)*s_h[i + k//2])\n",
    "#     #         for i in range(-1*k , 0):\n",
    "#     #             temp[i]= (1 - sigmoid(i))*temp_t[i] + sigmoid(i)*s_h[i]\n",
    "#     #         for i in range(0, k):\n",
    "#     #             s[i]= (1 - sigmoid(i))*temp_t[i] + sigmoid(i)*s_h[i]\n",
    "#             temp[-k:] = overlap\n",
    "#             s[:k] = overlap[::-1]\n",
    "#             temp.extend(s)\n",
    "#             used += 1\n",
    "#         lsh_res.append(temp)\n",
    "#         print(used, len(generated)*50//100)\n",
    "#         if used > len(generated)*50//100: \n",
    "#             lsh = lshash.LSHash(hash_length, window, num_hashtables=num_hashtables)\n",
    "#             for i in generated:\n",
    "#                 lsh.index(i)    \n",
    "#             used = 0\n",
    "#     return lsh_res\n",
    "\n",
    "def LSH(ori, generated, window, nTS, n_top = 30, hash_length = window // 300, num_hashtables=8, ts_length = -1):\n",
    "    if ts_length == -1: \n",
    "        ts_length = len(ori)\n",
    "    else:\n",
    "        ts_length -= ts_length%len(ori)\n",
    "    # index synthetic segments\n",
    "    lsh = lshash.LSHash(hash_length, window, num_hashtables=num_hashtables)\n",
    "    for i in generated:\n",
    "        lsh.index(i) \n",
    "    to_query = [ori[i%(len(ori)-window):i%(len(ori)-window) + window] for i in range(0, ts_length - window, window)]\n",
    "    lsh_res = []\n",
    "    k = int(window * .03)\n",
    "    for i in tqdm(range(nTS)):\n",
    "        temp = list(random.choice( lsh.query(to_query[0], distance_func=\"euclidean\", num_results=n_top))[0][0])\n",
    "        for i in range(1, len(to_query)): \n",
    "#             print(len(to_query[i]))\n",
    "            candidates = lsh.query(to_query[i], distance_func=\"euclidean\", num_results=n_top)\n",
    "            s = list(random.choice(candidates)[0][0])\n",
    "            temp_t = temp[-k:]\n",
    "            s_h = s[:k]\n",
    "            overlap = []\n",
    "            for i in range(-k//2, k//2):\n",
    "                overlap.append((1 - sigmoid(i))*temp_t[i + k//2] + sigmoid(i)*s_h[i + k//2])\n",
    "    #         for i in range(-1*k , 0):\n",
    "    #             temp[i]= (1 - sigmoid(i))*temp_t[i] + sigmoid(i)*s_h[i]\n",
    "    #         for i in range(0, k):\n",
    "    #             s[i]= (1 - sigmoid(i))*temp_t[i] + sigmoid(i)*s_h[i]\n",
    "            temp[-k:] = overlap\n",
    "            s[:k] = overlap[::-1]\n",
    "            temp.extend(s)\n",
    "        lsh_res.append(temp)\n",
    "    return lsh_res\n",
    "\n",
    "# lsh_res= LSH(data, segments, window, nTS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d93e9",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the distance between two series. Given series A, B returns the Euclidean distance between A and B\n",
    "def distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b)**2))\n",
    "    \n",
    "#The probability is converted according to the sorted distances, which adds up to 1\n",
    "def distopro(a):\n",
    "    a=len(a)\n",
    "    if(a==3):\n",
    "        b=[0.2,0.3,0.5]\n",
    "    elif(a==4):\n",
    "        b=[0.1,0.2,0.3,0.4]\n",
    "    else:\n",
    "        b=[0.04,0.12,0.2,0.28,0.36]\n",
    "    return np.array(b)\n",
    "        \n",
    "\n",
    "#Input is the original data matrix, return is the relationship matrix relation_matrix, and probability matrix probability_matrix\n",
    "#Data is the matrix of series, the first dimension is the number of series, and the second dimension is each series\n",
    "#Window_size is the size of the window to calculate the distance, and k is the number of the nearest neighbors selected. Currently, 3,4,5 are supported\n",
    "def transform(data, window_size, k):\n",
    "    numOfSeq=data.shape[0]\n",
    "    distance_matrix=np.ones([numOfSeq,numOfSeq],dtype = float)\n",
    "    for i in range(numOfSeq):\n",
    "        for j in range(numOfSeq):\n",
    "            distance_matrix[i][j]=distance(data[i,data.shape[1]-window_size:],data[j,0:window_size])\n",
    "    relation_matrix=np.ones([numOfSeq,k],dtype = int)\n",
    "    subdistance_matrix=np.ones([numOfSeq,k],dtype = float)\n",
    "    probability_matrix=np.ones([numOfSeq,k],dtype = float)\n",
    "    for i in range(numOfSeq):\n",
    "        relation_matrix[i]=distance_matrix[i].argsort()[::-1][data.shape[0]-k:]\n",
    "        #print(relation_matrix[i])\n",
    "#     print(relation_matrix[i])\n",
    "    for i in range(numOfSeq):\n",
    "        for j in range(k):\n",
    "            subdistance_matrix[i][j]=distance_matrix[i][relation_matrix[i][j]]\n",
    "    \n",
    "    for i in range(numOfSeq):\n",
    "        probability_matrix[i]=distopro(subdistance_matrix[i])\n",
    "    \n",
    "    \n",
    "    return distance_matrix, subdistance_matrix ,relation_matrix, probability_matrix\n",
    "            \n",
    "      \n",
    "#print(transform(np.array([[0,1,1,1],[1,0,1,1],[1,1,0,1],[1,1,1,0]]), 2, 3))\n",
    "\n",
    "\n",
    "#Given the ID of the current series, the ID of the next series is generated randomly according to probability\n",
    "def next_step(relation_array, probability_array):\n",
    "    value=random.random()\n",
    "#     print(value)\n",
    "    threshold=[0]\n",
    "    sum_value=0\n",
    "    for i in range(len(probability_array)):\n",
    "        sum_value=sum_value+probability_array[i]\n",
    "        threshold.append(sum_value)\n",
    "    for i in range(len(threshold)-1):\n",
    "        if(value>threshold[i] and value<=threshold[i+1]):\n",
    "            return relation_array[i]\n",
    "\n",
    "#Given a relation matrix and a probability matrix, returns a series of length        \n",
    "def random_walk(relation_matrix, probability_matrix, length):\n",
    "    seq=[0]\n",
    "    temp_id=0\n",
    "    for i in range(length-1):\n",
    "        temp_id=next_step(relation_matrix[temp_id],probability_matrix[temp_id])\n",
    "        seq.append(temp_id)\n",
    "        #print(temp_id)\n",
    "    return np.array(seq)\n",
    "\n",
    "\n",
    "def Graph(ori, generated, window, nTS, ts_length = -1):\n",
    "    if ts_length == -1: \n",
    "        ts_length = len(ori)\n",
    "    a,b,c,d=transform(np.array(generated), 100, 5)\n",
    "    graph_res = []\n",
    "    for i in range(nTS):\n",
    "        path = random_walk( c, d, ts_length//window)\n",
    "#         print(path)\n",
    "        temp=[]\n",
    "        for s in path:\n",
    "    #         print(path[i], i)\n",
    "            temp+=list(generated[s])\n",
    "        graph_res.append(temp)\n",
    "#     print(len(graph_res))   \n",
    "    return graph_res\n",
    "    \n",
    "# def Graph_update(ori, generated, window, nTS):\n",
    "#     a,b,c,d=transform(np.array(generated), 100, 5)\n",
    "#     used = 0\n",
    "#     graph_res = []\n",
    "#     for i in range(nTS):\n",
    "#         path = random_walk( c, d, int(len(ori)/window))\n",
    "# #         print(path)\n",
    "#         temp=[]\n",
    "#         for s in path:\n",
    "#     #         print(path[i], i)\n",
    "#             temp+=list(generated[s])\n",
    "#             used +=1\n",
    "#         graph_res.append(temp)\n",
    "#         print(used, len(generated)*50//100)\n",
    "#         if used > len(generated)*50//100: \n",
    "#             a,b,c,d=transform(np.array(generated), 100, 5)\n",
    "#             used = 0\n",
    "# #         print(len(graph_res))   \n",
    "#     return graph_res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410c024",
   "metadata": {},
   "source": [
    "# Generate LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4fce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTS = 100\n",
    "ts_length = 5200000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d193be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "lsh_res= LSH(data, segments, window, nTS=nTS, ts_length = ts_length)\n",
    "lsh_res = [i[:5200000] for i in lsh_res]\n",
    "print('LSH runtime: ', time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b50cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lsh_res)\n",
    "df = df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dca635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.to_csv(\"d1_lsh.csv\", sep=',', float_format='%.6f', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3504871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.to_csv(\"d1_lsh.csv\", sep=',', float_format='%.6f', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df for i in range(2)], axis=0)[:5184000]\n",
    "df.columns = ['s' + str(i) for i in range(100)]\n",
    "df.to_csv(\"d1_lsh.csv\", sep=',', float_format='%.6f', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4250504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "nb_station = 10\n",
    "nb_sensor = 100\n",
    "nb_days = 60\n",
    "granularity = 10 #seconds\n",
    "\n",
    "dtime = datetime(2019, 3, 1, 00)\n",
    "dtimestamp = datetime.timestamp(dtime)\n",
    "ms = int(round(dtimestamp * 1000))\n",
    "n_it = 10\n",
    "print(ms)\n",
    "\n",
    "list_time = [datetime.fromtimestamp(int((ms + i * granularity * 1000) //1000)).strftime('%Y-%m-%dT%H:%M:%S') for i in range(86400 // granularity * nb_days)] * 10\n",
    "\n",
    "print(len(list_time))\n",
    "\n",
    "list_st = []\n",
    "for s in range(10):\n",
    "    list_st += ['st' + str(s) for i in range(86400 // granularity * nb_days)]\n",
    "df['time'] = list_time\n",
    "df['id_station'] = list_st\n",
    "df = df[['time','id_station']+['s'+str(i) for i in range(100)]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3cf537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"d1_lsh.csv\", sep=',', float_format='%.6f', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f064ce9",
   "metadata": {},
   "source": [
    "# Generate Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de5dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "\n",
    "start = time.time()\n",
    "graph_res = Graph(data, segments, window, nTS=nTS, ts_length = ts_length)\n",
    "for i in range(len(graph_res)):\n",
    "    for j in range(len(graph_res[i])):\n",
    "        graph_res[i][j] = abs(graph_res[i][j])\n",
    "print('Graph runtime: ', time.time() - start, 's')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9cb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph_res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(graph_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_res = [abs(i[:5184000]) for i in graph_res]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62355995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "graph_res_ALL = list(itertools.chain.from_iterable(graph_res))\n",
    "print(len(graph_res_ALL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = pd.DataFrame()\n",
    "for i in range(100):\n",
    "    df_graph['s' + str(i)] = list(itertools.chain.from_iterable([graph_res[i*10 + idx] for idx in range(10)]))  #graph_res_ALL[i*5184000:(i+1)*5184000]\n",
    "df_graph.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a02c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "nb_station = 10\n",
    "nb_sensor = 100\n",
    "nb_days = 60\n",
    "granularity = 10 #seconds\n",
    "\n",
    "dtime = datetime(2019, 3, 1, 00)\n",
    "dtimestamp = datetime.timestamp(dtime)\n",
    "ms = int(round(dtimestamp * 1000))\n",
    "n_it = 10\n",
    "print(ms)\n",
    "\n",
    "list_time = [datetime.fromtimestamp(int((ms + i * granularity * 1000) //1000)).strftime('%Y-%m-%dT%H:%M:%S') for i in range(86400 // granularity * nb_days)] * 10\n",
    "\n",
    "print(len(list_time))\n",
    "\n",
    "list_st = []\n",
    "for s in range(10):\n",
    "    list_st += ['st' + str(s) for i in range(86400 // granularity * nb_days)]\n",
    "df['time'] = list_time\n",
    "df['id_station'] = list_st\n",
    "df = df[['time','id_station']+['s'+str(i) for i in range(100)]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd61bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"d1_lsh.csv\", sep=',', float_format='%.6f', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d509294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5edfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db644ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
